---
title: "Survival Analysis in R"
author:
  - name: "Srijana_Acharya_Gautam"
    affiliations:
      - Florida International University
      - Robert Stempel College of Public Health and Social Work
toc: true
number-sections: true
format: html
embed-resources: false
---



## What is survival analysis

Survival analysis is a statistical method for analyzing survival data (longitudinal time to event data). Now, before discussing the statistical terms, lets think about what survives, and what does it mean by survival. The answer that comes to our mind is, it's the living being that survives, and the survival time means life span such that time between ones's birth to death. That's true, survival analysis was originally used solely for investigations of mortality and morbidity on vital registration statistics. Xian Lui (2012) noted the history of arithmetic analysis of survival process can be traced back to the 17th century when English statistician John Graunt first published the life table in 1662. Since the outcome occurs over the course of time, the data should be longitudinal data.Since then the survival analysis was widely used in clinical trials.

Over the past 50 years, the literature notes the expanded applicability of survival analysis to the diverse fields like domain of biological science, biomedical science, engineering, and public health. Survival time therefore does not necessarily mean life span of living organisms, it can be start of drug to the first remission of the disease, diagnosis of the disease to the incidence of comorbidities, construction of a building to the collapse of the building, marriage to divorce, unemployment to the start of addiction drugs, occupational careers etc. In survival analysis the latter outcome is called an event, and the outcome of interest is the time to event.



## General features of survival data structure

**1.Survival process:** The primary feature of the survival data is the description of a change in status from specified original status as the underlying outcome measure. For example, start of cancer drug to remission of the cancer. The survival probability is the probability that an individual survives from the time origin (e.g., diagnosis of diabetes) to a specified future time t.

**2.Time to event:** It is calculated subtracting the specified starting time of the original status from the time of the occurrence of a particular event. It varies for different observations.

**3.Censoring:** Censoring is defined as assigning an specific value to any observation whose information on specified event/outcome is missing. Any study has a specified time or survival data generally are collected for a particular interval in which the occurrence of a particular event is observed. Researchers therefore can only observe those events that occur within a surveillance window between two-time limits. Many observations may not encounter the event in the given time frame, or some observations may get lost before the specified time. Such observations whose information on specified event are missing are censored which indicates that event did not occur for those observations in the given time. Censoring may occur for various reasons. In clinical trials, patients may be lost to follow-up due to migration or health problems, in longitudinal survey, some baseline respondents may lose interest in participating etc. Since censoring frequently occurs, most of the survival analysis literally deals with incomplete survival data, and accordingly scientists have found ways to use such limited information for correctly analyzing the incomplete survival data based on some restrictive assumptions on the distribution of censored survival times. Given the importance of handling censoring in survival analysis, a variety of censoring types are possible as below:

***a)Right censoring:*** The observations that are lost to follow-up or that do not encounter event during the specified study period, the actual event for such observations is placed somewhere to the right of the censored time along the time axis. This type of censoring is called right censoring. This type of censoring occurs most frequently in survival data. The basic assumption of this type of censoring is that the individual's censored time is independent of the actual survival time, thereby making right censoring non-informative.

***b)Left censoring***

***c)Interval censoring***

![](fig/06_survival_analysis_censoring_eg1.png){width="395"}

![](fig/06_survival_analysis_censoring_eg2.png){width="395"}



## Statistical methods used in survival analysis

**1) Kaplan-Meier (product limit)**

The Kaplan--Meier (KM) method explores the survival of a population under investigation and/or tests differences in the crude cumulative survival between exposure groups, with a graphical representation of the endpoint occurrence as a function of time. It is a survival probability estimation method for non-parametric data. As events are assumed to occur independently of one another, the probabilities of surviving from one interval to the next may be multiplied together to give the cumulative survival probability. The KM survival curve, a plot of the KM survival probability against time, provides a useful summary of the data that can be used to estimate measures such as median survival time. The large skew encountered in the distribution of most survival data is the reason that the mean is not often used. It is called product limit approach because it estimates the survival probability each time an event occurs. (meaning it does not consider time as an interval/range (e.g., 5-10 years of age) but as a specific time (e.g., 5 years, 6 years, etc).

**Important limitations of the KM method are**

1)  It does not provide an effect estimate (i.e., a relative risk) or the related confidence interval to compare the survival in different patient groups.

2)  It does not permit the adjustment of confounders in etiological research or predictors in prognostic research.

3)  It requires data categorization, so calculation of the incremental increase (or decrease) in the relative risk of a given event associated with one unit (or any number of units) increase in the candidate risk factor is not possible. These limitations can be approached by Cox regression analysis,

**2) Log rank test**

It is a method of comparing survival function among groups (non-parametric test). It test the following hypothesis;

Ho: In terms of survivability, there is no difference between two groups.

H1: There is a survival differential between the two groups.

We can reject the null hypothesis and infer that there is enough evidence to claim there is a difference in survival between the two groups if the p-value of the test is less than specified p-value which is generally 0.05 (95% confidence level).

**3) Cox proportional hazard regression**

The Cox model is a regression technique for performing survival analyses. This model estimates the hazard ratio (HR) of a given endpoint associated with a specific risk factor which can be continous or categorical variable. The hazard is the probability that an individual who is under observation at a time t has an event at that time. It represents the instantaneous event rate for an individual who has already survived to time t. The hazard function for a particular time interval gives the probability that the subject will fail in that interval, given that the subject has not failed up to that point in time. In regression models for survival analysis, we attempt to estimate parameters which describe the relationship between our predictors and the hazard rate. It is called the proportional hazards model because it assumes that the effects of different variables on survival are constant over time and additive over a particular scale. When the risk factor is a continuous variable, the Cox model provides the HR of the study endpoint associated with a predefined unit of increase in the independent variable and when the risk factor is categorical variable, the Cox model provides HR of one group compared to another reference group.

**Mathematical equation for Cox model**

***Hazard equation***

Hazard = Probability of the event happening at time t given it hasn't happened up until time t

$$
H(t) = \frac{p(\text{Event} \in [t, t + \Delta t) | \text{Event} > t)}{\Delta t}
$$

***Cox Model Equation***

$$
H(t) = H_0(t)\exp[B_1X_1 + B_2X_2 + ....B_kX_k]
$$

Where

-   $X_1, \ldots, X_k$ represents the predictor variables and
-   $H_0(t)$ is the baseline hazard at time t, which is the hazard of an individual having the predictors set to zero.
-   $B_1, \ldots, B_k$ represent regression coeffiecient

By computing the exponential of the regression coefficient $B_1, \ldots, B_k$ (directly provided by the software), we can calculate the HR of a given risk factor or predictor in the model. For example, if the risk factor $X_1$ is dichotomous and it is codified "1" if present (exposed) and "0" if absent (unexposed), the expression $e^{B_i}$ (where exp = 2.7183) can be interpreted as the estimated increase in the HR of the event in patients with the risk factor compared to those without the same risk factor; this is applied by assuming exposed and unexposed patients are similar for all the other covariates included in the model. If the risk factor is a continuous variable and it is directly related to the incidence rate of a given event (e.g., age in years as a risk factor for mortality), the HR will be interpreted as an increase in the hazard rate of death due to a 1-year increase in age.

**Assumption of Cox model**

Hazard may fluctuate as a function of time, but the hazardous effects of different variables on survival are constant over time and additive over a particular scale.

$$
\frac{H(t)}{H_0} = \text{constant}
$$

Where,

$H(t)$ = Increased hazard as a result of exposure.

$H_0$ = Baseline hazard in non-exposed

![](fig/06_survival_analysis_prop_hazards.png){width="395"}



## Packages

The packages required for conducting survival analysis can be installed automatically using the [ctv](https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/) packages. Following are the packages that will be functioning in this survival analysis project

[survival]{style="color: red;"} The survival package is the cornerstone of the entire R survival analysis. Not only is the package itself rich in features, but the object created by the [Surv()]{style="color: red;"} function, which contains failure time and censoring information, is the basic survival analysis data structure in R.

[ggfortify]{style="color: red;"} ggfortify enables producing handsome, one-line survival plots with [ggplot2::autoplot]{style="color: red;"}



## Load the data

This project uses the veterans dataset contained in the survival package. Veteran dataset contains data from a two-treatment, randomized trial for lung cancer. We load the data with required packages into our library as follows:

```{r}
library(survival)
library(ggplot2)
library(dplyr)
library(ggfortify)
```



## Checking the veteran data

```{r}
data(veteran)
head(veteran)
```

Veteran data contains following variables

**trt:** 1=standard 2=test

**celltype:** 1=squamous, 2=small cell, 3=adeno, 4=large

**time:** survival time in days after randomization

**status:** censoring status. 1 = dead, 0 = censored

**karno:** Karnofsky performance score (100=good). For proper pronounciation and meaning of this score click [here](https://www.cancer.gov/publications/dictionaries/cancer-terms/def/karnofsky-performance-status)

**diagtime:** months from diagnosis to randomization

**age:** in years

**prior:** prior therapy 0 = no, 1 = yes



## Kaplan Meier Analysis

We first need to use [Surv()]{style="color: red;"} to build the standard survival object. **Note:** a "+" after the time in the print out of the output indicates censored observation.

```{r}
# Kaplan Meier Survival curve

km <- with(veteran, Surv(time, status))
head(km, 80)
```

Now to begin our analysis, we use the formula [Surv()]{style="color: red;"} and the [Surfit()]{style="color: red;"} function to produce the Kaplan-Meier estimates of the probability of survival over time. The times parameter of the summary() function gives some control over which times to print. Here, it is set to print the estimates for 1, 30, 60 and 90 days, and then every 90 days thereafter. This is the simplest possible model. It only takes three lines of R code to fit it, and produce numerical and graphical summaries.

```{r}
km_fit <- survfit(Surv(time, status) ~ 1, data=veteran)
summary(km_fit, times = c(1,30,60,90*(1:10)))

#plot(km_fit, xlab="Days", main = 'Kaplan Meyer Plot') #base graphics is always ready
autoplot(km_fit)

```



## Survival curves by treatment

```{r}
km_trt_fit <- survfit(Surv(time, status) ~ trt, data=veteran)
autoplot(km_trt_fit)
```

Now to show one more small exploratory plot, we will create a new data frame to look at survival by age. First, we will create a new data frame with a categorical variable AG that has values LT60 and GT60, which respectively describe veterans younger and older than sixty. And we make **trt** and **prior** into factor variables.

```{r}
vet <- mutate(
  veteran,
  AG = ifelse((age < 60), "LT60", "OV60"),
  AG = factor(AG),
  trt = factor(trt,labels=c("standard","test")),
  prior = factor(prior,labels=c("N0","Yes"))
)

km_AG_fit <- survfit(Surv(time, status) ~ AG, data=vet)
autoplot(km_AG_fit)
```

Although the two curves appear to overlap in the first fifty days, younger patients clearly have a better chance of surviving more than a year.



## Conducting log-rank test

```{r}
library("survival")
library("survminer")
library("Rcpp")
```

First lets look at the summary table of the survival curve

```{r}
summary(km_trt_fit)$table
```

Now for better visualization with p-value, we are using following plot

```{r}
ggsurvplot(
  km_trt_fit,
  pval = TRUE, conf.int = TRUE,
  risk.table = TRUE, # Add risk table
  risk.table.col = "strata", # Change risk table color by groups
  linetype = "strata", # Change line type by groups
  surv.median.line = "hv", # Specify median survival
  ggtheme = theme_bw(), # Change ggplot2 theme
  palette = c("#E7B800", "#2E9FDF")
)
```

P-value is 0.93 which indicates that there is no significant difference between treatment 1 and 2 for survivability outcome.

The survival chance is 1.0 at time zero (or 100 percent of the participants are alive).

At time 250, the chances of survival for both trt=1 and tr2=2 are about 0.13 (or 13 percent).

The median survival time for trt=2 is about 60 days and for trt=1 is about 100 days, indicating that trt=1 has a better survival rate than trt=2, however the difference is not statistically significant

The following code shows how to perform a log-rank test to determine if there is a difference in survival between trt groups who received different treatments:

```{r}
surv_diff <- survdiff(Surv(time, status) ~ trt, data = veteran)
surv_diff
  
```

The Chi-Squared test statistic is 0 with 1 degree of freedom and the corresponding p-value is 0.9. Since this p-value is greater than 0.05, we cannot reject the null hypothesis.

In other words, we do not have sufficient evidence to say that there is a statistically significant difference in survival between the two treatment groups.



## Cox Proportional Hazard Models

Now we will fit a [Cox Proportional Hazards model](https://en.wikipedia.org/wiki/Proportional_hazards_model) that makes use of all of the covariates in the data set.

```{r}
# Fit the Cox Model
cox <- coxph(
  Surv(time, status) ~ trt + celltype + karno + diagtime + age + prior,
  data = vet
)
summary(cox)

```



## Plot the Cox model

```{r}
cox_fit <- survfit(cox)
#plot(cox_fit, main = "cph model", xlab="Days")
autoplot(cox_fit)
```

Note that the model flags small cell type, adeno cell type and karno as significant. However, some caution needs to be exercised in interpreting these results. While the Cox Proportional Hazard's model is thought to be "robust", a careful analysis would check the assumptions underlying the model. For example, the Cox model assumes that the covariates do not vary with time. In a [vignette](https://cran.r-project.org/web/packages/survival/vignettes/timedep.pdf) that accompanies the [Survival]{style="color: red;"} package Therneau, Crowson and Atkinson demonstrate that the Karnofsky score (karno) is, in fact, time-dependent so the assumptions for the Cox model are not met. The vignette authors have presented a strategy for dealing with time dependent covariates.

Data scientists who are accustomed to computing [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curves to assess model performance should be interested in the Concordance statistic. The documentation for the [survConcordance()]{style="color: red;"} function in the [Survival]{style="color: red;"} package defines concordance as "the probability of agreement for any two randomly chosen observations, where in this case agreement means that the observation with the shorter survival time of the two also has the larger risk score. The predictor (or risk score) will often be the result of a Cox model or other regression" and notes that: "For continuous covariates concordance is equivalent to [Kendall's tau](https://www.statstest.com/kendalls-tau/), and for logistic regression it is equivalent to the area under the [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) curve.".

To demonstrate using the [Survival]{style="color: red;"} package, along with [ggplot2]{style="color: red;"} and [ggfortify]{style="color: red;"}, here we will fit [Aalen's additive regression model](https://www.medicine.mcgill.ca/epidemiology/hanley/bios601/Encyclopedia%20of%20Biostatistics2ndEd2005.pdf) for censored data to the veteran data. To further understand AA regression please click [here](https://folk.ntnu.no/bo/STK4080/STK4080-Slides13-2019.pdf). The documentation states: The Aalen model assumes that the cumulative hazard H(t) for a subject can be expressed as

***a(t) + X B(t)***, where

**a(t)** is a time-dependent intercept term, **X** is the vector of covariates for the subject (possibly time-dependent), and **B(t)** is a time-dependent matrix of coefficients."

The plots show how the effects of the covariates change over time. We can see the steep slope and then abrupt change in slope of karno.

```{r}
aa_fit <- aareg(
  Surv(time, status) ~ trt + celltype + karno + diagtime + age + prior, 
  data = vet
)
aa_fit
```



## Plot the Aalen's Addictive Regression model

```{r}
#summary(aa_fit)  # provides a more complete summary of results
autoplot(aa_fit)
```


### Interpretation of AA model graph

Looking at this plot we can see that only karno is the time dependent variable because the graph is steeply below 0. Now with this knowledge, we can re-fit our model.



## References

[Liu, X. (Xian X. ). (2012). Survival analysis models and applications. Wiley/Higher Education Press.](https://fiu-flvc.primo.exlibrisgroup.com/discovery/fulldisplay?docid=alma991002743961506571&context=L&vid=01FALSC_FIU:FIU&lang=en&search_scope=MyInst_and_CI&adaptor=Local%20Search%20Engine&tab=All40&query=any,contains,survival%20analysis)

[Abd ElHafeez, S., D'Arrigo, G., Leonardis, D., Fusaro, M., Tripepi, G., & Roumeliotis, S. (2021). Methods to Analyze Time-to-Event Data: The Cox Regression Analysis. Oxidative medicine and cellular longevity, 2021, 1302811. https://doi.org/10.1155/2021/1302811](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8651375/#:~:text=The%20Cox%20regression%20model%20is%20based%20on%20the%20hazard%20function,b%20k%20x%20k%20.)

[Azzato, E., Greenberg, D., Shah, M. et al. Prevalent cases in observational studies of cancer survival: do they bias hazard ratio estimates?. Br J Cancer 100, 1806--1811 (2009). https://doi.org/10.1038/sj.bjc.6605062](https://www.nature.com/articles/6605062)
