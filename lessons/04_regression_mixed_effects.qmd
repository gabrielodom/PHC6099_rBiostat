---
title: "Mixed Effect Regression"
subtitle: "Learning how to use Mixed Effect Models in R"
date: "`r Sys.Date()`"
author:
  - name: Tarana Ferdous, Ana Bravo & Tendai Gwanzura
    affiliations:
      - Florida International University
      - Robert Stempel College of Public Health and Social Work
toc: true
number-sections: true
format: html
embed-resources: false
---


## Introduction


### What is Mixed Effect Model? 
Mixed Effects Regression is a method for analyzing data that are non-independent, multilevel/hierarchical, longitudinal, repeated or correlated. It allows both **fixed** and **random** effects, and are particularly used when there is non independence in the data, such as arises from a hierarchical structure. For example, students sampled from within schools, or patients from within hospitals.


### Notes on the content
Throughout this lesson, we added references of some YouTube videos which we found helpful. Most of the content here is from those videos, courtesy of the [**Quant Psych** channel](https://www.youtube.com/c/QuantPsych). If you find the content of this discussion difficult, we highly recommend you to go watch those videos. 


### Terminology:

Other terms that are used for Mixed Effect Models include: 

- Hierarchical Leaner Model (HLM)
- Multi-level model (MLM)
- Linear mixed-effect model (LMM)
- Mixed model 
- Repeated measures linear regression 
- Random effects model 
- Varying coefficients model

<u> Focus on what the model is trying to do instead of what the model is called.</u>


### An Example
First figure shows a positive correlation: the proportion of survival increases as the the severity of symptom increases. 

![](fig/04_mixed_effects_sev_vs_survive.png)

However, in real, if we color-code these data, we can see that three different clusters of hospitals data are shown.

![](fig/04_mixed_effects_sev_vs_survive_cluster.png)

In mixed effect models, they fit a separate regression line for each and every cluster. Then it estimates an average slope between `Y (Proportion of survival)` and **X (severity of symptoms)** across **all clusters (all hospitals)**.  

<!-- ![](fig/04_mixed_effects_dose_SBP.jpg) -->
![Association between average symptom severity and survival for three hospitals.](fig/04_mixed_effects_ave_sev_surv.png){fig-ave-sev-and-surv}

Here, the black line is the fixed effects and the colored lines are the random effects. So, all the participants across the three hospitals cannot be treated as independent data. Every cluster has its own regression line.    


## Mathematical Formulation of the Model

**Fixed effects** represent the systematic or population-level effects. These are parameters that apply to the *entire population*. In mathematical notation, we denote fixed effects as $\beta$ and the fixed effects part of the model can be expressed as: 

$$
Y = \textbf{X}\beta+e
$$
Where, 

- $Y$ is response variable 
- $\textbf{X}$ is a matrix of predictor variables  
- $e$ represents the random error.

**Random effects** account for variability due to *specific groups or clusters within the data*. These effects are specific to certain levels of a grouping variable (e.g., subjects, schools, or regions). In mathematical notation, we denote random effects as $\textbf{Z}a$, where,

- $\textbf{Z}$ is a fixed matrix 
- $a$ is an unobserved random effect vector

The full model incorporating both fixed and random effects is:

$$
Y = \textbf{X}\beta + \textbf{Z}a+ e.
$$
**For example**: to study the effect of different *doses* (predictor variable) 
of an anti-hypertensive drug on *blood pressure* (response variable) across 
multiple subjects, the model might look like this:

$$
Y_{ij} =
  \overbrace{\beta_0 + \beta_1Dose_{ij}}^{\text{fixed part}} +
  \underbrace{a_i + e_{ij}}_{\text{random part}}
$$

Where, 

- $Y_{ij}$ is blood pressure for subject $i$ at dose level $j$ 
- $\beta_0$ is fixed effect parameter (intercept), represents baseline blood pressure when the dose was zero.
- $\beta_1$ is another fixed effect parameter, represents effect of the dose levels on the blood pressure 
- $\text{Dose}_{ij}$ is dose level for subject $i$ at level $j$ 
- $a_i$ is random effect for subject $i$, that captures subject-specific variability not explained by fixed effects. These random effects account for individual differences.
- $e_{ij}$ is random error term, represents unexplained variability or noise in the model.


##  Regression Models used in analysis 

-   **Fixed effects model** (when all model effects are fixed effects)
      Same intercept and same slope 

-   **Mixed effects model** (when both fixed effect(s) and random effect(s) are present)
      Different intercepts same slope OR same intercept different slopes
    
-   **Random effects model** (when all model effects are random effects)
      Different intercepts different slopes

Depending on the data type and research question, we can use different types of models with random effects.

![**Examples:** Top Left: no group effects; Top Right: temperature/time (3 different unit of AC); Bottom Left: blood sugar level/hour 
(3 different diabetic-drug); Bottom Right: weight/week (3 different diets)](fig/04_mixed_effects_models.png)


## Choosing the Right Model

How should we decide which variable should be considered as fixed, mixed, or random? We have three strategies:


### Strategy 1: Look into the data set

- Example: Math dataset: Math achievement data for different schools (clusters)
- Variables: School, Minority Status, Sex, Socio-Economic Status (SES), 
Math achievement and mean SES, 

![](fig/04_mixed_effects_inspect_data.png)

- Decision: If all the values in a variable **(MEANSES)** does not vary within 
a cluster variable **(School)**, it cannot be fitted as random effect. This is because there is no slope as the **MEANSES** variable doesn't vary within the **SCHOOL** cluster.). 


### Strategy 2: Use theoretical knowledge to guide you
Ask yourself or an expert to know more about the relation between two variables, if that relation changes within the cluster or not. For example, according to historic nutrition models, if we control the *age*, the relationship between *calorie consumption* and *weight loss* is exactly same for all individuals. However, in many cases using theory to decide if the slope will be fixed or random may not be possible.


### Strategy 3: Model comparison
To explicitly test whether those effects should be fixed or random, we can compare the models with and without using the specific variable of interest as full model and reduced model. For example, in full model below, SES varies by school (random effect), but in reduced model SES did not vary by school (fixed effect).

![](fig/04_mixed_effects_model_comparison.png)
Here are some decision criteria based on this model comparison output:

- Decision 1: Because $p > 0.05$, there is no statistically significant difference between the full and reduced models, so we can use the reduced model.
- Decision 2: Because the Bayes Factor $> 10$ for reduced model, we can choose the reduced model. 
- Decision 3: The AIC and BIC give mixed results. The reduced model has lower BIC but higher AIC when compared to the full model. However, considering the "decisions" we made based on the $p$-value and Bayes Factor, we still choose the reduced model. 


## How to do the analysis?


### Packages for the following Lesson
```{r}
#| message: false
# install.packages("Matrix")
# install.packages("MASS") 
library(gt)        # to make table outputs presentation/publication ready. 
library(broom)     # clean output.
library(knitr)     # to make tables. 
library(gtsummary) # extension to gt
library(lattice)   # It is a powerful data visualization for multivariate data
library(lme4)      # Fit linear and generalized linear mixed-effects models
library(arm)       # Data Analysis Using Regression and Multilevel models
library(tidyverse) # for cleaning wrangling data

```


### Data Source and Description
Let's do the analysis using the **Planktonic larval duration (PLD)** example! This example is from [O'Connor et al (2007)](https://www.jstor.org/stable/25426272). As a brief intro on this study, temperature is important for the development of organisms. In marine species, temperature is very important and linked to growth. We want to see the association between time of survival (duration/PLD) and the temperature. 

```{r}
#| message: false

PLD <- read_table("../data/04_PLD.txt")
```

Let's check the structure of this data and how it briefly looks.
```{r}
#| message: false

#strcuture 
str(PLD)

# just the top - seeing how it looks
head(PLD)

# brief summary
summary(PLD)
```

Let's check how this would look if we plot the variable `pld` or *planktonic larvae duration* and the temperature. So we can see how the temperature is associated with their survival duration.
```{r}
#| message: false

# how to plot in base R 
plot(pld ~ temp, data = PLD,
     xlab = "Temperature (C)",
     ylab = "PLD survival (Days)",
     pch = 16)
# add lm line in base R
abline(lm(pld ~ temp, data = PLD))

```


### Fit first model: Linear model
Let's first fit a linear model and check any assumptions. Why are we fitting a linear model first? It might be important to check the standard error of this model and compare to the next model, that might be a better fit later on.
```{r}
#| message: false

# fitting linear model first 

LinearModel_1 <- lm(pld ~ temp, data = PLD)

summary(LinearModel_1)
```

We can fit this output in a `gtsummary` to make it nicer looking:
```{r}
#| message: false

LinearModel_1 |> 
  tbl_regression()
  
```

We are interested in checking out visually, the equal variance (homoscedasticity) of residuals. So, we plot a base residual graph:
```{r}
#| message: false

# better to do a scatter plot 
LinearModel_res <- resid(LinearModel_1)

# plot residual 
plot(PLD$temp, LinearModel_res,
     ylab = "Residuals",
     xlab = "Temperature (C)",
     main = "Residual graph"
     )
abline(0,0)
```

Just upon visual observation, it seems like this assumption may be
violated, so we think it might be important to do some transformations.


### Log transformation
```{r}
#| message: false

LinearMode_2Log <- lm(log(pld) ~ temp, data = PLD)

summary(LinearMode_2Log)
```


### Residual of new log transformed graph
```{r}
#| message: false

# better to do a scatter plot 
LinearModel2_res <- resid(LinearMode_2Log)

# plot residual 
plot(PLD$temp, LinearModel2_res,
     ylab = "residuals",
     xlab = "temp",
     main = "Residual graph (log transformation)"
     )
abline(0,0)
```

A bit better! Now we want to see the original plot we plotted with PLD and temperature:
```{r}
#| message: false

plot(log(pld) ~ temp, data = PLD,
     xlab = "Temperature in C",
     ylab = "PLD in days")
abline(LinearMode_2Log)
```


### Check distribution by `phylum` 
In ggplot you can use the `facet_wrap()` function to separate by phylum:
```{r}
#| message: false

ggplot(data = PLD) +
  aes(x = temp, y = log(pld)) +
  geom_point() +
  labs(x = "temperature, C",
       y = "Log(PLD)") + 
  stat_smooth(method = "lm", formula = "y ~ x", se = FALSE, fullrange = TRUE) +
  theme_classic() +
  facet_wrap(~ phylum)

```


### Fitting the mixed model
We can use the library `lme4` to fit a log-transformed linear regression model
with **random intercepts and fixed slope**
```{r}
#| message: false

# creating log -transformed variables 
PLD$log_pld <- log(PLD$pld)

# mixed model with random intercepts and fixed slope
MixEfcModel <- lmer(log_pld ~ temp + (1 | phylum), data = PLD)

summary(MixEfcModel)

```

**Interpretation:**  For one unit increase in the degrees of temperature, there is a 0.057 unit decrease in Planktonic larval duration. (or, as the temperature increase, the plankton duration is lower.) We now check the coefficients for random intercepts and fixed slope of phylum cluster:
```{r}
coef(MixEfcModel)$phylum
```


### Add Mixed Effect Predictions
We first need to create a new data frame with these random intercepts and fixed slope. We create a new data frame `modelCoef_df`:
```{r}
modelCoef_df <- 
  coef(MixEfcModel)$phylum %>% 
  # to convert row names between an explicit column
  rownames_to_column(var = "phylum") %>% 
  rename(intercept = `(Intercept)`, slope = temp)

modelCoef_df
```

Now we create a prediction model data frame by adding the `modelCoef_df` with the prediction model to calculate the predicted values:
```{r}
pld_predicted_df <- 
  PLD %>% 
  left_join(y = modelCoef_df, by = "phylum") %>% 
  mutate(
    log_pld_pred = intercept + temp * slope
  )
```


### Plotting the prediction models 
```{r}
ggplot(data = pld_predicted_df) +
  theme_classic() +
  aes(x = temp) +
  labs(
    x = "temperature, C",
    y = "Log(PLD)"
  ) + 
  geom_point(aes(y = log_pld)) +
  geom_line(aes(y = log_pld_pred), color = "blue", size = 1) +
  facet_wrap(~ phylum)
```


## Interpretation

We can see in the predicted model, all slopes for within all phylum clusters are in the same line, showing it has fixed effect and random intercepts. You can compare it with the linear model figure and can see the differences of the slopes.


## Conclusion

In this lecture you learned about the definition and types of mixed effect model, when it is appropriate to use a random, fixed or mixed effect model, 
the difference between an ordinary single-level model, and a mixed effect model,
the assumptions of the random intercept model, hypothesis testing for the variation, testing coefficient, fitting prediction model and finally, how to interpret results from the fixed part and the random part of a random intercept model.


## References

1. Harrison XA, Donaldson L, Correa-Cano ME, Evans J, Fisher DN, Goodwin CED, Robinson BS, Hodgson DJ, Inger R. A brief introduction to mixed effects modelling and multi-model inference in ecology. PeerJ. 2018 May 23;6:e4794. doi: 10.7717/peerj.4794. PMID: 29844961; PMCID: PMC5970551.

2. https://m-clark.github.io/mixed-models-with-R/random_intercepts.html

3. https://medium.com/@marc.jacobs012/introduction-to-mixed-models-in-r-9c017fd83a63

4. https://www.youtube.com/watch?v=c_tYZxQLoDA&list=PL8F480DgtpW9_IT7xN1XeRF_dglZmK0nM

5. https://www.youtube.com/watch?v=eVuQlGDZxHs&list=PL8F480DgtpW9_IT7xN1XeRF_dglZmK0nM&index=2

6.  supplementary material for Tom Snijders and Roel Bosker textbook - Shjders, T Bosker R, 1999. *Multilevel analysis: an introduction to basic and advanced mltilevel modeling,* London, Sage, including updates and corrections data set examples <http://stat.gamma.rug.nl/multilevel.htm>

7.  University of Bristol, Random Intercept model, (2018). <http://www.bristol.ac.uk/cmm/learning/videos/random-intercepts.html>

8. Midway, S. (2019). "Data Analysis in R." <https://bookdown.org/steve_midway/DAR/random-effects.html>


