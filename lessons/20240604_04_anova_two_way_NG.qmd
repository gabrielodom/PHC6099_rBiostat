---
title: "Two-Way ANOVA"
author: "Patrice Lewis, Julissa Martinez, & Natalie Goulett"
date: "`r Sys.Date()`"
toc: true
number-sections: true
format: html
embed-resources: false
---



## Purpose

A two-way ANOVA examines the influence of two or more independent categorical variables, also known as **factors**, on a continuous dependent variable. Each factor must have at least two **levels**, which are the categories within each factor being analyzed. In this chapter, we will see an example of how to test for these assumptions and how to conduct a two-way ANOVA test once we know they have been met.

An **interaction** occurs when the effect of one factor depends on the level of another factor. The two-way ANOVA method allows us to measure:

1. **Main Effects** - the individual effect of one factor on the dependent variable, and

2. **Interaction Effects** - the extent to which the effects of one factor changes across different levels of another factor.



## How does a two-way ANOVA work?

The F test, a group-wise comparison test, is used in an ANOVA to determine statistical significance. The outcome of an F test, the *F* statistic, measures how different the two groups' variances are to the overall variance of the dependent variable. When the variance is higher between the groups than within the groups, the *F* statistic will be greater. A large *F* statistic suggests there's a low likelihood that the observed difference is due to chance, and thus, it is likely that the independent variable(s) have an effect on the outcome.

For comparison, a critical value is calculated based on the desired alpha (α) and degrees of freedom of all groups. If the *F* statistic is greater than the *F* critical value, the results are considered statistically significant. For example, if the *F* statistic is greater than the *F* critical value at α = 0.05, then the p-value will be less than 0.05.


:::{.callout-tip}
## Hypotheses

There are three null hypotheses that can be tested by a two-way ANOVA:

-   H0~1~: *The population means of the first factor are equal.*

-   H0~2~: *The population means of the second factor are equal.*

-   H0~3~: *There is no interaction effect, that is, the effect of one independent variable does not depend on the value of the other independent variable.*
:::

### Assumptions

Three assumptions must be met before conducting a two-way ANOVA:

-   *Homogeneity of variance:* The variances for each group should be roughly equal. If the groups do not have equal variances, a non-parametric test, such as the Kruskal-Wallis test, may be used.

-   *Independence of observations:* The observations in each group are independent of each other and the observations within groups were obtained by a random sample. This can be assumed to be true so long as the experiment is properly designed.

Furthermore, the observations of the dependent variable must be unique, not grouped within categories. If observations are grouped, this effect should be accounted for with the use of a blocking variable or a repeated-measures ANOVA.

-   *Normally distributed dependent variable:* The values of the dependent variable should follow a normal distribution.



## Two-Way ANOVA Table

The following table includes the calculations used in a two-way ANOVA. For more detailed information on these calculations, please read [Models and Calculations for the Two-Way ANOVA]( https://www.itl.nist.gov/div898/handbook/prc/section4/prc438.htm), a lesson by the National Institute of Standards and Technology.

***explain k , N is total sample size
factor a has k groups, factor b has l groups 

| Source of Variation | Sum of Squares | Degrees of freedom | Mean Squares | F value  |
|---------------------|----------------|--------------------|--------------|----------|
| Factor A            | $SS_A$         | $k-1$              | $MS_A$       | $F_A$    |
| Factor B            | $SS_B$         | $l-1$              | $MS_B$       | $F_B$    |
| Interaction AB      | $SS_{AB}$      | $(k-1)(l-1)$       | $MS_{AB}$    | $F_{AB}$ |
| Error               | $SS_E$         | $N - kl$           | $MS_E$       |          |
| Total               | $SS_T$         | $N-1$              |              |          |

Where

1. $$ MS_E := \frac{SS_E}{N-kl} $$
2. $$ MS_A := \frac{SS_A}{k-1} \text{ and } F_A := \frac{MS_A}{MS_E} $$
3. $$ MS_B := \frac{SS_B}{l-1} \text{ and } F_B := \frac{MS_B}{MS_E} $$
4. $$ MS_{AB} := \frac{SS_{AB}}{(k-1)(l-1)} \text{ and } F_{AB} := \frac{MS_{AB}}{MS_E} $$

We explain these components as:  

-   $SS_A$: Factor $A$ main effect sums of squares, df = $k-1$
-   $SS_B$: Factor $B$ main effect sums of squares, df = $l-1$
-   $SS_{AB}$: interaction sum of squares, df = $(k-1)(l-1)$
-   $SS_E$: error sum of squares, df = $N-kl$
-   $SS_T$: Total sums of squares, df = $N-1$



## Crop Yield Two-Way ANOVA Example

***move to top:
The following two-way ANOVA example is based on the [Two-Way ANOVA lesson](https://www.scribbr.com/statistics/two-way-anova/) by Rebecca Bevans. We will use the agricultural crop yield dataset from this lesson in our example, which can be directly downloaded [here](https://www.scribbr.com/wp-content/uploads//2020/03/crop.data_.anova_.zip).

In this example, corn crops were planted in one of four blocks within a field, in either high or low density, and fertilized with one of three types of fertilizer. Their yield in bushels was then measured. The three factors of this experiment with their associated levels are:

1.  Type of fertilizer (type 1, 2, or 3)
2.  Planting density (1 = low, 2 = high)
3.  Block number in the field (block 1, 2, 3, or 4)


### Hypotheses

Suppose we want to use a two-way ANOVA to examine whether the type of fertilizer and planting density (factors) have an effect on the average crop yield (dependent variable). To answer this question, the following three hypotheses will be tested:

:::{.callout-tip}
## Null Hypotheses

-   H0~1~: *Fertilizer type has no effect on average crop yield*

-   H0~2~: *Planting density has no effect on average crop yield*

-   H0~3~: *The effects of fertilizer type and planting density on average yield are independent of each other (no interaction exists)*
:::

:::{.callout-tip}
## Alternative Hypotheses

-   H1~1~: *Fertilizer type has an effect on average crop yield*

-   H1~2~: *Planting density has an effect on average crop yield*

-   H1~3~: *The effects of fertilizer type and planting density on average yield are not independent of each other (no interaction occurs)*
:::

### Loading Libraries and Data

First, we will load the `tidyverse`, `gt`, `tidymodels`, `AICcmodavg`, and `ggplot2` packages and read in the crop yield dataset:
*** explain what packages are and why we will use them
```{r setup-data-download}
#| warning: false

# Uncomment the following code to install required packages

#   The gt and tidymodels packages were used to make a presentation-ready table:
# install.packages("gt")
# install.packages("tidymodels")
#   The AIC package was used to create AIC table to compare all three models:
# install.packages("AICcmodavg")
#   The tidyverse package was used to harmonize the data:
# install.packages("tidyverse")

# Load the required packages
library(gt)
library(tidymodels)
library(AICcmodavg)
library(tidyverse)

# read in the crop data dataset downloaded from
# https://www.scribbr.com/wp-content/uploads//2020/03/crop.data_.anova_.zip
crop_data_df <- read_csv("data/04_crop_data.csv")

```

### Transform Treatment Factors into R Factors
```{r}
#| label: trans-to-factor

# converting into a factor 
crop_data_df$fertilizer <- as.factor(crop_data_df$fertilizer)
crop_data_df$density <- as.factor(crop_data_df$density)
```


### Data Exploration

The first few datapoints of the crop yield dataset were inspected and summary statistics were performed on the entire dataset to examine the structure, center, and spread of the data.
```{r data-exploring}
#*** is the above a chunk label, or should each chunk also have `#| label:`? wow
# the comment turned blue that's crazy
#| warning: false
#*** why set code-fold to false? do we not want to see this part?

# show first six rows of the dataset
head(crop_data_df)

# overview of summary statistics
summary(crop_data_df)

```

#### Boxplots of Factors

Box plots for each factor were created to further examine the spread and center of the data using ggplot. The data for each factor appear to be approximately normally distributed with few outliers.
```{r box-plot}

# Plotting Crop Yield by Fertilizer
plot_fertilizer <- 
  ggplot(data = crop_data_df) +
    aes(
      x = as.factor(fertilizer),
      y = yield,
      color = as.factor(fertilizer) 
    ) +
  labs(
    title = "Crop Yield by Fertilizer Type",
    x = "Fertilizer Type",
    y = "Crop Yield"
  ) +
  geom_boxplot()

plot_fertilizer

# Plotting Crop Yield by Density
plot_density <- 
  ggplot(data = crop_data_df) +
    aes(
      x = as.factor(density),
      y = yield,
      color = as.factor(density)
    ) +
  labs(
    title = "Crop Yield by Planting Density",
    x = "Planting Density",
    y = "Crop Yield"
  ) +
  geom_boxplot()

plot_density

# Plotting Crop Yield by Block
plot_block <- 
  ggplot(data = crop_data_df) +
    aes(
      x = as.factor(block),
      y = yield,
      color = as.factor(block) 
    ) +
  labs(
    title = "Crop Yield by Block",
    x = "Block",
    y = "Crop Yield"
  ) +
  geom_boxplot()

plot_block

```

#### Combined Boxplot of Crop Yield by Fertilizer and Density

To help visualize the data, a box plot visualizing the effects of fertilizer and density on average crop yield was created. The y-axis indicates the average crop yield. The x-axis is divided by fertilizer type (labeled at the top of the graph) and indicates the planting density for each level of the fertilizer factor.

```{r crop-data-plot}

#***why do the colors, legend, and x-axis breaks change when I relocate this 
#   chunk (it was previously last)? I didn't make changes to this code, only 
#   the formatting - Does it look good, or should geom_point() be inside 
#   ggplot()?.
#   Is it because of the gt package?

anova_plot <- 
  ggplot(crop_data_df) +
  aes(
    x = density, 
    y = yield, 
    group = fertilizer,
    color = fertilizer
  ) +
  geom_point(
    cex = 1.5, 
    pch = 1.0, 
    position = position_jitter(w = 0.1, h = 0.1)
  )

anova_plot <- anova_plot + 
# summarize y values at unique x values
# *** does this create error bars using mean_se?
  stat_summary(
# calculate mean and se using mean_se function
    fun.data = 'mean_se',
    geom = 'errorbar',
    width = 0.2,
    color = "grey50"
  ) +
  stat_summary(
    fun.data = 'mean_se',
# ***why again?
    geom = 'pointrange'
  )

anova_plot <- anova_plot +
  facet_wrap(~ fertilizer)

anova_plot <- anova_plot +
  theme_classic() +
  labs(
    title = "Crop Yield Averages by Fertilizer Types and Planting Density",
    x = "Planting Density (1 = low density, 2 = high density)",
    y = "Average Yield"
  )

anova_plot

```

The differing spread of the box plots for each level of the two factors suggests that the factors have an effect on average yield. Before we can test whether these potential effects are statistically significant, we must first check that the data meet the ANOVA assumptions. To do this, we will generate a two-way ANOVA and run diagnostics on the model.



## Performing the Two-Way ANOVA with Interaction and Blocking Variables

Recall that the two-way ANOVA can account for more than two factors. The crops were planted across various `blocks` whose conditions may differ in terms sunlight, moisture, etc. This could possibly lead to confounding, so it is important to control for the possible effect of these differences between blocks by adding this third factor to our model.

A two-way ANOVA was created to model the effects of fertilizer, density, the interaction between fertilizer and density, and the blocking factor. In the following code, the argument `fertilizer * density` is equivalent to `fertilizer + density + fertilizer : density`, where `fertilizer : density` represents the interaction term.

:::{.callout-warning}
## Are your data balanced?

Because the crop data are **balanced** (the sample sizes across the levels within each factor are equal), we will use the base-R function `aov()`, which uses Type I sums of squares. If your data are **unbalanced**, use a Type II ANOVA (for data with no significant interaction) or Type III ANOVA (for data with significant interaction) to ensure your results have the highest possible power.
:::

```{r two-way-ANOVA-with-interaction-and-blocking}

# performing two-way anova with interaction and blocking
blocking <- 
  aov(yield ~ fertilizer * density + block, data = crop_data_df)

```



### Checking ANOVA Assumptions

We will now create diagnostic plots, which include a **residuals vs fitted plot, scale-location plot, Q-Q plot,** and **constant leverage plot**, to evaluate the normality and homoscedasticity of our data. Please read [Understanding Diagnostic Plots for Linear Regression Analysis](https://library.virginia.edu/data/articles/diagnostic-plots) for more information on diagnostic plots.

```{r Assumption-check}

# ***why do we create the ANOVA before checking assumptions? Shouldn't we
#   check the data before, and if so, how? I did check the literature - some 
#   tutorials do the ANOVA first, some don't. Is the current format okay?
# ***how can I tell which plot() function is used here? how does R know to make
#   these specific diagnostic plots?

# set plot parameter to display 2 x 2 pictures on one plot
par(mfrow=c(2,2))
plot(blocking)
# set plot parameter back to 1 x 1 format
par(mfrow=c(1,1))

```

The **residual vs fitted plot** shows the data are randomly spread about the "0" line with no large outliers, so we can assume the factors have equal variances. Similarly, the **scale-location plot** shows an approximately horizontal line with randomly spread points, indicating equal variances. Thus, the homoscedasticity assumption is met.

The points of the **Q-Q residuals plot** roughly follow the reference line, indicating the data are normally distributed.

The **constant leverage plot** displays a horizontal "0" value line with points randomly spread around it, indicating the spread of the points are the same at different levels. No points lie outside of the critical value lines (not visible in the graph due to scale), indicating no outliers exist that could skew the data.


### Two-way ANOVA - FUll Model Interpretation

Now that we have verified that the data satisfy the ANOVA assumptions, we may conduct the two-way ANOVA to test the hypotheses. Let's interpret the results of the ANOVA of the full model:

```{r two-way-ANOVA-with-interaction-and-blocking-results}

# creating a tidy table of full model using gt 
table_block <- blocking %>% 
#*** why do we do tidy table on blocking ANOVA object? to make a table obv
# but why this?
  tidy() %>% 
  gt()

# customizing gt table header
table_block |>
   tab_header(
      title = "Two-Way ANOVA of Crop Yield - Full Model",
      subtitle = "by fertilizer, density, fertilizer:density interaction, and blocking variable"
    )

```

For the block variable, the sum of squares is low and the p value of p = 0.23 is not significant at the α = 0.05 level. Hence, the block variable does not have a statistically significant effect on the crop yield. Because it does not add information to the model, it should be removed from the final model.


### Two-way ANOVA - Density + Fertilizer + Interaction

We will now run a two-way ANOVA on a new model using the density, fertilizer, and interaction variables to investigate whether these terms are significant.

```{r Two-way-ANOVA-with-interaction-results}

# performing the two-way ANOVA with interaction
interaction <- 
# fertilizer * density = fertilizer + density + fertilizer:density
  aov(yield ~ fertilizer * density, data = crop_data_df)

# creating a tidy table using gt
table_int <- interaction %>%
  tidy() %>% 
  gt()

# customizing table header
table_int |>
   tab_header(
      title = "Two-way ANOVA of Crop Yield with Interaction",
      subtitle = "by fertilizer, density, and fertilizer:density interaction"
    )

```

The p value for the interaction term is greater than 0.05, hence we fail to reject the null hypothesis (H0~3~) and conclude that there is no statistically significant interaction effect between fertilizer type and crop density on average yield. The interaction term should also be removed from the model.


### Two-way ANOVA - Density + Fertilizer

Because the interaction term was not significant, we will remove it from our model and perform a two-way ANOVA on a model with only the density and fertilizer factors.

```{r Two-way-ANOVA-without-interaction-results}

# performing the two-way ANOVA without the interaction term
two_way <- 
  aov(yield ~ fertilizer + density, data = crop_data_df)

# creating a tidy two-way ANOVA table using gt
table_1 <- two_way %>% 
  tidy() %>% 
  gt()

# customizing table header
table_1 |>
   tab_header(
      title = "Two-Way ANOVA of Crop Yield Without Interaction",
      subtitle = "by fertilizer and density"
    )

```

Without the interaction term, we see that the p values for both fertilizer type and planting density are significant at the α = 0.05 level. Thus, we reject null hypotheses H0~1~ and H0~2~ and conclude that both fertilizer and density have a statistically significant main effect on crop yield.



## Determining the Best-Fitting Model using AIC

The Akaike information criterion (AIC) is another method that can be used to determine the best model that best fits the data. The model that explains the greatest amount of the variation in the data using the fewest possible independent variables is considered the best-fitting model. The lower the AIC value, the more variation is explained by the model.

```{r}

# creating a list of models to compare and their respective names
model_set <- list(two_way, interaction, blocking)
model_names <- c("two_way", "interaction", "blocking")

# using AICtab to compare models 
gt_fmt <-
  aictab(model_set, modnames = model_names) 

# create gt table using AIC
gt_print <- 
  gt(gt_fmt)

gt_print

```

As shown in this table, the two_way model, which only includes the fertilizer and density variables without their interaction term, has the lowest AIC and is therefore the best fit for our crop data analysis.



## Post-Hoc Testing (Tukey HSD)

We now know which parameters are significant, however, we are also interested in learning how the levels of the factors differ from each other. To quantify these differences, the Tukey's Honestly-Significant-Difference test can be used.

```{r tukey-test}
# Performing Tukey HSD on the final model (yield ~ fertilizer + density)
tukey_crop <- TukeyHSD(two_way)  
  
tukey_crop %>% 
#***
  tidy %>% 
  gt() %>% 
  tab_header(
      title = "Tukey Multiple Comparisons of Means",
      subtitle = "for fertilizer and density"
  )

```

This table shows the pairwise differences between each level of the factors. Comparisons with p values less than 0.05 are considered significant:

-   fertilizer types 1 and 3
-   fertilizer types 2 and 3
-   planting density groups (binary)

To visualize the differences between the levels of each factor, the 95% family-wise confidence intervals of the pairs for fertilizer and density were plotted below. The x-axes of the plots display the difference in means between the paired levels. The y-axis denotes the pair being compared.

```{r tukey-plot}

# plot tukey confidence intervals and set tick marks to horizontal (las = 1)
#   position
plot(tukey_crop, las = 1)

```

Note that the significant confidence intervals do not include zero. From this plot, we see that only the fertilizer comparison of type 1 and 2 confidence interval includes 0. Thus, there is no statistically significant difference in the average crop yield produced by fertilizer 1 vs fertilizer 2. 95% family-wise confidence intervals for all other comparisons are statistically significant at the α = 0.05 level.



## Conclusions

There is a statistically significant difference in average crop yield by both the fertilizer type and planting density variables with F values of 9.018 (p \< 0.001) and 15.316 (p \< 0.001) respectively. The interaction between these two terms was not significant.

The Tukey post-hoc test showed significant pairwise differences between fertilizer types 1 and 3, and 2 and 3. It also depicted significant differences between the two types of planting densities (low and high).
