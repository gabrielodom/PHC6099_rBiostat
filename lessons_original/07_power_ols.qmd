---
title: "Power Analysis for OLS Regression"
author: "Lea Nehme and Zhayda Reilly"
date: "July 27, 2023"
toc: true
number-sections: true
format: html
embed-resources: false

bibliography: [bib/07_power_ols_references.bib, bib/packages.bib]
csl: bib/the-new-england-journal-of-medicine.csl
---

```{r}
#| label: tidyverse
#| echo: false

library(conflicted)
conflict_prefer("filter", "dplyr", quiet = TRUE)
conflict_prefer("lag", "dplyr", quiet = TRUE)

suppressPackageStartupMessages(library(tidyverse))

# suppress "`summarise()` has grouped output by " messages
options(dplyr.summarise.inform = FALSE)

```

```{r}
#| label: libraries

#install.packages("pwr")
library(pwr)
#install.packages("WebPower")
library(WebPower)
library(pwrss)
library(tidyverse)
```

## Introduction

The power of a hypothesis test is the probability of correctly rejecting
the null hypothesis or the probability that the test will correctly
support the alternative hypothesis (detecting an effect when there
actually is one) [@cohen1988]. Then,

-   High power: large chance of a test detecting a true effect.
-   Low power: test only has a small chance of detecting a true effect
    or that the results are likely to be distorted by random and
    systematic error.

$$
Power = 1-\beta
$$

Where, $\beta$ = probability of committing a Type II Error (the
probability that we would accept the null hypothesis even if the
alternative hypothesis is actually true). Then, by decreasing $\beta$
power increases \[\@(pdf)ef\].

![Visual view of beta](07_power_ols_beta.png)

Power is mainly influenced by sample size, effect size, and significance
level.

## Power Analysis: OLS Regression

For this power analysis we will use the univariate (simple) OLS
regression example of our last presentation examining the relationship
between a vehicle's weight (WT) and its miles per gallon or fuel
efficiency (MPG).

When performed, the paired correlation provided us with a pearson's
correlation coefficient of r(30) = -.868, p\<0.05, (n = 32). When we ran
this regression we got an ($R^2$ = .75) Therefore for the r2 value
(effect size) for a power analysis we will begin with an r2 value of .75
and an n = 32 to account for the observations already collected.
However, the power analysis should occur before collecting samples so
that we can have an appropriate number of observations required for our
hypothesized effect size. In our example, we are also assuming that the
variables are normally distributed. Based on our correlation analysis,
weight likely needs a cubic transformation, This would mean that our
model would have three coefficients of interest.

Formula for a univariate Ordinary Least Squares (OLS) Regression:

$$
\hat{y}_i = \beta_0 + \beta_1x_i
$$

The OLS regression model line for our example is:

$$
\widehat{MPG_i} = \beta_0 +\beta_1*WT_i
$$

Using an alpha value of $\alpha$ = .05 (The probability of a type I
error/rejecting a correct $H_0$, we will identify the number of
observations or sample size (n) necessary to obtain statistical power
(80% or $\beta$ = 0.20) given various effect sizes. Statistical power in
our example identifies the likelihood that a univariate OLS will detect
an effect of a certain size if there is one.

A power analysis is made up of four main components. We will provide
estimates for any three of these, as the following functions in r
calculate the fourth component.

We found three functions in r to conduct power analyses for an OLS
regression:

1.  The `pwrss.f.reg` function in the `pwrss` package
2.  The `pwr.f2.test` function in the `pwr` package
3.  The `wp.regression` function in the `WebPower` package

### The `pwrss.f.reg` function

We will start our power analysis using the The `pwrss.f.reg` function
for one predictor in an OLS regression, with our given observations of n
= 32 and $R^2$ = .75. Given these values, we are expecting that one
variable (WT) explains 75% of the variance in the outcome or Miles per
gallon (R2=0.75 or r2 = 0.75 in the code) [@apracti].

```{r}
#| label: pwrss.f.reg for MPG
#| code-fold: false
#| echo: true

RegOne_lm <- pwrss.f.reg(
  r2 = 0.75,
  k = 1,
  n = 32,
  power = NULL,
  alpha = 0.05
)
RegOne_lm$power
```

Given the information provided, we get 100% power. Our effect size of r2
= 0.75 is considered a large effect provided the following guidelines by
Cohen (1988) [@cohen1988a]

$f^2$ = 0.02 indicates a small effect;

$f^2$ = 0.15 indicates a medium effect;

$f^2$ = 0.35 indicates a large effect.

We will use these guidelines to continue our exploration. We will
concentrate on a fixed medium effect size. Where, the paired correlation
is approximately r = .40 for a medium correlation and for an $f^2$ or
effect size of 0.15. using this fixed effect, we will look at various
sample sizes to obtain power of 80% or greater given a medium effect
size. In our sequence of possible sample sizes, the minimum n = 1 as n
\> p(p+1)/2 = 1(2)/2 = 1

```{r}
#| label: pwrss.f.reg with fixed effect size
#| code-fold: false
#| echo: true

OLSReg_df <- tibble(n = seq.int(from = 2, to = 99 + 2))

OLSReg_df$power <- map_dbl(
  .x = OLSReg_df$n,
  .f = ~{
    out_ls <- pwrss.f.reg(
      # "Effect size" of a linear model
      r2 = 0.15,
      # number of predictors
      k = 1,
      # sample size
      n = .x,
      power = NULL,
      alpha = 0.05,
      # Stop printing messages
      verbose = FALSE
    )
    out_ls$power
  }
)
```

The following is the power curve for a fixed effect of f2 = 0.15

```{r}
#| label: graph of pwrss.f.reg with fixed effect size
#| code-fold: false
#| echo: true
ggplot(data = OLSReg_df) +
  theme_bw() +
  aes(x = n, y = power) +
  labs(
    title = "Omnibus (F-test) Power for Linear Model",
    subtitle = "Fixed Effect Size R2 = 0.15, 1 Predictor"
  ) +
  scale_y_continuous(limits = c(0, 1)) +
  geom_point() +
  geom_abline(slope = 0, intercept = 0.8, colour = "gold")

```

Given the graph, we notice that we need an approximate sample size or n
of close to 50 to detect a medium effect size in an OLS Regression.

The following is a power analysis for a univariate OLS regression given
a fixed sample size. We will create a sequence of effect sizes that
capture Cohen's guidelines as well as the effect size of 0.75 of our
sample regression. Our fixed n will be n = 32 as the sample.

```{r}
#| label: pwrss.f.reg with fixed sample size
#| code-fold: false
#| echo: true
OLSRegN_df <- tibble(R2 = seq(0, 0.75, length.out = 100))

OLSRegN_df$power <- map_dbl(
  .x = OLSRegN_df$R2,
  .f = ~{
    out2_ls <- pwrss.f.reg(
      # "Effect size" of a linear model
      r2 = .x,
      # number of predictors
      k = 1,
      # sample size
      n = 32,
      power = NULL,
      alpha = 0.05,
      # Stop printing messages
      verbose = FALSE
    )
    out2_ls$power
  }
)
```

The following is the power curve for a fixed sample size of n = 32

```{r}
#| label: graph of pwrss.f.reg with fixed sample size
#| code-fold: false
#| echo: true

ggplot(data = OLSRegN_df) +
  theme_bw() +
  aes(x = R2, y = power) +
  labs(
    title = "Omnibus (F-test) Power for Linear Model",
    subtitle = "Fixed Sample Size = 32, 1 Predictor"
  ) +
  scale_y_continuous(limits = c(0, 1)) +
  geom_point() +
  geom_abline(slope = 0, intercept = 0.8, colour = "red")

```

Given the graph, we notice that given n = 32, a power of 80% and higher
is achieved when the effect size is at least approximately r2 = 0.20.

### The `pwr.f2.test` function

Power analysis using the `pwr.f2.test`: where, u = 1, The F numerator
degrees of freedom (u=1) or the number of coefficients(independent
variables) in the model

and we will use Cohen's criteria for effect sizes and first provide
analyses for a medium effect size of 0.15
[@cohen1988a][@powerin][@statistia]

```{r}
#| label: power analysis using pwr.f2.test (fixed es)
#| code-fold: false
#| echo: true

# Using Cohen 1988 criteria, where, 
#f2 = 0.02 small effect;
#f2 = 0.15 medium effect;
#f2 = 0.35 indicates a large effect

### Fixed Effect size f2 = 0.15###
# n = 50
pwr.f2.test(
  u = 1, 
  v = 50 - 1 - 1,
  f2 = .15, 
  sig.level = 0.05, 
  power = NULL
  )
# n = 25
pwr.f2.test(
  u = 1, 
  v = 25 - 1 - 1,
  f2 = 0.15, 
  sig.level = 0.05, 
  power = NULL
  )
# n = 12
pwr.f2.test(
  u = 1, 
  v = 12 - 1 - 1,
  f2 = 0.15, 
  sig.level = 0.05, 
  power = NULL
  )
```

Now, we will explore a fixed n = 32

```{r}
#| label: power analysis using pwr.f2.test (fixed n)
#| code-fold: false
#| echo: true
# ES = .02, r = .14
pwr.f2.test(
  u = 1, 
  v = 32 - 1 - 1,
  f2 = .02, 
  sig.level = 0.05, 
  power = NULL
  )
# ES = 0.15, r = .39
pwr.f2.test(
  u = 1, 
  v = 32 - 1 - 1,
  f2 = 0.15, 
  sig.level = 0.05, 
  power = NULL
  ) 
# ES = .35, r = .59
pwr.f2.test(
  u = 1, 
  v = 32 - 1 - 1,
  f2 = 0.35, 
  sig.level = 0.05, 
  power = NULL
  )
```

We will now look at the 3 types of effect sizes given various sample
sizes

```{r}
#| label: power analysis using pwr.f2.test (various)
#| code-fold: false
#| echo: true
effect_sizes <- c(0.02, 0.15, 0.35) 
sample_sizes = seq(20, 100, 20)

input_df <- crossing(effect_sizes,sample_sizes)
glimpse(input_df)

get_power <- function(df){
  power_result <- pwr.f2.test(
    u = 1,
    v = df$sample_sizes - 1 - 1, 
    f2 = df$effect_sizes,
    )
  df$power=power_result$power
  return(df)
}

# run get_power for each combination of effect size 
# and sample size

power_curves <- input_df %>%
  do(get_power(.)) %>%
  mutate(effect_sizes = as.factor(effect_sizes)) 


ggplot(power_curves, 
       aes(x=sample_sizes,
           y=power, 
           color=effect_sizes)
       ) + 
  geom_line() + 
  geom_hline(yintercept = 0.8, 
             linetype='dotdash',
             color = "purple")

```

Based on the graph, if we have an effect size of 0.15, we need
approximately 50 or more observations (recall n = v + 1 + 1)

### The `wp.regression` function

Lastly, we use the `wp.regression` function to examine the appropriate
sample size given an effect size of 0.15 to achieve a power of 80% or
higher [@zhang2017][@wp.regre]

```{r}
#| label: power using wp.regression, fixed es
#| code-fold: false
#| echo: true

# Using webpower 
#p1 = 1
### Fixed ES = 0.15 ###
res <- wp.regression(n = seq(20,100,20), 
                     p1 = 1, 
                     f2 = 0.15, 
                     alpha = 0.05, 
                     power = NULL
                    )
res
plot(res,  main = "Fixed Effect Size = 0.15")+
abline(a = .80, b = 0, col = 'steelblue', lwd = 3, lty = 2)

```

The results are similar to the previous functions. However, in this
function, given an effect size of 0.15, we need an n of close to 60 to
achieve 80% power.

```{r}
#| label: power using wp.regression fixed n
#| code-fold: false
#| echo: true

# Using webpower 
#p1 = 1
### Fixed n = 50 ###
res <- wp.regression(n = 50, 
                     p1 = 1, 
                     f2 = seq(0.00, 0.35, 0.05), 
                     alpha = 0.05, 
                     power = NULL
                    )
res
```


## References {.unnumbered}
