[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHC 6099: R Computing for Health Sciences",
    "section": "",
    "text": "These are the written lecture materials for the class PHC 6099 at Florida International University’s Stempel College of Public Health. This is the second semester of the “R” course sequence (the first semester is PHC6701; the text for that class is available here: https://gabrielodom.github.io/PHC6701_r4ds/) The source code and data sets for this book are available here: https://github.com/gabrielodom/PHC6099_rBiostat."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "lessons_original/01_ggplot2.html",
    "href": "lessons_original/01_ggplot2.html",
    "title": "How to create a scatterplot",
    "section": "",
    "text": "Scatterplots display the relationship between two variables using dots to represent the values for each numeric variable. This presentation will examine the relationship between GDP per capita and Fertility over time using ggplot with facets.\nHypothesis: A negative relationship exists between GDP per capita and fertility i.e. as GDP per capita increases, fertility decreases."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#introduction",
    "href": "lessons_original/01_ggplot2.html#introduction",
    "title": "How to create a scatterplot",
    "section": "",
    "text": "Scatterplots display the relationship between two variables using dots to represent the values for each numeric variable. This presentation will examine the relationship between GDP per capita and Fertility over time using ggplot with facets.\nHypothesis: A negative relationship exists between GDP per capita and fertility i.e. as GDP per capita increases, fertility decreases."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#data",
    "href": "lessons_original/01_ggplot2.html#data",
    "title": "How to create a scatterplot",
    "section": "Data",
    "text": "Data\nData was obtained from GapMinder for each health and non-health indicator and combined into one data set. The data includes information on over 180 countries and territories from the years 1800 to 2099. Countries and territories with missing information were not excluded from the data set as the lack of information can also be looked into and shed light on why data was not collected or provided.\nTo determine whether a country’s health and income outcomes are influenced by population sizes and GDP per capita, the data will be used to create a series of graphs to view different trends. It is important to note certain analysis’ will only be done on specific countries and on certain years. Predictive values were provided up until 2099 however, we will focus on years with full and current data.\n\n\nCode\n# Contains colour palette for ggplot\nlibrary(viridis)\n\n# Contains \"gganimate\"\nlibrary(ggplot2)\nlibrary(gganimate)\n\nlibrary(tidyverse)\n\n\n# Reads csv file\ngapminder_data &lt;-  \n  # read_csv(\"clean_data/gapminder_scatterplot.csv\")\n  read_csv(\"../data/gapminder_2024spring.csv\")"
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#how-to-create-a-scatter-plot",
    "href": "lessons_original/01_ggplot2.html#how-to-create-a-scatter-plot",
    "title": "How to create a scatterplot",
    "section": "How to create a scatter-plot",
    "text": "How to create a scatter-plot\n\nIntro to ggplot2\nGgplot2 is a package used to create graphs and visualize data. The main three components of ggplot2 are the data, aesthetics and geom layers.\n\nThe data layer - states what data will be used to graph\nThe aesthetics layer - specifies the variables that are being mapped\nThe geom layer - specifies the type of graph to be produced\n\n\n\n\n\n\n\n\nBasic scatter-plot using ggplot2\nIn order to create a scatter-plot using ggplot, you must specify what data you will be using, state which variables will be mapped and how under aesthetics. What differentiates the scatter-plot from any other type of graph will be specified under the geom layer. For the scatter-plot, geom_point will be used.\nIn this example, we will analyze the relationship between fertility rates and gdp per capita for each country in 2011.\n\nfig_bubble_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(x = gdp_per_capita, y = fertility) +\n  geom_point()\n\nfig_bubble_2011 \n\n\n\n\n\n\n\n\n\n\nElevating your scatter-plot\nIn the example above, we have mapped out fertility as our y-axis and gdp per capita as our x-axis. However, at it’s very basic level, there is not enough information provided to accurately analyze the relationship between the two. For this reason, we can add additional layers that will provide more information to properly analyze the scatter-plot.\n\n\nCode\nfig_bubble_pretty_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    # will change the size of the point based on population size \n    size = population, \n    # will assign colors based on the continent the country is in \n    color = continent\n  ) +\n  # gives a range as to how big or small the points of population should be\n  scale_size(range = c(1, 20)) + \n  # removes N/A from the legend and titles it Continent \n  scale_colour_discrete(na.translate = F, name = \"Continent\") +\n  # removes population size from the legend \n  guides(size = \"none\") +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    # transforms numbers from scientific notation to regular number \n    labels = scales::comma\n  ) +\n  labs(\n    title = \"Fertility rate descreases as GDP per capita increases in 2011\",\n    y = \"Fertility rates\",\n    caption = \"Source: Gapminder\"\n  ) +\n  # the ylim was set based on the fertility, lowest was 1.15 & highest was 7.25\n  ylim(1.2, 8.0) +\n  # alpha increases transparency of the points to ensure they can all be seen\n  geom_point(alpha = 0.5) \n\nfig_bubble_pretty_2011\n\n\n\n\n\n\n\n\n\n[@ggplot-2011-adv] builds on the previous scatterplot of Fertility Rates (y axis) against GDP per capita (x axis) for 2011. The bubble size depicts respective country populations, and continents are coded by colors according to the key. This figure displays a negative relationship between GDP per capita and Fertility Rates. It supports the Hypothesis which states that as GDP per capita increases, Fertility Rates decreases. This trend can be confirmed for all continents, however, the degree to which fertility rates drop between continents varies. Most European country appear below a fertility rate of 2 babies per woman. The Americas appear to follow closely behind (under 4), followed by Oceania and Asia. A significant number of African countries still maintained higher fertility rates with lower GDP per capita for 2011.\n\n\nFacets\nHere is an example of wanting to create four separate graphs to see the relationship between fertility rates and GDP per capita based on the years 1860, 1910, 1960 and 2010. In this example we omitted the facet argument.\n\n\nCode\nfig_bubble_multiple &lt;-\n  ggplot(data = filter(gapminder_data, year %in% c(1860, 1910, 1960, 2010))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE, name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    subtitle = \"throughout 1860, 1910, 1960 and 2010\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) \n\nfig_bubble_multiple\n\n\n\n\n\n\n\n\n\nWithout having used the facet argument, all points of all four years have been included into one graph. This graph does not provide us with the information we were looking for.\n\n\nCode\nfig_bubble_multiple_facet &lt;-\n  ggplot(data = filter(gapminder_data, year %in% c(1860, 1910, 1960, 2010))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE , name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    subtitle = \"throughout 1860, 1910, 1960 and 2010\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) +\n  # specifiying we want the graphs split based on year\n  facet_wrap(~ year)\n\nfig_bubble_multiple_facet\n\n\n\n\n\n\n\n\n\nNow that we’ve specified the facet argument, we now have four seperate graphs that can be properly analysed. In [@ggplot-facet-years] we see an increasingly negative relationship between the two variables over time. This observation is congruent with the hypothesis that as GDP per capita increases, fertility decreases.\nThis global trend can be attributed to the increasing proportion of women in the workforce in the mid to late 20th century. As a result of World War II (1939-1945), women took on roles outside the home to compensate for men at war. Despite increased GDP per capita, this may have contributed to reduced fertility (babies per woman) over time. During 1860 - 1910, the scatter-plot figures remained in the upper left quadrant with the numbers remaining between 2 - 8 babies per woman. In 1960, a clear disparity among continents is seen. Most European countries’ fertility rates fell below 5, while their GDP per capita increased. Most African countries maintained high fertility rates above 5, but little change is seen in GDP per capita. The Asian continent shows the most variation among countries during that year. Some smaller Asian countries continued to maintain high fertility rates as GDP per capita increased in 1960. However, others displayed a drastic decrease in fertility rates by 1960. The Americas followed a steady decline over the years. By 2010, an overall negative relationship can be seen with most countries’ fertility rates below 5 babies per woman.\n\nfig_bubble_row_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent, nrow = 1)\n\nfig_bubble_row_2011 \n\n\n\n\n\n\n\n\nIn the graph above, we see an example of seperating the single graph into graphs based on continent. It has also been specified to have all graphs appear in one single row through the nrow argument. However, this graph is also unclear and cannot be used to compare the relationship between fertility and gdp per capita.\n\nfig_bubble_facet_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent)\n\nfig_bubble_facet_2011 \n\n\n\n\n\n\n\n\nIn the next example above, we removed the nrow argument and the system automatically seperated the graphs into three columns with two rows. However, again, there is no way to clearly determine any relationship between fertility and gdp per capita."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#scatterplot-animation",
    "href": "lessons_original/01_ggplot2.html#scatterplot-animation",
    "title": "How to create a scatterplot",
    "section": "Scatterplot animation",
    "text": "Scatterplot animation\nGGplot2 contains the “gganimate” package that allows for animation of data. It enhances data visualization through real-time outputs. In this case the gapminder data will be filtered to 2011 and below (full data available).\n\n\nCode\ngapminder_df &lt;- \n  gapminder_data %&gt;% \n  # Excludes data beyond 2011 (last year with complete data)\n  filter(year &lt;= \"2011\")\n\nfig_animate &lt;- \n  ggplot(gapminder_df) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent \n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  # Assigns color palette \n  scale_color_viridis_d() +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  geom_point(show.legend = TRUE, alpha = 0.7) +\n  # Assigns the gganimate features\n  transition_time(year) +\n  ease_aes('linear', interval = 2.0) +\n  # Prints time of current frame\n  labs(title = \"Year: {frame_time}\", x = \"GDP per capita\", y = \"Fertility\")\n  \n\nfig_animate\n\n\nNULL\n\n\n@plot-animate depicts the changes between Fertility and GDP per capita as the years increase from 1799 to 2011 (last full data year). This allows real-time visualization of the decrease in fertility and increase in GDP per capita.\n\n\nCode\nfacet_animate &lt;- \n  ggplot(gapminder_df) +\n  aes(\n    x = gdp_per_capita, \n    y = fertility,\n    size = population, \n    colour = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  # Groups output by continents\n  facet_wrap(~continent) +\n  labs(\n    title = 'Year: {closest_state}', \n    x = 'GDP per capita', \n    y = 'fertility'\n  ) +\n  geom_point(alpha = 0.7, show.legend = TRUE) +\n  # Contains gganimate features\n  transition_states(year, transition_length = 3, state_length = 1) +\n  # Animation pattern, time between each state\n  ease_aes('linear', interval = 2.0)\n\nfacet_animate\n\n\nNULL\n\n\nIn @animate-facets, the ggplot data for various continents as time passes is shown to support the initial hypothesis."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#conclusion",
    "href": "lessons_original/01_ggplot2.html#conclusion",
    "title": "How to create a scatterplot",
    "section": "Conclusion",
    "text": "Conclusion\nA global negative trend is depicted between GDP per capita and fertility over time. Such changes were due to wars as well as social, cultural and economic changes that incentivize smaller families especially in Asian countries. Most European, American and Asian countries depicted significant decreases in fertility rates over time as GDP per capita increased. On the other hand, African countries remain in the top rank for fertility over the years. These differences are depicted in the population pyramid changes of developed vs developing countries. Public health policies can be tailored to incentivizing increased fertility in developed countries to ensure generation continuity, and effective family planning strategies in developing countries."
  },
  {
    "objectID": "lessons_original/01_rayshader.html",
    "href": "lessons_original/01_rayshader.html",
    "title": "R Rayshader Overview",
    "section": "",
    "text": "R rayshader is an R package that allows users to generate high-quality 3D maps, visualizations, and animations.\nrayshader also allows the user to translate ggplot2 objects into beautiful 3D data visualizations.\n\nTo install rayshader, you can use the following code in R:\n\n# remotes::install_github(\n#   \"tylermorganwall/rayshader\"\n# )\n\n# remotes::install_cran(\"rayrender\")"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#overview",
    "href": "lessons_original/01_rayshader.html#overview",
    "title": "R Rayshader Overview",
    "section": "",
    "text": "R rayshader is an R package that allows users to generate high-quality 3D maps, visualizations, and animations.\nrayshader also allows the user to translate ggplot2 objects into beautiful 3D data visualizations.\n\nTo install rayshader, you can use the following code in R:\n\n# remotes::install_github(\n#   \"tylermorganwall/rayshader\"\n# )\n\n# remotes::install_cran(\"rayrender\")"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#functions",
    "href": "lessons_original/01_rayshader.html#functions",
    "title": "R Rayshader Overview",
    "section": "Functions",
    "text": "Functions\n\nrayshader 0.35. 1 has 56 functions and 4 datasets\nseven functions related to mapping\nalso has functions to add water and generate overlays\nalso included are functions to add additional effects and information to 3D visualizations\nfunctions for converting rasters to matrices\nfunctions to display and save your visualizations\nrayshader has a function to generate 3D plots using ggplot2 objects"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#example",
    "href": "lessons_original/01_rayshader.html#example",
    "title": "R Rayshader Overview",
    "section": "Example",
    "text": "Example\nFirst we load all the required libraries. These libraries are required for various functions and operations used in creating 3D maps with rayshader.\n\nlibrary(rayshader)\nlibrary(rayrender) \nlibrary(reshape2)\nlibrary(tidyverse)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#example-1",
    "href": "lessons_original/01_rayshader.html#example-1",
    "title": "R Rayshader Overview",
    "section": "Example",
    "text": "Example\nThen, we download and load the data\n\n# Here, I load a map with the raster package.\nloadzip &lt;- tempfile() \n\ndownload.file(\"https://tylermw.com/data/dem_01.tif.zip\", loadzip)\n\nlocaltif &lt;- raster::raster(\n  unzip(loadzip, \"dem_01.tif\")\n)\n\nunlink(loadzip)\n\n# write_rds(localtif, \"../data/01_rayshader_eg_20240503.rds\")\n\nIn this code snippet, we create a temporary file (loadzip) to store the downloaded zip file from the specified URL. The download.file() function is used to download the file, and unzip() is used to extract the “dem_01.tif” file from the downloaded zip. Finally, we load the raster data into the localtif object."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#create-map",
    "href": "lessons_original/01_rayshader.html#create-map",
    "title": "R Rayshader Overview",
    "section": "Create Map",
    "text": "Create Map\nTo create a map first we need to convert this raster data file into a matrix using raster_to_matrix()\n\n#And convert it to a matrix:\nelmat &lt;- raster_to_matrix(localtif)\n\nLoading required package: raster\n\n\nLoading required package: sp\n\n\n\nAttaching package: 'raster'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nThen we use sphere_shade() and plot_map() to create our base map\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nHere, elmat is a matrix created from the raster data using the raster_to_matrix() function. sphere_shade() applies shading to the elevation matrix, giving it a 3D effect. The texture parameter specifies the type of texture to be applied. In this case, it uses the “desert” texture. Finally, plot_map() is used to display the shaded map."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#add-water-layer",
    "href": "lessons_original/01_rayshader.html#add-water-layer",
    "title": "R Rayshader Overview",
    "section": "Add Water Layer",
    "text": "Add Water Layer\nWe can add a water layer to the map using detect_water() and add_water()\n\n# detect_water and add_water adds a water layer to the map:\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nIn this code snippet, detect_water() function detects water areas in the elevation matrix. Then, add_water() adds a water layer to the map using the detected water areas. The color parameter specifies the color of the water. Finally, plot_map() is used to display the map with the water layer."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#add-shadow-layer",
    "href": "lessons_original/01_rayshader.html#add-shadow-layer",
    "title": "R Rayshader Overview",
    "section": "Add Shadow Layer",
    "text": "Add Shadow Layer\nWe can also add shadow layer in the map.\n\n# And here we add an ambient occlusion shadow layer, which models lighting\n#   from atmospheric scattering:\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  add_shadow(ray_shade(elmat), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat), 0) %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nHere, add_shadow() is used to add a shadow layer to the map. ray_shade() calculates shadows based on the elevation matrix (elmat). The zscale parameter controls the strength of the shadows. ambient_shade() generates ambient lighting for the map. The second parameter of add_shadow() specifies the opacity of the shadows. Finally, plot_map() displays the map with shadows."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#convert-to-3d",
    "href": "lessons_original/01_rayshader.html#convert-to-3d",
    "title": "R Rayshader Overview",
    "section": "Convert to 3D",
    "text": "Convert to 3D\nWe can convert this 2D map into 3D mapping using plot_3d() (by passing a texture map into the plot_3d function)\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  add_shadow(ray_shade(elmat, zscale = 3), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat), 0) %&gt;%\n  plot_3d(\n    elmat, zscale = 10, fov = 0, theta = 135,\n    zoom = 0.75, phi = 45, windowsize = c(1000, 800)\n  )\nSys.sleep(0.2)\nrender_snapshot()\n\n\n\n\n\n\n\n\nWe can add a scale bar, as well as a compass using render_scalebar() and render_compass()\n\nrender_camera(fov = 0, theta = 60, zoom = 0.75, phi = 45)\nrender_scalebar(\n  limits = c(0, 5, 10),\n  label_unit = \"km\",\n  position = \"W\",\n  y = 50,\n  scale_length = c(0.33,1)\n)\nrender_compass(position = \"E\")\nrender_snapshot(clear = TRUE)\n\n\n\n\n\n\n\n\nHere, render_camera() sets the camera properties for the 3D map. render_scalebar() adds a scale bar to the map. The limits parameter specifies the limits of the scale bar, label_unit provides the label for the scale, position sets the position of the scale bar, y controls the vertical position, and scale_length determines the length of the scale bar. render_compass() adds a compass to the map, and render_snapshot() captures the final image of the map."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#d-plotting-with-rayshader-and-ggplot2",
    "href": "lessons_original/01_rayshader.html#d-plotting-with-rayshader-and-ggplot2",
    "title": "R Rayshader Overview",
    "section": "3D plotting with rayshader and ggplot2",
    "text": "3D plotting with rayshader and ggplot2\nRayshader can also be used to make 3D plots out of ggplot2 objects using the plot_gg() function\n\nggdiamonds = ggplot(diamonds) +\n  stat_density_2d(\n    aes(\n      x = x, y = depth, fill = stat(nlevel)\n    ), \n    geom = \"polygon\", n = 200, bins = 50,contour = TRUE\n  ) +\n  facet_wrap(clarity~.) +\n  scale_fill_viridis_c(option = \"A\")\n\npar(mfrow = c(1, 2))\n\nplot_gg(ggdiamonds, width = 5, height = 5, raytrace = FALSE, preview = TRUE)\n\nWarning: `stat(nlevel)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(nlevel)` instead.\n\n\n\n\n\n\n\n\nplot_gg(\n  ggdiamonds, \n  width = 5, \n  height = 5, \n  multicore = TRUE, \n  scale = 250, \n  zoom = 0.7, \n  theta = 10, \n  phi = 30, \n  windowsize = c(800, 800)\n)\nSys.sleep(0.2)\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#contour-plot",
    "href": "lessons_original/01_rayshader.html#contour-plot",
    "title": "R Rayshader Overview",
    "section": "Contour Plot",
    "text": "Contour Plot\nRayshader will automatically ignore lines and other elements that should not be mapped to 3D.\nHere’s a contour plot of the volcano dataset.\n\n# Contours and other lines will automatically be ignored. Here is the volcano\n#   dataset:\n\nggvolcano &lt;- volcano %&gt;% \n  melt() %&gt;%\n  ggplot() +\n  geom_tile(aes(x = Var1, y = Var2, fill = value)) +\n  geom_contour(aes(x = Var1, y = Var2, z = value), color = \"black\") +\n  scale_x_continuous(\"X\", expand = c(0, 0)) +\n  scale_y_continuous(\"Y\", expand = c(0, 0)) +\n  scale_fill_gradientn(\"Z\", colours = terrain.colors(10)) +\n  coord_fixed()\n\npar(mfrow = c(1, 2))\nplot_gg(ggvolcano, width = 7, height = 4, raytrace = FALSE, preview = TRUE)\n\nWarning: Removed 1861 rows containing missing values or values outside the scale range\n(`geom_contour()`).\n\n\n\n\n\n\n\n\n\n\nplot_gg(\n  ggvolcano,\n  multicore = TRUE, \n  raytrace = TRUE, \n  width = 7, \n  height = 4, \n  scale = 300, \n  windowsize = c(1400, 866), \n  zoom = 0.6, \n  phi = 30, \n  theta = 30\n)\n\nWarning: Removed 1861 rows containing missing values or values outside the scale range\n(`geom_contour()`).\n\nSys.sleep(0.2)\n\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#mtcars-data-example",
    "href": "lessons_original/01_rayshader.html#mtcars-data-example",
    "title": "R Rayshader Overview",
    "section": "mtcars Data Example",
    "text": "mtcars Data Example\nRayshader also detects when the user passes the color aesthetic, and maps those values to 3D\n\nmtplot = ggplot(mtcars) + \n  geom_point(\n    aes(x = mpg, y = disp, color = cyl)\n  ) + \n  scale_color_continuous(limits = c(0, 8))\n\npar(mfrow = c(1, 2))\nplot_gg(mtplot, width = 3.5, raytrace = FALSE, preview = TRUE)\n\n\n\n\n\n\n\nplot_gg(mtplot)\nSys.sleep(0.2)\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#reference",
    "href": "lessons_original/01_rayshader.html#reference",
    "title": "R Rayshader Overview",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.rayshader.com/\nhttps://www.youtube.com/watch?v=zgFXVhmKNbU"
  },
  {
    "objectID": "lessons_original/01_skimr.html",
    "href": "lessons_original/01_skimr.html",
    "title": "Skimr Package",
    "section": "",
    "text": "Skimr is an R package designed to provide summary statistics about variables in data frames, tibbles, data tables and vectors. The function is modifiable where you can add additional variables, which are not a part of default summary function within R. Skimr allows us to quickly assess data quality by feature and type in a quick report. This is a critical step in Data Exploration, where Understanding our data helps us to generate a hypothesis and determine what data analysis are appropriate.\nThis presentation will cover the simplest and most effective ways to explore data in R.\n\n\nTo begin we will upload the packages necessary for the lesson, this includes the following:\n\nreadr() to import our data file\nknitr() that houses the kable() feature that allows us to construct and customize tables.\ntidyverse houses the dyplyrpackage that assists with data manipulation and visualization.\nTheskimrpackage provides a compact summary of the variables in a dataset.\n\n\n\nCode\n# install.packages(\"skimr\")\n# install.packages(\"knitr\")\n# install.packages(\"tidyverse\")\n\n# load all the packages we will need to analyze the data and use the skim\n#   function\nlibrary(skimr)\nlibrary(knitr)\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n\n\n\nFor this assignment we will be using the Census_2010 dataset. There is no code book associated with the data, making it difficult to provide an accurate description of the variables. The information recorded shows the United States population estimates from the years 2010-2015, as well as relevant variables like net population change, number of births, number of deaths, international and domestic migration. Within the dataframe, there are 3,193 observations and 100 variables.\nThe data can be imported into R from the following link: https://fiudit-my.sharepoint.com/:x:/g/personal/ssinc013_fiu_edu/ESK1A13PstVGtf7HUwNNt68Bnh1YPfH8L-hnvMUxjBuCVw?e=CCwQU9\n\n\nCode\n# import the data\n# census_2010 &lt;- read_csv(\"Data/census_2010.csv\")\ncensus_2010 &lt;- readxl::read_xlsx(\"../data/01_census_2010.xlsx\")\n\n# what are the variables\ncolnames(census_2010) %&gt;% \n  head(n = 10)\n [1] \"SUMLEV\"            \"REGION\"            \"DIVISION\"         \n [4] \"STATE\"             \"COUNTY\"            \"STNAME\"           \n [7] \"CTYNAME\"           \"CENSUS2010POP\"     \"ESTIMATESBASE2010\"\n[10] \"POPESTIMATE2010\""
  },
  {
    "objectID": "lessons_original/01_skimr.html#packages",
    "href": "lessons_original/01_skimr.html#packages",
    "title": "Skimr Package",
    "section": "",
    "text": "To begin we will upload the packages necessary for the lesson, this includes the following:\n\nreadr() to import our data file\nknitr() that houses the kable() feature that allows us to construct and customize tables.\ntidyverse houses the dyplyrpackage that assists with data manipulation and visualization.\nTheskimrpackage provides a compact summary of the variables in a dataset.\n\n\n\nCode\n# install.packages(\"skimr\")\n# install.packages(\"knitr\")\n# install.packages(\"tidyverse\")\n\n# load all the packages we will need to analyze the data and use the skim\n#   function\nlibrary(skimr)\nlibrary(knitr)\nlibrary(readxl)\nlibrary(tidyverse)"
  },
  {
    "objectID": "lessons_original/01_skimr.html#census-data",
    "href": "lessons_original/01_skimr.html#census-data",
    "title": "Skimr Package",
    "section": "",
    "text": "For this assignment we will be using the Census_2010 dataset. There is no code book associated with the data, making it difficult to provide an accurate description of the variables. The information recorded shows the United States population estimates from the years 2010-2015, as well as relevant variables like net population change, number of births, number of deaths, international and domestic migration. Within the dataframe, there are 3,193 observations and 100 variables.\nThe data can be imported into R from the following link: https://fiudit-my.sharepoint.com/:x:/g/personal/ssinc013_fiu_edu/ESK1A13PstVGtf7HUwNNt68Bnh1YPfH8L-hnvMUxjBuCVw?e=CCwQU9\n\n\nCode\n# import the data\n# census_2010 &lt;- read_csv(\"Data/census_2010.csv\")\ncensus_2010 &lt;- readxl::read_xlsx(\"../data/01_census_2010.xlsx\")\n\n# what are the variables\ncolnames(census_2010) %&gt;% \n  head(n = 10)\n [1] \"SUMLEV\"            \"REGION\"            \"DIVISION\"         \n [4] \"STATE\"             \"COUNTY\"            \"STNAME\"           \n [7] \"CTYNAME\"           \"CENSUS2010POP\"     \"ESTIMATESBASE2010\"\n[10] \"POPESTIMATE2010\""
  },
  {
    "objectID": "lessons_original/01_skimr.html#separate-dataframes-by-type",
    "href": "lessons_original/01_skimr.html#separate-dataframes-by-type",
    "title": "Skimr Package",
    "section": "4.1 Separate dataframes by type",
    "text": "4.1 Separate dataframes by type\nThe data frames produced by skim() are wide and sparse, filled with columns that are mostly NA. For that reason, it can be convenient to work with “by type” subsets of the original data frame. These smaller subsets have their NA columns removed.\nFeatures:\n\npartition() - Creates a list of smaller data frames. Each entry in the list is a data type from the original dataframe\nbind() - Takes the list and rebuilds the original dataframe.\nyank() - Extract a subtable from a dataframe with a particular type.\n\nThe following syntax is using partition() to separate the large census_df.\n\n\nCode\n# split the character and numeric data\nseparate_df &lt;- partition(skim(census_2010))\n# check only the character data\nseparate_df$character\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n\n\n\n\n\nCode\n\n# create summary statistics for only numeric variables\nnumeric_separate_df &lt;- separate_df[2]\n# pull out the desired summary statistics in the nested list\nhead(numeric_separate_df$numeric[\"mean\"]) %&gt;% \n  kable(digits = 1) \n\n\n\n\n\nmean\n\n\n\n\n49.8\n\n\n2.7\n\n\n5.2\n\n\n30.3\n\n\n101.9\n\n\n193387.1\n\n\n\n\n\nThe following syntax is using bind() to combine the smaller character and numeric lists into the desired df.\n\n\nCode\n# combine the character and numeric data\nhead(bind(separate_df))\n\n\n\nData summary\n\n\nName\ncensus_2010\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSUMLEV\n0\n1\n49.84\n1.25\n40\n50\n50\n50\n50\n▁▁▁▁▇\n\n\nREGION\n0\n1\n2.67\n0.81\n1\n2\n3\n3\n4\n▁▆▁▇▂\n\n\nDIVISION\n0\n1\n5.19\n1.97\n1\n4\n5\n7\n9\n▂▇▅▆▃\n\n\nSTATE\n0\n1\n30.26\n15.15\n1\n18\n29\n45\n56\n▃▇▆▆▇\n\n\n\n\n\nCode\n\n# confirm that the bound table is the same as the original skimmed table\nidentical(bind(separate_df), skim(census_2010)) \n[1] TRUE\n\n\nThe following syntax is using yank() to extract a specific table eg.character to examine.\n\n\nCode\n# Extract character data\nyank(skim(census_2010), \"character\")\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0"
  },
  {
    "objectID": "lessons_original/01_skimr.html#skimr-with-dplyr",
    "href": "lessons_original/01_skimr.html#skimr-with-dplyr",
    "title": "Skimr Package",
    "section": "4.2 Skimr with Dplyr",
    "text": "4.2 Skimr with Dplyr\nSkimr functions can be used in combination with Dplyr functions to examine specific variables within the census dataset.\nThe following example used skim() with filter() to display the variable CENSUS2010POP. The dataframe was further customized to display variable name and data type using select().\n\n\nCode\n# use dplyr functions on the statistics summary table\ncensus_filter &lt;- skim(census_2010) %&gt;% \n  filter(skim_variable == \"CENSUS2010POP\")\ncensus_filter\n\n\n\nData summary\n\n\nName\ncensus_2010\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCENSUS2010POP\n0\n1\n193387\n1176201\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n\n\n\n\n\nCode\n\ncensus_select &lt;- skim(census_2010) %&gt;% \n  select(skim_type, skim_variable)\nhead(census_select)\n# A tibble: 6 × 2\n  skim_type skim_variable\n  &lt;chr&gt;     &lt;chr&gt;        \n1 character STNAME       \n2 character CTYNAME      \n3 numeric   SUMLEV       \n4 numeric   REGION       \n5 numeric   DIVISION     \n6 numeric   STATE        \n\n\nYou can also customize the output of the skim() function by using various arguments. For example, you can use the numeric argument to specify which variables should be treated as numeric variables, or use the ranges argument to specify custom ranges for variables.\nUsing skim() in combination with mutate() we will compute a new variable to add to our skim dataframe.\n\n\nCode\n# create a new variable calculate the change in birth rate from 2010 to 2011\ncensus_2010 %&gt;% \n  # new variable\n  mutate(net_birth = BIRTHS2011 - BIRTHS2010) %&gt;% \n  # move the variable to the beginning of the dataset\n  relocate(net_birth, .after = CENSUS2010POP) %&gt;% \n  # summary statistics table\n  skim() %&gt;% \n  # only the first fifteen variables\n  head(n = 15) %&gt;% \n  # change the formatting \n  kable(digit = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nSTNAME\n0\n1\n4\n20\n0\n51\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nSUMLEV\n0\n1\nNA\nNA\nNA\nNA\nNA\n4.98e+01\n1.25e+00\n40\n50\n50\n50\n50\n▁▁▁▁▇\n\n\nnumeric\nREGION\n0\n1\nNA\nNA\nNA\nNA\nNA\n2.67e+00\n8.10e-01\n1\n2\n3\n3\n4\n▁▆▁▇▂\n\n\nnumeric\nDIVISION\n0\n1\nNA\nNA\nNA\nNA\nNA\n5.19e+00\n1.97e+00\n1\n4\n5\n7\n9\n▂▇▅▆▃\n\n\nnumeric\nSTATE\n0\n1\nNA\nNA\nNA\nNA\nNA\n3.03e+01\n1.52e+01\n1\n18\n29\n45\n56\n▃▇▆▆▇\n\n\nnumeric\nCOUNTY\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.02e+02\n1.08e+02\n0\n33\n77\n133\n840\n▇▁▁▁▁\n\n\nnumeric\nCENSUS2010POP\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.93e+05\n1.18e+06\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n\n\nnumeric\nnet_birth\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.87e+03\n1.18e+04\n-3\n96\n232\n639\n386443\n▇▁▁▁▁\n\n\nnumeric\nESTIMATESBASE2010\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.93e+05\n1.18e+06\n82\n11299\n26446\n71491\n37254503\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2010\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.94e+05\n1.18e+06\n83\n11275\n26467\n71721\n37334079\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2011\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.95e+05\n1.19e+06\n90\n11277\n26417\n72387\n37700034\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2012\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.97e+05\n1.20e+06\n81\n11195\n26362\n72496\n38056055\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2013\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.98e+05\n1.21e+06\n89\n11180\n26519\n72222\n38414128\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2014\n0\n1\nNA\nNA\nNA\nNA\nNA\n2.00e+05\n1.22e+06\n87\n11121\n26483\n72257\n38792291\n▇▁▁▁▁"
  },
  {
    "objectID": "lessons_original/01_skimr.html#adding-variables",
    "href": "lessons_original/01_skimr.html#adding-variables",
    "title": "Skimr Package",
    "section": "4.3 Adding Variables",
    "text": "4.3 Adding Variables\n\nbase - An sfl that sets skimmers for all column types.\nappend - Whether the provided options should be in addition to the defaults already in skim. Default is TRUE.\n\nAs mentioned, skim() is designed to display default statistics, however you can use this function to change the summary statistics that it returns.\nskim_with() is type closure: a function that returns adds a new variable to the table. This lets you have several skimming functions in a single R session, but it also means that you need to assign the return of skim_with() before you can use it.\nYou assign values within skim_with() by using the sfl() helper (skimr function list). It identifies which skimming functions you want to remove, by setting them to NULL. Assign an sfl to each column type that you wish to modify.\nFor example, we will add the following variables to the dataframe: median, min, max, IQR, length.\n\n\nCode\nmy_skim &lt;- skim_with(\n  numeric = sfl(median, min, max, IQR),\n  character = sfl(length), \n  append = TRUE\n)\n\n# add new variables into the summary table\ncensus_2010 %&gt;% \n  my_skim() %&gt;% \n  head(n = 10)\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nlength\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n3193\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n3193\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nmedian\nmin\nmax\nIQR\n\n\n\n\nSUMLEV\n0\n1\n4.98e+01\n1.25e+00\n40\n50\n50\n50\n50\n▁▁▁▁▇\n50\n40\n50\n0\n\n\nREGION\n0\n1\n2.67e+00\n8.10e-01\n1\n2\n3\n3\n4\n▁▆▁▇▂\n3\n1\n4\n1\n\n\nDIVISION\n0\n1\n5.19e+00\n1.97e+00\n1\n4\n5\n7\n9\n▂▇▅▆▃\n5\n1\n9\n3\n\n\nSTATE\n0\n1\n3.03e+01\n1.52e+01\n1\n18\n29\n45\n56\n▃▇▆▆▇\n29\n1\n56\n27\n\n\nCOUNTY\n0\n1\n1.02e+02\n1.08e+02\n0\n33\n77\n133\n840\n▇▁▁▁▁\n77\n0\n840\n100\n\n\nCENSUS2010POP\n0\n1\n1.93e+05\n1.18e+06\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n26424\n82\n37253956\n60105\n\n\nESTIMATESBASE2010\n0\n1\n1.93e+05\n1.18e+06\n82\n11299\n26446\n71491\n37254503\n▇▁▁▁▁\n26446\n82\n37254503\n60192\n\n\nPOPESTIMATE2010\n0\n1\n1.94e+05\n1.18e+06\n83\n11275\n26467\n71721\n37334079\n▇▁▁▁▁\n26467\n83\n37334079\n60446"
  },
  {
    "objectID": "lessons_original/01_table1.html",
    "href": "lessons_original/01_table1.html",
    "title": "Demographics table with table1",
    "section": "",
    "text": "Code\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"lag\", \"dplyr\", quiet = TRUE)\n\nsuppressPackageStartupMessages(library(tidyverse))\n\n# suppress \"`summarise()` has grouped output by \" messages\noptions(dplyr.summarise.inform = FALSE)"
  },
  {
    "objectID": "lessons_original/01_table1.html#necessary-packages",
    "href": "lessons_original/01_table1.html#necessary-packages",
    "title": "Demographics table with table1",
    "section": "Necessary Packages",
    "text": "Necessary Packages\nThe htmlTable package allows for the usage of the table1() function to create a table 1, while also making life easy when attempting to copy this table into a Word document.\nThe boot package was created to aid in performing bootstrapping analysis. With it comes numerous data sets, specifically clinical trial data sets to make this possible. However, there is no code book provided within the package when the data is downloaded as a csv file. This is a link on Github that explains and elaborates on every data within the package itself2.\n\n#install.packages(\"htmlTable\")\n#install.packages(\"boot\")\n\n# Load libraries\nlibrary(htmlTable)\nlibrary(table1)\nlibrary(boot)"
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html",
    "href": "lessons_original/02_fisher_exact_test.html",
    "title": "Fisher’s Exact Test",
    "section": "",
    "text": "Fisher’s exact test is an independent test used to determine if there is a relationship between categorical (non-parametric) variables with a small sample size.\nUsed to assess whether proportions of one variable are different among values of another table.\nUses (hypergeometric) marginal distribution to derive exact p-values which are not approximated, which are also somewhat conservative.\nThe rules of Chi distribution do not apply when the frequency count is &lt;5 for more than 20% of the cells in a contingency table (Bower 2003).\nData is easily manipulated by using a contingency table.\n\n\n\n\nAssumes that the individual observations are independent.\nAssumes that the row and column totals are fixed or conditioned.\nThe variables are categorical and randomly sampled.\nObservations are count data.\n\n\n\n\nThe hypotheses of Fisher’s exact test are similar to Chi-square test:\nNull hypothesis:\\((H_0)\\) There is no relationship between the categorical variables, the variables are independent.\nAlternative hypothesis: \\((H_1)\\) There is a relationship between the categorical variables, the variables are dependent."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#introduction",
    "href": "lessons_original/02_fisher_exact_test.html#introduction",
    "title": "Fisher’s Exact Test",
    "section": "",
    "text": "Fisher’s exact test is an independent test used to determine if there is a relationship between categorical (non-parametric) variables with a small sample size.\nUsed to assess whether proportions of one variable are different among values of another table.\nUses (hypergeometric) marginal distribution to derive exact p-values which are not approximated, which are also somewhat conservative.\nThe rules of Chi distribution do not apply when the frequency count is &lt;5 for more than 20% of the cells in a contingency table (Bower 2003).\nData is easily manipulated by using a contingency table.\n\n\n\n\nAssumes that the individual observations are independent.\nAssumes that the row and column totals are fixed or conditioned.\nThe variables are categorical and randomly sampled.\nObservations are count data.\n\n\n\n\nThe hypotheses of Fisher’s exact test are similar to Chi-square test:\nNull hypothesis:\\((H_0)\\) There is no relationship between the categorical variables, the variables are independent.\nAlternative hypothesis: \\((H_1)\\) There is a relationship between the categorical variables, the variables are dependent."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#fishers-exact-test-equation",
    "href": "lessons_original/02_fisher_exact_test.html#fishers-exact-test-equation",
    "title": "Fisher’s Exact Test",
    "section": "Fisher’s Exact Test Equation",
    "text": "Fisher’s Exact Test Equation\nFisher’s exact test for a one-tailed p-value is calculated using the following formula:\n\\[   p = {(a+b)!(c+d)!(a+c)!(b+d)! \\over a! b! c! d! n!} \\] - n = population size/ total frequency\n- a + b = “successes” values in the contingency table\n- a + c = sample size / draws from the population\n- a = sample successes\n\nFormula description\nthis test is usually used as a one-tailed test but it can also be used as a two tailed test as well, \\(a\\),\\(b\\),\\(c\\), and \\(d\\) are the individual frequencies on the 2x2 contingency table and \\(n\\) is our total frequency. This particular test is used to obtain the probability of the combination of frequencies that we can actually obtain.\n\n\nWhat is a contingency table?\nThis is a table that shows the distribution of a variable in the rows and columns. Sometimes referred to as a 2x2 table. They are useful in summarizing categorical variables. The table() function is used to create a contingency table in R. When the variables of interest are summarized in a contingency table it is easier to run the Fisher’s Exact test.\n\nExample: Creating a contingency table\nLets say we have information on the gender of participants in a clinical trial and the type of drug administered to them we can create the following contingency table for further analysis.\n\n# Example R code to create a contingency table\n\n# Creating a data frame\n df &lt;- data.frame(\n   \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\"),\n   \"Gender\" = c(\"Male\", \"Male\", \"Female\")\n )\n \n# Creating contingency table using table()\nctable &lt;- table(df)\nprint(ctable)\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n\n\n\n\n\nPerforming Fisher’s Exact Test in R\nWe will need to install the ggstatplot package to visualize the statistical results.\n\n# install.packages(\"ggstatplot\") \n# install.packages(\"summarytools\")\n# install.packages(\"gmodels\")\n# install.packages(tidyverse)\n\n\n\nData Source: GMP2017\nFor this example we will be using the Greater Manchester Police’s UK stop and search data from 2017(December) sourced from the Sage Research Methods Dataset Part 2 (https://methods.sagepub.com/dataset/fishers-exact-gmss-2017). This data has information on stop and search events, gender and ethnicity. For this example we would like to access whether there is a significant relationship between gender and stop and search events (having controlled drugs vs harmful weapons)?\n\nGMP17 &lt;- read.csv(\n  \"../data/02_dataset-gmss-2017-subset1_jittered_20240503.csv\"\n)\n\n\n\nLoad in libraries\n\nlibrary(gmodels)\nlibrary(ggstatsplot)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(katex)\nlibrary(tidyverse)\n\n\n\nDescriptive summary\n\n\nCode\nhead(GMP17)\n\n\n  Gender Ethnicity ObjectSearch\n1      1         1            1\n2      1         1           -9\n3      1         1            1\n4      1         1            1\n5      1         1           -9\n6      1         1            1\n\n\nCode\nstr(GMP17)\n\n\n'data.frame':   186 obs. of  3 variables:\n $ Gender      : int  1 1 1 1 1 1 1 1 1 -9 ...\n $ Ethnicity   : int  1 1 1 1 1 1 2 1 1 1 ...\n $ ObjectSearch: int  1 -9 1 1 -9 1 1 1 -9 -9 ...\n\n\nCode\n# determining the number of rows\nNROW(GMP17)\n\n\n[1] 186\n\n\n\n\nAssessing frequencies to answer research question\nFor this analysis we will use the Gender variable and the ObjectSearch variable\n\n# Dropping the Ethnicity variable to remain with variables of interest for for the 2x2 table\n\nnewGMP17 &lt;-GMP17[ -c(2) ]\n \nhead(newGMP17)\n\n  Gender ObjectSearch\n1      1            1\n2      1           -9\n3      1            1\n4      1            1\n5      1           -9\n6      1            1\n\n\nThe data contains missing values categorized as -9 that we need to drop and we need to rename our variables based on the data dictionary provided https://methods.sagepub.com/dataset/download/fishers-exact-gmss-2017/guide/codebook.\n\n# Exclude rows that have missing data in both variables\nnewGMP17_nom &lt;- subset(newGMP17, Gender &gt; 0)\nnewGMP17_nom2 &lt;- subset(newGMP17_nom, ObjectSearch  &gt; 0)\nsummary(newGMP17_nom2)\n\n     Gender       ObjectSearch  \n Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.000  \n Median :1.000   Median :1.000  \n Mean   :1.052   Mean   :1.267  \n 3rd Qu.:1.000   3rd Qu.:2.000  \n Max.   :2.000   Max.   :2.000  \n\nnrow(newGMP17_nom2)\n\n[1] 116\n\n\n\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$Gender &lt;- recode_factor(\n  newGMP17_nom2$Gender,\n  \"1\" = \"Male\",\n  \"2\" = \"Female\"\n)\n\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$ObjectSearch &lt;- recode_factor(\n  newGMP17_nom2$ObjectSearch,\n  \"1\" = \"Controlled_Drugs\",\n  \"2\" = \"Harmful_Objects\"\n)\n\n\n# Creating the contingency table for subset data\ncGMP17 = table(newGMP17_nom2)\nprint(cGMP17)\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male                 83              27\n  Female                2               4\n\n\n\n\nVisualizing data using mosaic plot\n\nwe can use the mosaic plot to represent the data.\n\n\nmosaicplot(\n  cGMP17,\n  main = 'Mosaic Plot',\n  color = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nRunning the Fisher’s exact test using fisher.test()\nWhat if we just run a Chi-square test?\nUsing our GMP17 dataset we can try to run a Chi-square test instead of the Fisher’s Exact test and see what happens.\nThe R output gives us a warning that the Chi Square is not appropriate hence we should use another test in this case the Fisher’s Exact Test.\n\nchisq.test(cGMP17)$expected\n\nWarning in chisq.test(cGMP17): Chi-squared approximation may be incorrect\n\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male          80.603448       29.396552\n  Female         4.396552        1.603448\n\n\n\n\nRunning the test\n\n# running the fisher's exact test\n\ntest &lt;- fisher.test(cGMP17)\ntest\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  cGMP17\np-value = 0.04297\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.8133673 70.2637501\nsample estimates:\nodds ratio \n  6.030297 \n\n\nUsing the gt summary to view results.\n\nnewGMP17_nom2 |&gt; \n  tbl_summary(by = Gender) |&gt; \n  add_p() |&gt; \n  add_overall()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall, N = 1161\nMale, N = 1101\nFemale, N = 61\np-value2\n\n\n\n\nObjectSearch\n\n\n\n\n\n\n0.043\n\n\n    Controlled_Drugs\n85 (73%)\n83 (75%)\n2 (33%)\n\n\n\n\n    Harmful_Objects\n31 (27%)\n27 (25%)\n4 (67%)\n\n\n\n\n\n1 n (%)\n\n\n2 Fisher’s exact test\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of results\nThe most important test statistic is the p - value therefore we can retrieve the specific result using the following code;\n\ntest$p.value \n\n[1] 0.04297268\n\n\nOdds ratio = 6.33, 95% CI = 0.85-73.59], we reject the null hypothesis (p &lt; 0.05) and conclude that there is a strong association between the two categorical independent variables (gender and object search events)\nTherefore the odds ratio indicates that the odds of having controlled drugs at a stop and search is 6.33 times as likely for males compared to females. In other words, males are more likely of having controlled drugs at a stop and search than females.\n\n\nVisualizing statistical results with plots using ggstatsplot\n\nwe download the ggsattsplot package to visualize the results in a plot.\n\n\n# Fisher's exact test \n\ntest &lt;- fisher.test(cGMP17)\n\n# combine plot and statistical test with ggbarstats\n\nggbarstats(\n  newGMP17_nom2, Gender, ObjectSearch,\n  results.subtitle = FALSE,\n  subtitle = paste0(\n    \"Fisher's exact test\", \", p-value = \",\n    ifelse(test$p.value &lt; 0.001, \"&lt; 0.001\", round(test$p.value, 3))\n  )\n)\n\n\n\n\n\n\n\n\nFrom the plot, it is clear that the proportion of males among object search events is higher compared to females, suggesting that there is a relationship between the two variables.\nThis is confirmed thanks to the p-value displayed in the subtitle of the plot. As previously, we reject the null hypothesis and we conclude that the variables gender and stop and search events are not independent (p-value = 0.038)."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#what-if-we-have-more-than-two-levels",
    "href": "lessons_original/02_fisher_exact_test.html#what-if-we-have-more-than-two-levels",
    "title": "Fisher’s Exact Test",
    "section": "What if we have more than two levels?",
    "text": "What if we have more than two levels?\nUsing the drug example used previously lets say we have 3 drugs ‘Drug A, Drug B or Drug C’ and we want to see if there is any relationship with gender ‘Male/Female’.\n\n# Creating a data frame\ndf &lt;- data.frame (\n  \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\", \"Drug C\", \"Drug C\"),\n  \"Gender\" = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Female\")\n)\n \n# Creating contingency table using table()\nctable &lt;- table(df)\nprint(ctable)\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n  Drug C      2    0\n\n\n\n# Running the Fisher's Exact test for the 3x2 table\nfisher.test(ctable)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  ctable\np-value = 0.6\nalternative hypothesis: two.sided\n\n\nThe p-value is non-significant [p = 0.6], we fail to reject the null hypothesis (p &lt; 0.05) and conclude that there is no association between the drug treatments and gender. If the results had been significant we would have gone ahead and conducted a post hoc analysis using pairwise_fisher_test to asses each combination.\nSummary\nThis article describe the assumptions and hypotheses of the Fisher’s Exact test. It also provides examples on how it can be applied."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#references",
    "href": "lessons_original/02_fisher_exact_test.html#references",
    "title": "Fisher’s Exact Test",
    "section": "References",
    "text": "References\n\nBower, Keith M. 2003. “When to Use Fisher’s Exact Test.” In American Society for Quality, Six Sigma Forum Magazine, 2:35–37. 4.\nMcCrum-Gardner, Evie. 2008. “Which Is the Correct Statistical Test to Use?” British Journal of Oral and Maxillofacial Surgery 46 (1): 38–41.\nWong KC. Chi squared test versus Fisher’s exact test. Hong Kong Med J. 2011 Oct;17(5):427\nPatil, I. (2021). Visualizations with statistical details: The ‘ggstatsplot’ approach. Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\nZach Bobbit. (2021). Fisher’s Exact Test: Definition, Formula, and Example"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "What is bootstrapping?\nBootstrapping is a technique from Efron (1979) that is built on a simple idea: if the data we have is a sample from a population, why don’t we sample from our own data to make more samples? Now, because we don’t have access to any new data, we’re going to take samples of our data set with replacement.\n\n\nThe purpose of bootstrapping is to increase the sample size for our analysis when the sample we have been given is small."
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#when-to-use-bootstrapping",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#when-to-use-bootstrapping",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "The purpose of bootstrapping is to increase the sample size for our analysis when the sample we have been given is small."
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#distribution",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#distribution",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.1 Distribution",
    "text": "3.1 Distribution\nBoxplots and histograms will be useful to understand the distribution of the data.\nOur data is not normal based on the distribution.\n\n\nCode\n# check the boxplot of the data\nboxplot(\n  new_penguins_df$flipper_length_mm ~ new_penguins_df$island, las = 1, \n  ylab = \"Flipper Length (mm)\",\n  xlab = \"Island\",\n  main = \"Flipper Length by Island\"\n)\n\n\n\n\n\n\n\n\n\nCode\n\n# check the histogram of the data\nhist(\n  x = new_penguins_df$flipper_length_mm,\n  main = \"Distribution of Flipper Length (mm)\",\n  xlab = \"Flipper Length\"\n)"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#bootstrapping-test",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#bootstrapping-test",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.2 Bootstrapping Test",
    "text": "3.2 Bootstrapping Test\nWe need the difference in means in order to conduct our permutation test. We will test whether the difference is significant so that we can reject the null. This indicates that there is a different in flipper length among the same species that come from different islands.\n\n\nCode\n# set a seed so that our random results can be replicated by other people:\nset.seed(20150516)\n\n# take a random re-sample of the data that is the *same size*\nN &lt;- length(new_penguins_df$flipper_length_mm)\n\n# a random sample:\nsample(new_penguins_df$flipper_length_mm, size = N, replace = TRUE)\n [1] 184 192 198 195 195 176 188 183 184 193 199 198 184 190 198 195 195 199 193\n[20] 197 198 189 197 188 189 199 200 190 183 198 194 190 191 196 189 195 198 197\n[39] 191 184 198 180 195 186 193 193 191 195 190 198 189 181 197 196 182 200 188\n[58] 184 202 189 197 186 181 195 181 191 185 193 196 185 192 199 186 196 180 190\n[77] 190 195 197 193 191 181 195 190 186 189 192 187 190 195 195 182 172 194 181\n\n# number of bootstrap samples\nB_int &lt;- 10000\n\n# create a list of these thousands of samples \nbootstrapSamples_ls &lt;- map(\n  .x = 1:B_int,\n  .f = ~{\n    sample(new_penguins_df$flipper_length_mm, size = N, replace = TRUE)\n  }\n)\n\n# subset of the random samples \nbootstrapSamples_ls[1:3]\n[[1]]\n [1] 183 190 189 188 181 198 181 172 187 189 189 193 180 197 191 190 196 191 195\n[20] 181 193 190 190 186 188 195 190 197 198 190 180 198 194 188 195 191 203 199\n[39] 190 189 195 186 189 199 202 197 189 190 194 190 181 190 190 181 186 196 174\n[58] 185 174 202 191 184 181 184 193 190 190 190 191 196 189 195 195 198 193 190\n[77] 197 184 186 188 193 190 191 195 198 180 191 185 189 192 183 192 199 186 195\n\n[[2]]\n [1] 187 194 187 189 184 188 187 187 184 197 193 191 187 189 190 172 187 186 180\n[20] 193 191 195 195 180 184 189 197 191 187 186 186 187 184 188 190 193 198 190\n[39] 195 198 184 197 195 195 195 198 194 191 198 197 198 186 194 195 189 186 181\n[58] 180 191 180 191 193 196 191 202 191 187 181 199 172 181 191 195 195 194 198\n[77] 191 191 190 192 190 199 195 193 195 197 188 181 190 185 186 191 174 193 195\n\n[[3]]\n [1] 191 196 203 195 185 195 193 186 186 202 186 203 187 180 185 186 192 202 186\n[20] 192 200 195 184 185 195 193 199 190 189 185 181 181 188 197 181 190 188 185\n[39] 187 184 184 195 199 186 200 186 192 195 190 182 189 191 203 193 195 191 191\n[58] 199 195 198 187 191 195 190 190 187 189 192 186 199 193 190 187 181 190 191\n[77] 190 190 183 193 190 197 181 190 187 198 187 190 200 184 190 184 186 191 193"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-1",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-1",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.3 Building Confidence Intervals for Various Statistics: Example 1",
    "text": "3.3 Building Confidence Intervals for Various Statistics: Example 1\n\n\nCode\n\n# The Sample Mean\nbootMeans_num &lt;-\n  bootstrapSamples_ls %&gt;%\n  # the map_dbl() function takes in a list and returns an atomic vector of type\n  #   double (numeric)\n  map_dbl(mean)\n\n# a normally distributed histogram using the samples from bootstrapping\nhist(bootMeans_num)\n\n\n\n\n\n\n\n\n\nCode\n\n# 95% confidence interval?\nquantile(bootMeans_num, probs = c(0.025, 0.975))\n 2.5% 97.5% \n  189   191"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-2",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-2",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.4 Building Confidence Intervals for Various Statistics: Example 2",
    "text": "3.4 Building Confidence Intervals for Various Statistics: Example 2\nSource: https://www.geeksforgeeks.org/bootstrap-confidence-interval-with-r-programming/\n\n\nCode\n\n# Custom function to find correlation between the bill length and depth \ncorr.fun &lt;- function(data, idx) {\n  \n# vector of indices that the boot function uses\n  df &lt;- data[idx, ]\n\n# Find the spearman correlation between\n# the 3rd (length) and 5th (depth) columns of dataset\n  cor(df[, 3], df[, 4], method = 'spearman')\n}\n\n# Setting the seed for reproducability of results\nset.seed(42)\n\n# Calling the boot function with the dataset\nbootstrap &lt;- boot(iris, corr.fun, R = 1000)\n\n# Display the result of boot function\nbootstrap\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = iris, statistic = corr.fun, R = 1000)\n\n\nBootstrap Statistics :\n    original   bias    std. error\nt1*    0.938 -0.00272     0.00944\n\n# Plot the bootstrap sampling distribution using ggplot\nplot(bootstrap)\n\n\n\n\n\n\n\n\n\nCode\n\n# Function to find the bootstrap CI\nboot.ci(\n  boot.out = bootstrap,\n    type = \"perc\"\n)\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bootstrap, type = \"perc\")\n\nIntervals : \nLevel     Percentile     \n95%   ( 0.914,  0.952 )  \nCalculations and Intervals on Original Scale"
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html",
    "href": "lessons_original/03_two_sample_ttest.html",
    "title": "Two sample t test",
    "section": "",
    "text": "This is also called the independent sample t test. It is used to see whether the unknown population means of two groups are equal or different. This test requires one variable which can be the exposure x and another variable which can be the outcome y. If you have more than two groups then analysis of variance (ANOVA) will be more suitable. If data is nonparametric then an alternative test to use would be the Mann Whitney U test or a permutation test.(cressie1986?).\nThere are two types of t tests, the first being the Student’s t test, which assumes the variance of the two groups is equal, the second being the Welch’s t test (default in R), which assumes the variance in the two groups is different.\nIn this article we will be discussing the Student’s t test.\n\n\n\nMeasurements for one observation do not affect measurements for any other observation (assumes independence).\nData in each group must be obtained via a random sample from the population.\nData in each group are normally distributed.\nData values are continuous.\nThe variances for the two independent groups are equal in the Student’s t test.\nThere should be no significant outliers.\n\n\n\n\n\n(H_0): the mean of group A (m_A) is equal to the mean of group B (m_B)- two tailed test,\n(H_0): (m_A)\\ge (m_B)- one tailed test.\n(H_0): (m_A)\\le (m_B)- one tailed test.\nThe corresponding alternative hypotheses would be as follows:\n\n\n\n(H_1): (m_A)\\neq(m_B)- two tailed test.\n(H_1): (m_A)&lt;(m_B)- one tailed test.\n(H_1): (m_A)&gt; (m_B)- one tailed test.\n\n\n\n\nFor the Student’s t test which assumes equal variance the following is how the |t| statistic may be calculated using groups A and B as examples:\nt ={ {m_{A} - m_{B}} \\over \\sqrt{ {S^2 \\over n_{A} } + {S^2 \\over n_{B}}   }}\nThis can be described as the sample mean difference divided by the sample standard deviation of the sample mean difference where:\nm_A and m_B are the mean values of A and B,\nn_A and n_B are the seize of group A and B,\nS^2 is the estimator for the pooled variance,\nwith the degrees of freedom (df) = n_A + n_B - 2,\nand S^2 is calculated as follows:\nS^2 = { {\\sum{ (x_A-m_{A})^2} + \\sum{ (x_B-m_{B})^2}} \\over {n_{A} + n_{B} - 2 }}\nResults for both Students t test and Welch’s t test are usually similar unless the group sizes and standard deviations are different.\nWhat if the data is not independent?\nIf the data is not independent such as paired data in the form of matched pairs which are correlated, we use the paired t test. This test checks whether the means of two paired groups are different from each other. It’s usually used in clinical trial studies with a “before and after” or case control studies with matched pairs. For this test we only assume the difference of each pair to be normally distributed (the paired groups are the ones important for analysis) unlike the independent t test which assumes that data from both samples are independent and variances are equal.(fralick?)\n\n\n\n\n\n\n\ntidyverse: data manipulation and visualization.\nrstatix: providing pipe friendly R functions for easy statistical analyses.\ncar: providing variance tests.\n\n\n\nCode\n#install.packages(\"ggstatplot\") \n#install.packages(\"car\")\n#install.packages(\"rstatix\")\n#install.packages(tidyVerse)\n\n\n\n\n\nThis example dataset sourced from kaggle was obtained from surveys of students in Math and Portuguese classes in secondary school. It contains demographic information on gender, social and study information.(cortez2008?)\n\n\nCode\n# load relevant libraries\nlibrary(rcompanion)\nlibrary(car)\nlibrary (gt)\nlibrary(gtsummary)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(tidyverse)\n\n\n\n\nCode\n# load the dataset\nstu_math &lt;- read_csv(\"../data/03_student-mat.csv\")\n\n\nRows: 395 Columns: 33\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (17): school, sex, address, famsize, Pstatus, Mjob, Fjob, reason, guardi...\ndbl (16): age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking the data\n\n\nCode\n# check the data\nglimpse(stu_math)\n\n\nRows: 395\nColumns: 33\n$ school     &lt;chr&gt; \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\",…\n$ sex        &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\",…\n$ age        &lt;dbl&gt; 18, 17, 15, 15, 16, 16, 16, 17, 15, 15, 15, 15, 15, 15, 15,…\n$ address    &lt;chr&gt; \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\",…\n$ famsize    &lt;chr&gt; \"GT3\", \"GT3\", \"LE3\", \"GT3\", \"GT3\", \"LE3\", \"LE3\", \"GT3\", \"LE…\n$ Pstatus    &lt;chr&gt; \"A\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"A\", \"A\", \"T\", \"T\", \"T\",…\n$ Medu       &lt;dbl&gt; 4, 1, 1, 4, 3, 4, 2, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4,…\n$ Fedu       &lt;dbl&gt; 4, 1, 1, 2, 3, 3, 2, 4, 2, 4, 4, 1, 4, 3, 2, 4, 4, 3, 2, 3,…\n$ Mjob       &lt;chr&gt; \"at_home\", \"at_home\", \"at_home\", \"health\", \"other\", \"servic…\n$ Fjob       &lt;chr&gt; \"teacher\", \"other\", \"other\", \"services\", \"other\", \"other\", …\n$ reason     &lt;chr&gt; \"course\", \"course\", \"other\", \"home\", \"home\", \"reputation\", …\n$ guardian   &lt;chr&gt; \"mother\", \"father\", \"mother\", \"mother\", \"father\", \"mother\",…\n$ traveltime &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1,…\n$ studytime  &lt;dbl&gt; 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, 1, 1,…\n$ failures   &lt;dbl&gt; 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,…\n$ schoolsup  &lt;chr&gt; \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"n…\n$ famsup     &lt;chr&gt; \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\",…\n$ paid       &lt;chr&gt; \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", …\n$ activities &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"ye…\n$ nursery    &lt;chr&gt; \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes…\n$ higher     &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n$ internet   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\",…\n$ romantic   &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\"…\n$ famrel     &lt;dbl&gt; 4, 5, 4, 3, 4, 5, 4, 4, 4, 5, 3, 5, 4, 5, 4, 4, 3, 5, 5, 3,…\n$ freetime   &lt;dbl&gt; 3, 3, 3, 2, 3, 4, 4, 1, 2, 5, 3, 2, 3, 4, 5, 4, 2, 3, 5, 1,…\n$ goout      &lt;dbl&gt; 4, 3, 2, 2, 2, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 3, 2, 5, 3,…\n$ Dalc       &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ Walc       &lt;dbl&gt; 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 2, 1, 4, 3,…\n$ health     &lt;dbl&gt; 3, 3, 3, 5, 5, 5, 3, 1, 1, 5, 2, 4, 5, 3, 3, 2, 2, 4, 5, 5,…\n$ absences   &lt;dbl&gt; 6, 4, 10, 2, 4, 10, 0, 6, 0, 0, 0, 4, 2, 2, 0, 4, 6, 4, 16,…\n$ G1         &lt;dbl&gt; 5, 5, 7, 15, 6, 15, 12, 6, 16, 14, 10, 10, 14, 10, 14, 14, …\n$ G2         &lt;dbl&gt; 6, 5, 8, 14, 10, 15, 12, 5, 18, 15, 8, 12, 14, 10, 16, 14, …\n$ G3         &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14,…\n\n\nIn total there are 395 observations and 33 variables. We will drop the variables we do not need and keep the variables that will help us answer the following: Is there a difference between boys and girls in math final grades?\nH_0: There is no statistical difference between the final grades between boys and girls.\nH_1: There is a statistically significant difference in the final grades between the two groups.\n\n\nCode\n# creating a subset of the data \nmath = subset(stu_math, select= c(sex,G3))\nglimpse(math)\n\n\nRows: 395\nColumns: 2\n$ sex &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"…\n$ G3  &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14, 14, 10…\n\n\nSummary statistics- the dependent variable is continuous (grades=G3) and the independent variable is character but binary (sex).\n\n\nCode\n# summarizing our data\n summary(math)\n\n\n     sex                  G3       \n Length:395         Min.   : 0.00  \n Class :character   1st Qu.: 8.00  \n Mode  :character   Median :11.00  \n                    Mean   :10.42  \n                    3rd Qu.:14.00  \n                    Max.   :20.00  \n\n\nWe see that data ranges from 0-20 with 0 being people who were absent and could not take the test therefore missing data. We remove these 0 values before running the t test. However other models should be considered such as the zero inflated model to differentiate those who truly got a 0 and those who were not present to take test.\n\n\nCode\n# creating a boxplot to visualize the data with no outliers\nmath2 = subset(math, G3&gt;0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nVisualizing the data- we can use histograms and box lots to visualize the data to check for outliers and distribution thus checking for normality.\n\n\nCode\n# Histograms for data by groups \n\nmale = math2$G3[math2$sex == \"M\"]\nfemale = math2$G3[math2$sex == \"F\"]\n\n# plotting distribution for males\nplotNormalHistogram(\n  male, \n  breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for males \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for males seem to be normally distributed from 0-20. Data is approximately normal because we have a large amount of bins.\n\n\nCode\n# plotting distribution for females\nplotNormalHistogram(\n  female, breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for females \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for females also appear to be normally distributed. The final score across both is almost evenly distributed. However there seem to be a significant number of individuals who failed the test (grade=0).\n\n\nCode\n# plotting bar plot to see the distribution in sample size\nsample_size = table(math2$sex)\nbarplot(sample_size,main= \"Distribution of sample size by sex\")\n\n\n\n\n\n\n\n\n\nThe bar graph shows that there are slightly more females in the sample than males.\nIdentifying outliers\n\n\nCode\n# creating a boxplot to visualize the outliers (G3=0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nThe box plot shows us that there are no outliers as these have been removed in terms of people who had a score of 0. This score is not truly reflective of the performance between boys and girls as a grade of 0 may represent absentia or other reasons for the test not been taken. Therefore we opt to drop the outliers. We will compare to see if this decision affects the mean which appears similar from the above plot.\n\n\nCode\n# finding the mean for the groups with outliers\nmean(math$G3[math$sex==\"F\"])\n\n\n[1] 9.966346\n\n\nCode\nmean(math$G3[math$sex==\"M\"])\n\n\n[1] 10.91444\n\n\nCode\n# finding the mean for the groups without outliers\nmean(math2$G3[math2$sex==\"F\"])\n\n\n[1] 11.20541\n\n\nCode\nmean(math2$G3[math2$sex==\"M\"])\n\n\n[1] 11.86628\n\n\nThe mean has increased slightly and the difference decreased after removing the outliers but the distribution is still the same.\nCheck the equality of variances (homogeneity)\nWe can use the Levene’s test or the Bartlett’s test to check for homogeneity of variances. The former is in the car library and the later in the rstatix library. If the variances are homogeneous the p value will be greater than 0.05.\nOther tests include F test 2 sided, Brown-Forsythe and O’Brien but we shall not cover these.\n\n\nCode\n# running the Bartlett's test to check equal variance\nbartlett.test(G3~sex, data=math2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  G3 by sex\nBartlett's K-squared = 0.12148, df = 1, p-value = 0.7274\n\n\nCode\n# running the Levene's test to check equal variance\nmath2 %&gt;% levene_test(G3~sex)\n\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1   355     0.614 0.434\n\n\nThe p value is greater than 0.05 suggesting there is no difference between the variances of the two groups.\n\n\n\n\nData is continuous(G3)\nData is normally distributed\nData is independent (males and females distinct not the same individual)\nNo significant outliers\nThere are equal variances\n\nAs the assumptions are met we go ahead to perform the Student’s t test.\n\n\n\nSince the default is the Welch t test we use the \\color{blue}{\\text{var.eqaul = TRUE }} code to signify a Student’s t test. There is a t.test() function in stats package and a t_test() in the rstatix package. For this analysis we use the rstatix method as it comes out as a table.\n\n\nCode\n# perfoming the two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE) %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df      p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.0531 ns      \n\n\n\n\nCode\nstat.test$statistic\n\n\n        t \n-1.940477 \n\n\nThe results are represented as follows;\n\ny - dependent variable\ngroup1, group 2 - compared groups(independent variables)\ndf - degrees of freedom\np - p value\n\ngtsummary table of results\n\n\nCode\n math2 |&gt; \n  tbl_summary(\n    by = sex,\n    statistic =\n      list(\n        all_continuous() ~ \"{mean} ({sd})\",\n        all_dichotomous() ~ \"{p}%\")\n    ) |&gt; \n   add_n() |&gt; \n  add_overall() |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOverall, N = 3571\nF, N = 1851\nM, N = 1721\nDifference2\n95% CI2,3\np-value2\n\n\n\n\nG3\n357\n11.5 (3.2)\n11.2 (3.2)\n11.9 (3.3)\n-0.66\n-1.3, 0.01\n0.053\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n3 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nInterpretation of results\nFor the two sample t test with t(355) = -1.940477, p = 0.0531, the p value is greater than our alpha of 0.05 , we fail to reject the null hypothesis and conclude that there is no statistical difference between the means of the two groups. There is no difference in final grades between boys and girls. (A significant |t| would be 1.96 or greater).\nEffect size\nCohen’s d can be an used as an effect size statistic for the two sample t test. It is the difference between the means of each group divided by the pooled standard deviation.\nd= {m_A-m_B \\over SD_pooled}\nIt ranges from 0 to infinity, with 0 indicating no effect where the means are equal. 0.5 means that the means differ by half the standard deviation of the data and 1 means they differ by 1 standard deviation. It is divided into small, medium or large using the following cut off points.\n\nsmall 0.2-&lt;0.5\nmedium 0.5-&lt;0.8\nlarge &gt;=0.8\n\nFor the above test the following is how we can find the effect size;\n\n\nCode\n#perfoming cohen's d\nmath2 %&gt;% \n  cohens_d(G3~sex,var.equal = TRUE)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2 effsize    n1    n2 magnitude\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 G3    F      M       -0.206   185   172 small    \n\n\nThe effect size is small d= -0.20.\nIn conclusion, a two-samples t-test showed that the difference was not statistically significant, t(355) = -1.940477, p &lt; 0.0531, d = -0.20; where, t(355) is shorthand notation for a t-statistic that has 355 degrees of freedom and d is Cohen’s d. We can conclude that the females mean final grade is greater than males final grade (d= -0.20) but this result is not significant.\nWhat if it is one tailed t test?\nUse the \\color{blue}{\\text{alternative =}} option to determine if one group is \\color{blue}{\\text{\"less\"}} or \\color{blue}{\\text{\"greater\"}}. For example if we want to see whether the final grades for females are greater than males we can use the following code:\n\n\nCode\n# perfoming the one tailed two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE, alternative = \"greater\") %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df     p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.973 ns      \n\n\nThe p value is greater than 0.05 (p=0.973), we fail to reject the null hypothesis. We conclude that the final grades for females are not significantly greater than for males.\nWhat about running the paired sample t test?\nWe can simply add the syntax \\color{blue}{\\text{paired= TRUE}} to our t_test() to run the analysis for matched pairs data.\n\n\n\n\nThis article covers the Student’s t test and how we run it in R. It also shows how we find the effect size and how we can conclude the results."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#assumptions",
    "href": "lessons_original/03_two_sample_ttest.html#assumptions",
    "title": "Two sample t test",
    "section": "",
    "text": "Measurements for one observation do not affect measurements for any other observation (assumes independence).\nData in each group must be obtained via a random sample from the population.\nData in each group are normally distributed.\nData values are continuous.\nThe variances for the two independent groups are equal in the Student’s t test.\nThere should be no significant outliers."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#hypotheses",
    "href": "lessons_original/03_two_sample_ttest.html#hypotheses",
    "title": "Two sample t test",
    "section": "",
    "text": "(H_0): the mean of group A (m_A) is equal to the mean of group B (m_B)- two tailed test,\n(H_0): (m_A)\\ge (m_B)- one tailed test.\n(H_0): (m_A)\\le (m_B)- one tailed test.\nThe corresponding alternative hypotheses would be as follows:\n\n\n\n(H_1): (m_A)\\neq(m_B)- two tailed test.\n(H_1): (m_A)&lt;(m_B)- one tailed test.\n(H_1): (m_A)&gt; (m_B)- one tailed test."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#statistical-hypotheses-formula",
    "href": "lessons_original/03_two_sample_ttest.html#statistical-hypotheses-formula",
    "title": "Two sample t test",
    "section": "",
    "text": "For the Student’s t test which assumes equal variance the following is how the |t| statistic may be calculated using groups A and B as examples:\nt ={ {m_{A} - m_{B}} \\over \\sqrt{ {S^2 \\over n_{A} } + {S^2 \\over n_{B}}   }}\nThis can be described as the sample mean difference divided by the sample standard deviation of the sample mean difference where:\nm_A and m_B are the mean values of A and B,\nn_A and n_B are the seize of group A and B,\nS^2 is the estimator for the pooled variance,\nwith the degrees of freedom (df) = n_A + n_B - 2,\nand S^2 is calculated as follows:\nS^2 = { {\\sum{ (x_A-m_{A})^2} + \\sum{ (x_B-m_{B})^2}} \\over {n_{A} + n_{B} - 2 }}\nResults for both Students t test and Welch’s t test are usually similar unless the group sizes and standard deviations are different.\nWhat if the data is not independent?\nIf the data is not independent such as paired data in the form of matched pairs which are correlated, we use the paired t test. This test checks whether the means of two paired groups are different from each other. It’s usually used in clinical trial studies with a “before and after” or case control studies with matched pairs. For this test we only assume the difference of each pair to be normally distributed (the paired groups are the ones important for analysis) unlike the independent t test which assumes that data from both samples are independent and variances are equal.(fralick?)"
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#example",
    "href": "lessons_original/03_two_sample_ttest.html#example",
    "title": "Two sample t test",
    "section": "",
    "text": "tidyverse: data manipulation and visualization.\nrstatix: providing pipe friendly R functions for easy statistical analyses.\ncar: providing variance tests.\n\n\n\nCode\n#install.packages(\"ggstatplot\") \n#install.packages(\"car\")\n#install.packages(\"rstatix\")\n#install.packages(tidyVerse)\n\n\n\n\n\nThis example dataset sourced from kaggle was obtained from surveys of students in Math and Portuguese classes in secondary school. It contains demographic information on gender, social and study information.(cortez2008?)\n\n\nCode\n# load relevant libraries\nlibrary(rcompanion)\nlibrary(car)\nlibrary (gt)\nlibrary(gtsummary)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(tidyverse)\n\n\n\n\nCode\n# load the dataset\nstu_math &lt;- read_csv(\"../data/03_student-mat.csv\")\n\n\nRows: 395 Columns: 33\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (17): school, sex, address, famsize, Pstatus, Mjob, Fjob, reason, guardi...\ndbl (16): age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking the data\n\n\nCode\n# check the data\nglimpse(stu_math)\n\n\nRows: 395\nColumns: 33\n$ school     &lt;chr&gt; \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\",…\n$ sex        &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\",…\n$ age        &lt;dbl&gt; 18, 17, 15, 15, 16, 16, 16, 17, 15, 15, 15, 15, 15, 15, 15,…\n$ address    &lt;chr&gt; \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\",…\n$ famsize    &lt;chr&gt; \"GT3\", \"GT3\", \"LE3\", \"GT3\", \"GT3\", \"LE3\", \"LE3\", \"GT3\", \"LE…\n$ Pstatus    &lt;chr&gt; \"A\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"A\", \"A\", \"T\", \"T\", \"T\",…\n$ Medu       &lt;dbl&gt; 4, 1, 1, 4, 3, 4, 2, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4,…\n$ Fedu       &lt;dbl&gt; 4, 1, 1, 2, 3, 3, 2, 4, 2, 4, 4, 1, 4, 3, 2, 4, 4, 3, 2, 3,…\n$ Mjob       &lt;chr&gt; \"at_home\", \"at_home\", \"at_home\", \"health\", \"other\", \"servic…\n$ Fjob       &lt;chr&gt; \"teacher\", \"other\", \"other\", \"services\", \"other\", \"other\", …\n$ reason     &lt;chr&gt; \"course\", \"course\", \"other\", \"home\", \"home\", \"reputation\", …\n$ guardian   &lt;chr&gt; \"mother\", \"father\", \"mother\", \"mother\", \"father\", \"mother\",…\n$ traveltime &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1,…\n$ studytime  &lt;dbl&gt; 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, 1, 1,…\n$ failures   &lt;dbl&gt; 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,…\n$ schoolsup  &lt;chr&gt; \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"n…\n$ famsup     &lt;chr&gt; \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\",…\n$ paid       &lt;chr&gt; \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", …\n$ activities &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"ye…\n$ nursery    &lt;chr&gt; \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes…\n$ higher     &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n$ internet   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\",…\n$ romantic   &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\"…\n$ famrel     &lt;dbl&gt; 4, 5, 4, 3, 4, 5, 4, 4, 4, 5, 3, 5, 4, 5, 4, 4, 3, 5, 5, 3,…\n$ freetime   &lt;dbl&gt; 3, 3, 3, 2, 3, 4, 4, 1, 2, 5, 3, 2, 3, 4, 5, 4, 2, 3, 5, 1,…\n$ goout      &lt;dbl&gt; 4, 3, 2, 2, 2, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 3, 2, 5, 3,…\n$ Dalc       &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ Walc       &lt;dbl&gt; 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 2, 1, 4, 3,…\n$ health     &lt;dbl&gt; 3, 3, 3, 5, 5, 5, 3, 1, 1, 5, 2, 4, 5, 3, 3, 2, 2, 4, 5, 5,…\n$ absences   &lt;dbl&gt; 6, 4, 10, 2, 4, 10, 0, 6, 0, 0, 0, 4, 2, 2, 0, 4, 6, 4, 16,…\n$ G1         &lt;dbl&gt; 5, 5, 7, 15, 6, 15, 12, 6, 16, 14, 10, 10, 14, 10, 14, 14, …\n$ G2         &lt;dbl&gt; 6, 5, 8, 14, 10, 15, 12, 5, 18, 15, 8, 12, 14, 10, 16, 14, …\n$ G3         &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14,…\n\n\nIn total there are 395 observations and 33 variables. We will drop the variables we do not need and keep the variables that will help us answer the following: Is there a difference between boys and girls in math final grades?\nH_0: There is no statistical difference between the final grades between boys and girls.\nH_1: There is a statistically significant difference in the final grades between the two groups.\n\n\nCode\n# creating a subset of the data \nmath = subset(stu_math, select= c(sex,G3))\nglimpse(math)\n\n\nRows: 395\nColumns: 2\n$ sex &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"…\n$ G3  &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14, 14, 10…\n\n\nSummary statistics- the dependent variable is continuous (grades=G3) and the independent variable is character but binary (sex).\n\n\nCode\n# summarizing our data\n summary(math)\n\n\n     sex                  G3       \n Length:395         Min.   : 0.00  \n Class :character   1st Qu.: 8.00  \n Mode  :character   Median :11.00  \n                    Mean   :10.42  \n                    3rd Qu.:14.00  \n                    Max.   :20.00  \n\n\nWe see that data ranges from 0-20 with 0 being people who were absent and could not take the test therefore missing data. We remove these 0 values before running the t test. However other models should be considered such as the zero inflated model to differentiate those who truly got a 0 and those who were not present to take test.\n\n\nCode\n# creating a boxplot to visualize the data with no outliers\nmath2 = subset(math, G3&gt;0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nVisualizing the data- we can use histograms and box lots to visualize the data to check for outliers and distribution thus checking for normality.\n\n\nCode\n# Histograms for data by groups \n\nmale = math2$G3[math2$sex == \"M\"]\nfemale = math2$G3[math2$sex == \"F\"]\n\n# plotting distribution for males\nplotNormalHistogram(\n  male, \n  breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for males \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for males seem to be normally distributed from 0-20. Data is approximately normal because we have a large amount of bins.\n\n\nCode\n# plotting distribution for females\nplotNormalHistogram(\n  female, breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for females \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for females also appear to be normally distributed. The final score across both is almost evenly distributed. However there seem to be a significant number of individuals who failed the test (grade=0).\n\n\nCode\n# plotting bar plot to see the distribution in sample size\nsample_size = table(math2$sex)\nbarplot(sample_size,main= \"Distribution of sample size by sex\")\n\n\n\n\n\n\n\n\n\nThe bar graph shows that there are slightly more females in the sample than males.\nIdentifying outliers\n\n\nCode\n# creating a boxplot to visualize the outliers (G3=0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nThe box plot shows us that there are no outliers as these have been removed in terms of people who had a score of 0. This score is not truly reflective of the performance between boys and girls as a grade of 0 may represent absentia or other reasons for the test not been taken. Therefore we opt to drop the outliers. We will compare to see if this decision affects the mean which appears similar from the above plot.\n\n\nCode\n# finding the mean for the groups with outliers\nmean(math$G3[math$sex==\"F\"])\n\n\n[1] 9.966346\n\n\nCode\nmean(math$G3[math$sex==\"M\"])\n\n\n[1] 10.91444\n\n\nCode\n# finding the mean for the groups without outliers\nmean(math2$G3[math2$sex==\"F\"])\n\n\n[1] 11.20541\n\n\nCode\nmean(math2$G3[math2$sex==\"M\"])\n\n\n[1] 11.86628\n\n\nThe mean has increased slightly and the difference decreased after removing the outliers but the distribution is still the same.\nCheck the equality of variances (homogeneity)\nWe can use the Levene’s test or the Bartlett’s test to check for homogeneity of variances. The former is in the car library and the later in the rstatix library. If the variances are homogeneous the p value will be greater than 0.05.\nOther tests include F test 2 sided, Brown-Forsythe and O’Brien but we shall not cover these.\n\n\nCode\n# running the Bartlett's test to check equal variance\nbartlett.test(G3~sex, data=math2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  G3 by sex\nBartlett's K-squared = 0.12148, df = 1, p-value = 0.7274\n\n\nCode\n# running the Levene's test to check equal variance\nmath2 %&gt;% levene_test(G3~sex)\n\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1   355     0.614 0.434\n\n\nThe p value is greater than 0.05 suggesting there is no difference between the variances of the two groups.\n\n\n\n\nData is continuous(G3)\nData is normally distributed\nData is independent (males and females distinct not the same individual)\nNo significant outliers\nThere are equal variances\n\nAs the assumptions are met we go ahead to perform the Student’s t test.\n\n\n\nSince the default is the Welch t test we use the \\color{blue}{\\text{var.eqaul = TRUE }} code to signify a Student’s t test. There is a t.test() function in stats package and a t_test() in the rstatix package. For this analysis we use the rstatix method as it comes out as a table.\n\n\nCode\n# perfoming the two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE) %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df      p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.0531 ns      \n\n\n\n\nCode\nstat.test$statistic\n\n\n        t \n-1.940477 \n\n\nThe results are represented as follows;\n\ny - dependent variable\ngroup1, group 2 - compared groups(independent variables)\ndf - degrees of freedom\np - p value\n\ngtsummary table of results\n\n\nCode\n math2 |&gt; \n  tbl_summary(\n    by = sex,\n    statistic =\n      list(\n        all_continuous() ~ \"{mean} ({sd})\",\n        all_dichotomous() ~ \"{p}%\")\n    ) |&gt; \n   add_n() |&gt; \n  add_overall() |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOverall, N = 3571\nF, N = 1851\nM, N = 1721\nDifference2\n95% CI2,3\np-value2\n\n\n\n\nG3\n357\n11.5 (3.2)\n11.2 (3.2)\n11.9 (3.3)\n-0.66\n-1.3, 0.01\n0.053\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n3 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nInterpretation of results\nFor the two sample t test with t(355) = -1.940477, p = 0.0531, the p value is greater than our alpha of 0.05 , we fail to reject the null hypothesis and conclude that there is no statistical difference between the means of the two groups. There is no difference in final grades between boys and girls. (A significant |t| would be 1.96 or greater).\nEffect size\nCohen’s d can be an used as an effect size statistic for the two sample t test. It is the difference between the means of each group divided by the pooled standard deviation.\nd= {m_A-m_B \\over SD_pooled}\nIt ranges from 0 to infinity, with 0 indicating no effect where the means are equal. 0.5 means that the means differ by half the standard deviation of the data and 1 means they differ by 1 standard deviation. It is divided into small, medium or large using the following cut off points.\n\nsmall 0.2-&lt;0.5\nmedium 0.5-&lt;0.8\nlarge &gt;=0.8\n\nFor the above test the following is how we can find the effect size;\n\n\nCode\n#perfoming cohen's d\nmath2 %&gt;% \n  cohens_d(G3~sex,var.equal = TRUE)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2 effsize    n1    n2 magnitude\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 G3    F      M       -0.206   185   172 small    \n\n\nThe effect size is small d= -0.20.\nIn conclusion, a two-samples t-test showed that the difference was not statistically significant, t(355) = -1.940477, p &lt; 0.0531, d = -0.20; where, t(355) is shorthand notation for a t-statistic that has 355 degrees of freedom and d is Cohen’s d. We can conclude that the females mean final grade is greater than males final grade (d= -0.20) but this result is not significant.\nWhat if it is one tailed t test?\nUse the \\color{blue}{\\text{alternative =}} option to determine if one group is \\color{blue}{\\text{\"less\"}} or \\color{blue}{\\text{\"greater\"}}. For example if we want to see whether the final grades for females are greater than males we can use the following code:\n\n\nCode\n# perfoming the one tailed two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE, alternative = \"greater\") %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df     p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.973 ns      \n\n\nThe p value is greater than 0.05 (p=0.973), we fail to reject the null hypothesis. We conclude that the final grades for females are not significantly greater than for males.\nWhat about running the paired sample t test?\nWe can simply add the syntax \\color{blue}{\\text{paired= TRUE}} to our t_test() to run the analysis for matched pairs data."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#conclusion",
    "href": "lessons_original/03_two_sample_ttest.html#conclusion",
    "title": "Two sample t test",
    "section": "",
    "text": "This article covers the Student’s t test and how we run it in R. It also shows how we find the effect size and how we can conclude the results."
  },
  {
    "objectID": "lessons/00_lesson_template.html",
    "href": "lessons/00_lesson_template.html",
    "title": "The Method",
    "section": "",
    "text": "# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n\n1 Introduction to &lt;the method&gt;\n\n\n2 Mathematical definition of &lt;the method&gt;\n\n\n3 Data source and description\n\n\n4 Cleaning the data to create a model data frame\n\n\n5 Assumptions of &lt;the method&gt;\n\n\n6 Checking the assumptions with plots\n\n\n7 Code to run &lt;the method&gt;\n\n\n8 Code output\nNOTE: this section will be created automatically by the Quarto document. You should not create a section specifically for this. When you run the code in the previous section, you will get the output automatically.\n\n\n9 Brief interpretation of the output"
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html",
    "href": "lessons/02_z-test_one_prop.html",
    "title": "Z-Test for One Proportion",
    "section": "",
    "text": "The one-sample \\(Z\\)-test is used to compare a sample proportion to a population proportion."
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#independence-and-randomness",
    "href": "lessons/02_z-test_one_prop.html#independence-and-randomness",
    "title": "Z-Test for One Proportion",
    "section": "6.1 Independence and Randomness",
    "text": "6.1 Independence and Randomness\nBecause the samples were collected at random via an FDA approved clinical trial protocol, we assume that all the participants were randomly selected and are independent of each other."
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#extreme-proportions",
    "href": "lessons/02_z-test_one_prop.html#extreme-proportions",
    "title": "Z-Test for One Proportion",
    "section": "6.2 “Extreme” Proportions",
    "text": "6.2 “Extreme” Proportions\nAccording to Ling et al. (2020), the 12-month abstinence proportion of all 533 participants in their study was 40.5 percent. As we can see here, our abstinence rates are 39.4. Neither these proportions are smaller than 5% or greater than 95%.\n\n(pExpected &lt;- 0.508 * (425/533))\n\n[1] 0.4050657\n\n# Count the number of TRUE values\n(nAbstinent &lt;- sum(outcomesCTN0094$kosten1993_isAbs))\n\n[1] 1402"
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#type-and-counts-of-data",
    "href": "lessons/02_z-test_one_prop.html#type-and-counts-of-data",
    "title": "Z-Test for One Proportion",
    "section": "6.3 Type and Counts of Data",
    "text": "6.3 Type and Counts of Data\nWe observe binary data, and we see at least 10 successes and at least 10 failures."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html",
    "href": "lessons/01_mosaic_violin.html",
    "title": "Mosaic & Box/Violin Plots",
    "section": "",
    "text": "# install.packages(\"public.ctn0094data\")\n# install.packages(\"tidyverse\")\n# install.packages(\"ggmosaic\")\n\nlibrary(public.ctn0094data)\nlibrary(tidyverse)\nlibrary(ggmosaic)"
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#mosaic-plot",
    "href": "lessons/01_mosaic_violin.html#mosaic-plot",
    "title": "Mosaic & Box/Violin Plots",
    "section": "6.1 Mosaic Plot",
    "text": "6.1 Mosaic Plot\n\n# mosaic\nmosaic_basic &lt;- demographics_final_df %&gt;% \n  ggplot() +\n  geom_mosaic(\n    aes(\n      x = product(project),\n      fill = race\n    )\n  ) +\n  labs(y=\"Race\", x=\"Project\", title = \"Mosaic Plot of Race by CTN Project\") +\n  theme_mosaic() +\n  theme(legend.position = \"none\")\n  \nmosaic_basic"
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#violin-plot",
    "href": "lessons/01_mosaic_violin.html#violin-plot",
    "title": "Mosaic & Box/Violin Plots",
    "section": "6.2 Violin Plot",
    "text": "6.2 Violin Plot\n\nviolin_basic &lt;- demographics_final_df %&gt;% \n  ggplot() +\n  aes(x = race, y = age, color = race) +\n  labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Violin Plot of Race and Age\",\n    subtitle = \"With Summary Information\",\n    color = \"Race\"\n  ) +\n  geom_violin() +\n  geom_boxplot(width=0.1)\n\nviolin_basic"
  }
]