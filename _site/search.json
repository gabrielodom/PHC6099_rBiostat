[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHC 6099: R Computing for Health Sciences",
    "section": "",
    "text": "These are the written lecture materials for the class PHC 6099 at Florida International University’s Stempel College of Public Health. This is the second semester of the “R” course sequence (the first semester is PHC6701; the text for that class is available here: https://gabrielodom.github.io/PHC6701_r4ds/) The source code and data sets for this book are available here: https://github.com/gabrielodom/PHC6099_rBiostat."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "lessons_original/01_ggplot2.html",
    "href": "lessons_original/01_ggplot2.html",
    "title": "How to create a scatterplot",
    "section": "",
    "text": "Scatterplots display the relationship between two variables using dots to represent the values for each numeric variable. This presentation will examine the relationship between GDP per capita and Fertility over time using ggplot with facets.\nHypothesis: A negative relationship exists between GDP per capita and fertility i.e. as GDP per capita increases, fertility decreases."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#introduction",
    "href": "lessons_original/01_ggplot2.html#introduction",
    "title": "How to create a scatterplot",
    "section": "",
    "text": "Scatterplots display the relationship between two variables using dots to represent the values for each numeric variable. This presentation will examine the relationship between GDP per capita and Fertility over time using ggplot with facets.\nHypothesis: A negative relationship exists between GDP per capita and fertility i.e. as GDP per capita increases, fertility decreases."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#data",
    "href": "lessons_original/01_ggplot2.html#data",
    "title": "How to create a scatterplot",
    "section": "Data",
    "text": "Data\nData was obtained from GapMinder for each health and non-health indicator and combined into one data set. The data includes information on over 180 countries and territories from the years 1800 to 2099. Countries and territories with missing information were not excluded from the data set as the lack of information can also be looked into and shed light on why data was not collected or provided.\nTo determine whether a country’s health and income outcomes are influenced by population sizes and GDP per capita, the data will be used to create a series of graphs to view different trends. It is important to note certain analysis’ will only be done on specific countries and on certain years. Predictive values were provided up until 2099 however, we will focus on years with full and current data.\n\n\nCode\n# Contains colour palette for ggplot\nlibrary(viridis)\n\n# Contains \"gganimate\"\nlibrary(ggplot2)\nlibrary(gganimate)\n\nlibrary(tidyverse)\n\n\n# Reads csv file\ngapminder_data &lt;-  \n  # read_csv(\"clean_data/gapminder_scatterplot.csv\")\n  read_csv(\"../data/gapminder_2024spring.csv\")"
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#how-to-create-a-scatter-plot",
    "href": "lessons_original/01_ggplot2.html#how-to-create-a-scatter-plot",
    "title": "How to create a scatterplot",
    "section": "How to create a scatter-plot",
    "text": "How to create a scatter-plot\n\nIntro to ggplot2\nGgplot2 is a package used to create graphs and visualize data. The main three components of ggplot2 are the data, aesthetics and geom layers.\n\nThe data layer - states what data will be used to graph\nThe aesthetics layer - specifies the variables that are being mapped\nThe geom layer - specifies the type of graph to be produced\n\n\n\n\n\n\n\n\nBasic scatter-plot using ggplot2\nIn order to create a scatter-plot using ggplot, you must specify what data you will be using, state which variables will be mapped and how under aesthetics. What differentiates the scatter-plot from any other type of graph will be specified under the geom layer. For the scatter-plot, geom_point will be used.\nIn this example, we will analyze the relationship between fertility rates and gdp per capita for each country in 2011.\n\nfig_bubble_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(x = gdp_per_capita, y = fertility) +\n  geom_point()\n\nfig_bubble_2011 \n\n\n\n\n\n\n\n\n\n\nElevating your scatter-plot\nIn the example above, we have mapped out fertility as our y-axis and gdp per capita as our x-axis. However, at it’s very basic level, there is not enough information provided to accurately analyze the relationship between the two. For this reason, we can add additional layers that will provide more information to properly analyze the scatter-plot.\n\n\nCode\nfig_bubble_pretty_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    # will change the size of the point based on population size \n    size = population, \n    # will assign colors based on the continent the country is in \n    color = continent\n  ) +\n  # gives a range as to how big or small the points of population should be\n  scale_size(range = c(1, 20)) + \n  # removes N/A from the legend and titles it Continent \n  scale_colour_discrete(na.translate = F, name = \"Continent\") +\n  # removes population size from the legend \n  guides(size = \"none\") +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    # transforms numbers from scientific notation to regular number \n    labels = scales::comma\n  ) +\n  labs(\n    title = \"Fertility rate descreases as GDP per capita increases in 2011\",\n    y = \"Fertility rates\",\n    caption = \"Source: Gapminder\"\n  ) +\n  # the ylim was set based on the fertility, lowest was 1.15 & highest was 7.25\n  ylim(1.2, 8.0) +\n  # alpha increases transparency of the points to ensure they can all be seen\n  geom_point(alpha = 0.5) \n\nfig_bubble_pretty_2011\n\n\n\n\n\n\n\n\n\n[@ggplot-2011-adv] builds on the previous scatterplot of Fertility Rates (y axis) against GDP per capita (x axis) for 2011. The bubble size depicts respective country populations, and continents are coded by colors according to the key. This figure displays a negative relationship between GDP per capita and Fertility Rates. It supports the Hypothesis which states that as GDP per capita increases, Fertility Rates decreases. This trend can be confirmed for all continents, however, the degree to which fertility rates drop between continents varies. Most European country appear below a fertility rate of 2 babies per woman. The Americas appear to follow closely behind (under 4), followed by Oceania and Asia. A significant number of African countries still maintained higher fertility rates with lower GDP per capita for 2011.\n\n\nFacets\nHere is an example of wanting to create four separate graphs to see the relationship between fertility rates and GDP per capita based on the years 1860, 1910, 1960 and 2010. In this example we omitted the facet argument.\n\n\nCode\nfig_bubble_multiple &lt;-\n  ggplot(data = filter(gapminder_data, year %in% c(1860, 1910, 1960, 2010))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE, name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    subtitle = \"throughout 1860, 1910, 1960 and 2010\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) \n\nfig_bubble_multiple\n\n\n\n\n\n\n\n\n\nWithout having used the facet argument, all points of all four years have been included into one graph. This graph does not provide us with the information we were looking for.\n\n\nCode\nfig_bubble_multiple_facet &lt;-\n  ggplot(data = filter(gapminder_data, year %in% c(1860, 1910, 1960, 2010))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE , name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    subtitle = \"throughout 1860, 1910, 1960 and 2010\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) +\n  # specifiying we want the graphs split based on year\n  facet_wrap(~ year)\n\nfig_bubble_multiple_facet\n\n\n\n\n\n\n\n\n\nNow that we’ve specified the facet argument, we now have four seperate graphs that can be properly analysed. In [@ggplot-facet-years] we see an increasingly negative relationship between the two variables over time. This observation is congruent with the hypothesis that as GDP per capita increases, fertility decreases.\nThis global trend can be attributed to the increasing proportion of women in the workforce in the mid to late 20th century. As a result of World War II (1939-1945), women took on roles outside the home to compensate for men at war. Despite increased GDP per capita, this may have contributed to reduced fertility (babies per woman) over time. During 1860 - 1910, the scatter-plot figures remained in the upper left quadrant with the numbers remaining between 2 - 8 babies per woman. In 1960, a clear disparity among continents is seen. Most European countries’ fertility rates fell below 5, while their GDP per capita increased. Most African countries maintained high fertility rates above 5, but little change is seen in GDP per capita. The Asian continent shows the most variation among countries during that year. Some smaller Asian countries continued to maintain high fertility rates as GDP per capita increased in 1960. However, others displayed a drastic decrease in fertility rates by 1960. The Americas followed a steady decline over the years. By 2010, an overall negative relationship can be seen with most countries’ fertility rates below 5 babies per woman.\n\nfig_bubble_row_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent, nrow = 1)\n\nfig_bubble_row_2011 \n\n\n\n\n\n\n\n\nIn the graph above, we see an example of seperating the single graph into graphs based on continent. It has also been specified to have all graphs appear in one single row through the nrow argument. However, this graph is also unclear and cannot be used to compare the relationship between fertility and gdp per capita.\n\nfig_bubble_facet_2011 &lt;-\n  ggplot(data = filter(gapminder_data, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent)\n\nfig_bubble_facet_2011 \n\n\n\n\n\n\n\n\nIn the next example above, we removed the nrow argument and the system automatically seperated the graphs into three columns with two rows. However, again, there is no way to clearly determine any relationship between fertility and gdp per capita."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#scatterplot-animation",
    "href": "lessons_original/01_ggplot2.html#scatterplot-animation",
    "title": "How to create a scatterplot",
    "section": "Scatterplot animation",
    "text": "Scatterplot animation\nGGplot2 contains the “gganimate” package that allows for animation of data. It enhances data visualization through real-time outputs. In this case the gapminder data will be filtered to 2011 and below (full data available).\n\n\nCode\ngapminder_df &lt;- \n  gapminder_data %&gt;% \n  # Excludes data beyond 2011 (last year with complete data)\n  filter(year &lt;= \"2011\")\n\nfig_animate &lt;- \n  ggplot(gapminder_df) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent \n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  # Assigns color palette \n  scale_color_viridis_d() +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  geom_point(show.legend = TRUE, alpha = 0.7) +\n  # Assigns the gganimate features\n  transition_time(year) +\n  ease_aes('linear', interval = 2.0) +\n  # Prints time of current frame\n  labs(title = \"Year: {frame_time}\", x = \"GDP per capita\", y = \"Fertility\")\n  \n\nfig_animate\n\n\nNULL\n\n\n@plot-animate depicts the changes between Fertility and GDP per capita as the years increase from 1799 to 2011 (last full data year). This allows real-time visualization of the decrease in fertility and increase in GDP per capita.\n\n\nCode\nfacet_animate &lt;- \n  ggplot(gapminder_df) +\n  aes(\n    x = gdp_per_capita, \n    y = fertility,\n    size = population, \n    colour = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  # Groups output by continents\n  facet_wrap(~continent) +\n  labs(\n    title = 'Year: {closest_state}', \n    x = 'GDP per capita', \n    y = 'fertility'\n  ) +\n  geom_point(alpha = 0.7, show.legend = TRUE) +\n  # Contains gganimate features\n  transition_states(year, transition_length = 3, state_length = 1) +\n  # Animation pattern, time between each state\n  ease_aes('linear', interval = 2.0)\n\nfacet_animate\n\n\nNULL\n\n\nIn @animate-facets, the ggplot data for various continents as time passes is shown to support the initial hypothesis."
  },
  {
    "objectID": "lessons_original/01_ggplot2.html#conclusion",
    "href": "lessons_original/01_ggplot2.html#conclusion",
    "title": "How to create a scatterplot",
    "section": "Conclusion",
    "text": "Conclusion\nA global negative trend is depicted between GDP per capita and fertility over time. Such changes were due to wars as well as social, cultural and economic changes that incentivize smaller families especially in Asian countries. Most European, American and Asian countries depicted significant decreases in fertility rates over time as GDP per capita increased. On the other hand, African countries remain in the top rank for fertility over the years. These differences are depicted in the population pyramid changes of developed vs developing countries. Public health policies can be tailored to incentivizing increased fertility in developed countries to ensure generation continuity, and effective family planning strategies in developing countries."
  },
  {
    "objectID": "lessons_original/01_rayshader.html",
    "href": "lessons_original/01_rayshader.html",
    "title": "R Rayshader Overview",
    "section": "",
    "text": "R rayshader is an R package that allows users to generate high-quality 3D maps, visualizations, and animations.\nrayshader also allows the user to translate ggplot2 objects into beautiful 3D data visualizations.\n\nTo install rayshader, you can use the following code in R:\n\n# remotes::install_github(\n#   \"tylermorganwall/rayshader\"\n# )\n\n# remotes::install_cran(\"rayrender\")"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#overview",
    "href": "lessons_original/01_rayshader.html#overview",
    "title": "R Rayshader Overview",
    "section": "",
    "text": "R rayshader is an R package that allows users to generate high-quality 3D maps, visualizations, and animations.\nrayshader also allows the user to translate ggplot2 objects into beautiful 3D data visualizations.\n\nTo install rayshader, you can use the following code in R:\n\n# remotes::install_github(\n#   \"tylermorganwall/rayshader\"\n# )\n\n# remotes::install_cran(\"rayrender\")"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#functions",
    "href": "lessons_original/01_rayshader.html#functions",
    "title": "R Rayshader Overview",
    "section": "Functions",
    "text": "Functions\n\nrayshader 0.35. 1 has 56 functions and 4 datasets\nseven functions related to mapping\nalso has functions to add water and generate overlays\nalso included are functions to add additional effects and information to 3D visualizations\nfunctions for converting rasters to matrices\nfunctions to display and save your visualizations\nrayshader has a function to generate 3D plots using ggplot2 objects"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#example",
    "href": "lessons_original/01_rayshader.html#example",
    "title": "R Rayshader Overview",
    "section": "Example",
    "text": "Example\nFirst we load all the required libraries. These libraries are required for various functions and operations used in creating 3D maps with rayshader.\n\nlibrary(rayshader)\nlibrary(rayrender) \nlibrary(reshape2)\nlibrary(tidyverse)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#example-1",
    "href": "lessons_original/01_rayshader.html#example-1",
    "title": "R Rayshader Overview",
    "section": "Example",
    "text": "Example\nThen, we download and load the data\n\n# Here, I load a map with the raster package.\nloadzip &lt;- tempfile() \n\ndownload.file(\"https://tylermw.com/data/dem_01.tif.zip\", loadzip)\n\nlocaltif &lt;- raster::raster(\n  unzip(loadzip, \"dem_01.tif\")\n)\n\nunlink(loadzip)\n\n# write_rds(localtif, \"../data/01_rayshader_eg_20240503.rds\")\n\nIn this code snippet, we create a temporary file (loadzip) to store the downloaded zip file from the specified URL. The download.file() function is used to download the file, and unzip() is used to extract the “dem_01.tif” file from the downloaded zip. Finally, we load the raster data into the localtif object."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#create-map",
    "href": "lessons_original/01_rayshader.html#create-map",
    "title": "R Rayshader Overview",
    "section": "Create Map",
    "text": "Create Map\nTo create a map first we need to convert this raster data file into a matrix using raster_to_matrix()\n\n#And convert it to a matrix:\nelmat &lt;- raster_to_matrix(localtif)\n\nLoading required package: raster\n\n\nLoading required package: sp\n\n\n\nAttaching package: 'raster'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\nThen we use sphere_shade() and plot_map() to create our base map\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nHere, elmat is a matrix created from the raster data using the raster_to_matrix() function. sphere_shade() applies shading to the elevation matrix, giving it a 3D effect. The texture parameter specifies the type of texture to be applied. In this case, it uses the “desert” texture. Finally, plot_map() is used to display the shaded map."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#add-water-layer",
    "href": "lessons_original/01_rayshader.html#add-water-layer",
    "title": "R Rayshader Overview",
    "section": "Add Water Layer",
    "text": "Add Water Layer\nWe can add a water layer to the map using detect_water() and add_water()\n\n# detect_water and add_water adds a water layer to the map:\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nIn this code snippet, detect_water() function detects water areas in the elevation matrix. Then, add_water() adds a water layer to the map using the detected water areas. The color parameter specifies the color of the water. Finally, plot_map() is used to display the map with the water layer."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#add-shadow-layer",
    "href": "lessons_original/01_rayshader.html#add-shadow-layer",
    "title": "R Rayshader Overview",
    "section": "Add Shadow Layer",
    "text": "Add Shadow Layer\nWe can also add shadow layer in the map.\n\n# And here we add an ambient occlusion shadow layer, which models lighting\n#   from atmospheric scattering:\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  add_shadow(ray_shade(elmat), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat), 0) %&gt;%\n  plot_map()\n\n\n\n\n\n\n\n\nHere, add_shadow() is used to add a shadow layer to the map. ray_shade() calculates shadows based on the elevation matrix (elmat). The zscale parameter controls the strength of the shadows. ambient_shade() generates ambient lighting for the map. The second parameter of add_shadow() specifies the opacity of the shadows. Finally, plot_map() displays the map with shadows."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#convert-to-3d",
    "href": "lessons_original/01_rayshader.html#convert-to-3d",
    "title": "R Rayshader Overview",
    "section": "Convert to 3D",
    "text": "Convert to 3D\nWe can convert this 2D map into 3D mapping using plot_3d() (by passing a texture map into the plot_3d function)\n\nelmat %&gt;%\n  sphere_shade(texture = \"desert\") %&gt;%\n  add_water(detect_water(elmat), color = \"desert\") %&gt;%\n  add_shadow(ray_shade(elmat, zscale = 3), 0.5) %&gt;%\n  add_shadow(ambient_shade(elmat), 0) %&gt;%\n  plot_3d(\n    elmat, zscale = 10, fov = 0, theta = 135,\n    zoom = 0.75, phi = 45, windowsize = c(1000, 800)\n  )\nSys.sleep(0.2)\nrender_snapshot()\n\n\n\n\n\n\n\n\nWe can add a scale bar, as well as a compass using render_scalebar() and render_compass()\n\nrender_camera(fov = 0, theta = 60, zoom = 0.75, phi = 45)\nrender_scalebar(\n  limits = c(0, 5, 10),\n  label_unit = \"km\",\n  position = \"W\",\n  y = 50,\n  scale_length = c(0.33,1)\n)\nrender_compass(position = \"E\")\nrender_snapshot(clear = TRUE)\n\n\n\n\n\n\n\n\nHere, render_camera() sets the camera properties for the 3D map. render_scalebar() adds a scale bar to the map. The limits parameter specifies the limits of the scale bar, label_unit provides the label for the scale, position sets the position of the scale bar, y controls the vertical position, and scale_length determines the length of the scale bar. render_compass() adds a compass to the map, and render_snapshot() captures the final image of the map."
  },
  {
    "objectID": "lessons_original/01_rayshader.html#d-plotting-with-rayshader-and-ggplot2",
    "href": "lessons_original/01_rayshader.html#d-plotting-with-rayshader-and-ggplot2",
    "title": "R Rayshader Overview",
    "section": "3D plotting with rayshader and ggplot2",
    "text": "3D plotting with rayshader and ggplot2\nRayshader can also be used to make 3D plots out of ggplot2 objects using the plot_gg() function\n\nggdiamonds = ggplot(diamonds) +\n  stat_density_2d(\n    aes(\n      x = x, y = depth, fill = stat(nlevel)\n    ), \n    geom = \"polygon\", n = 200, bins = 50,contour = TRUE\n  ) +\n  facet_wrap(clarity~.) +\n  scale_fill_viridis_c(option = \"A\")\n\npar(mfrow = c(1, 2))\n\nplot_gg(ggdiamonds, width = 5, height = 5, raytrace = FALSE, preview = TRUE)\n\nWarning: `stat(nlevel)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(nlevel)` instead.\n\n\n\n\n\n\n\n\nplot_gg(\n  ggdiamonds, \n  width = 5, \n  height = 5, \n  multicore = TRUE, \n  scale = 250, \n  zoom = 0.7, \n  theta = 10, \n  phi = 30, \n  windowsize = c(800, 800)\n)\nSys.sleep(0.2)\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#contour-plot",
    "href": "lessons_original/01_rayshader.html#contour-plot",
    "title": "R Rayshader Overview",
    "section": "Contour Plot",
    "text": "Contour Plot\nRayshader will automatically ignore lines and other elements that should not be mapped to 3D.\nHere’s a contour plot of the volcano dataset.\n\n# Contours and other lines will automatically be ignored. Here is the volcano\n#   dataset:\n\nggvolcano &lt;- volcano %&gt;% \n  melt() %&gt;%\n  ggplot() +\n  geom_tile(aes(x = Var1, y = Var2, fill = value)) +\n  geom_contour(aes(x = Var1, y = Var2, z = value), color = \"black\") +\n  scale_x_continuous(\"X\", expand = c(0, 0)) +\n  scale_y_continuous(\"Y\", expand = c(0, 0)) +\n  scale_fill_gradientn(\"Z\", colours = terrain.colors(10)) +\n  coord_fixed()\n\npar(mfrow = c(1, 2))\nplot_gg(ggvolcano, width = 7, height = 4, raytrace = FALSE, preview = TRUE)\n\nWarning: Removed 1861 rows containing missing values or values outside the scale range\n(`geom_contour()`).\n\n\n\n\n\n\n\n\n\n\nplot_gg(\n  ggvolcano,\n  multicore = TRUE, \n  raytrace = TRUE, \n  width = 7, \n  height = 4, \n  scale = 300, \n  windowsize = c(1400, 866), \n  zoom = 0.6, \n  phi = 30, \n  theta = 30\n)\n\nWarning: Removed 1861 rows containing missing values or values outside the scale range\n(`geom_contour()`).\n\nSys.sleep(0.2)\n\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#mtcars-data-example",
    "href": "lessons_original/01_rayshader.html#mtcars-data-example",
    "title": "R Rayshader Overview",
    "section": "mtcars Data Example",
    "text": "mtcars Data Example\nRayshader also detects when the user passes the color aesthetic, and maps those values to 3D\n\nmtplot = ggplot(mtcars) + \n  geom_point(\n    aes(x = mpg, y = disp, color = cyl)\n  ) + \n  scale_color_continuous(limits = c(0, 8))\n\npar(mfrow = c(1, 2))\nplot_gg(mtplot, width = 3.5, raytrace = FALSE, preview = TRUE)\n\n\n\n\n\n\n\nplot_gg(mtplot)\nSys.sleep(0.2)\nrender_snapshot(clear = TRUE)"
  },
  {
    "objectID": "lessons_original/01_rayshader.html#reference",
    "href": "lessons_original/01_rayshader.html#reference",
    "title": "R Rayshader Overview",
    "section": "Reference",
    "text": "Reference\n\nhttps://www.rayshader.com/\nhttps://www.youtube.com/watch?v=zgFXVhmKNbU"
  },
  {
    "objectID": "lessons_original/01_skimr.html",
    "href": "lessons_original/01_skimr.html",
    "title": "Skimr Package",
    "section": "",
    "text": "Skimr is an R package designed to provide summary statistics about variables in data frames, tibbles, data tables and vectors. The function is modifiable where you can add additional variables, which are not a part of default summary function within R. Skimr allows us to quickly assess data quality by feature and type in a quick report. This is a critical step in Data Exploration, where Understanding our data helps us to generate a hypothesis and determine what data analysis are appropriate.\nThis presentation will cover the simplest and most effective ways to explore data in R.\n\n\nTo begin we will upload the packages necessary for the lesson, this includes the following:\n\nreadr() to import our data file\nknitr() that houses the kable() feature that allows us to construct and customize tables.\ntidyverse houses the dyplyrpackage that assists with data manipulation and visualization.\nTheskimrpackage provides a compact summary of the variables in a dataset.\n\n\n\nCode\n# install.packages(\"skimr\")\n# install.packages(\"knitr\")\n# install.packages(\"tidyverse\")\n\n# load all the packages we will need to analyze the data and use the skim\n#   function\nlibrary(skimr)\nlibrary(knitr)\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n\n\n\nFor this assignment we will be using the Census_2010 dataset. There is no code book associated with the data, making it difficult to provide an accurate description of the variables. The information recorded shows the United States population estimates from the years 2010-2015, as well as relevant variables like net population change, number of births, number of deaths, international and domestic migration. Within the dataframe, there are 3,193 observations and 100 variables.\nThe data can be imported into R from the following link: https://fiudit-my.sharepoint.com/:x:/g/personal/ssinc013_fiu_edu/ESK1A13PstVGtf7HUwNNt68Bnh1YPfH8L-hnvMUxjBuCVw?e=CCwQU9\n\n\nCode\n# import the data\n# census_2010 &lt;- read_csv(\"Data/census_2010.csv\")\ncensus_2010 &lt;- readxl::read_xlsx(\"../data/01_census_2010.xlsx\")\n\n# what are the variables\ncolnames(census_2010) %&gt;% \n  head(n = 10)\n [1] \"SUMLEV\"            \"REGION\"            \"DIVISION\"         \n [4] \"STATE\"             \"COUNTY\"            \"STNAME\"           \n [7] \"CTYNAME\"           \"CENSUS2010POP\"     \"ESTIMATESBASE2010\"\n[10] \"POPESTIMATE2010\""
  },
  {
    "objectID": "lessons_original/01_skimr.html#packages",
    "href": "lessons_original/01_skimr.html#packages",
    "title": "Skimr Package",
    "section": "",
    "text": "To begin we will upload the packages necessary for the lesson, this includes the following:\n\nreadr() to import our data file\nknitr() that houses the kable() feature that allows us to construct and customize tables.\ntidyverse houses the dyplyrpackage that assists with data manipulation and visualization.\nTheskimrpackage provides a compact summary of the variables in a dataset.\n\n\n\nCode\n# install.packages(\"skimr\")\n# install.packages(\"knitr\")\n# install.packages(\"tidyverse\")\n\n# load all the packages we will need to analyze the data and use the skim\n#   function\nlibrary(skimr)\nlibrary(knitr)\nlibrary(readxl)\nlibrary(tidyverse)"
  },
  {
    "objectID": "lessons_original/01_skimr.html#census-data",
    "href": "lessons_original/01_skimr.html#census-data",
    "title": "Skimr Package",
    "section": "",
    "text": "For this assignment we will be using the Census_2010 dataset. There is no code book associated with the data, making it difficult to provide an accurate description of the variables. The information recorded shows the United States population estimates from the years 2010-2015, as well as relevant variables like net population change, number of births, number of deaths, international and domestic migration. Within the dataframe, there are 3,193 observations and 100 variables.\nThe data can be imported into R from the following link: https://fiudit-my.sharepoint.com/:x:/g/personal/ssinc013_fiu_edu/ESK1A13PstVGtf7HUwNNt68Bnh1YPfH8L-hnvMUxjBuCVw?e=CCwQU9\n\n\nCode\n# import the data\n# census_2010 &lt;- read_csv(\"Data/census_2010.csv\")\ncensus_2010 &lt;- readxl::read_xlsx(\"../data/01_census_2010.xlsx\")\n\n# what are the variables\ncolnames(census_2010) %&gt;% \n  head(n = 10)\n [1] \"SUMLEV\"            \"REGION\"            \"DIVISION\"         \n [4] \"STATE\"             \"COUNTY\"            \"STNAME\"           \n [7] \"CTYNAME\"           \"CENSUS2010POP\"     \"ESTIMATESBASE2010\"\n[10] \"POPESTIMATE2010\""
  },
  {
    "objectID": "lessons_original/01_skimr.html#separate-dataframes-by-type",
    "href": "lessons_original/01_skimr.html#separate-dataframes-by-type",
    "title": "Skimr Package",
    "section": "4.1 Separate dataframes by type",
    "text": "4.1 Separate dataframes by type\nThe data frames produced by skim() are wide and sparse, filled with columns that are mostly NA. For that reason, it can be convenient to work with “by type” subsets of the original data frame. These smaller subsets have their NA columns removed.\nFeatures:\n\npartition() - Creates a list of smaller data frames. Each entry in the list is a data type from the original dataframe\nbind() - Takes the list and rebuilds the original dataframe.\nyank() - Extract a subtable from a dataframe with a particular type.\n\nThe following syntax is using partition() to separate the large census_df.\n\n\nCode\n# split the character and numeric data\nseparate_df &lt;- partition(skim(census_2010))\n# check only the character data\nseparate_df$character\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n\n\n\n\n\nCode\n\n# create summary statistics for only numeric variables\nnumeric_separate_df &lt;- separate_df[2]\n# pull out the desired summary statistics in the nested list\nhead(numeric_separate_df$numeric[\"mean\"]) %&gt;% \n  kable(digits = 1) \n\n\n\n\n\nmean\n\n\n\n\n49.8\n\n\n2.7\n\n\n5.2\n\n\n30.3\n\n\n101.9\n\n\n193387.1\n\n\n\n\n\nThe following syntax is using bind() to combine the smaller character and numeric lists into the desired df.\n\n\nCode\n# combine the character and numeric data\nhead(bind(separate_df))\n\n\n\nData summary\n\n\nName\ncensus_2010\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSUMLEV\n0\n1\n49.84\n1.25\n40\n50\n50\n50\n50\n▁▁▁▁▇\n\n\nREGION\n0\n1\n2.67\n0.81\n1\n2\n3\n3\n4\n▁▆▁▇▂\n\n\nDIVISION\n0\n1\n5.19\n1.97\n1\n4\n5\n7\n9\n▂▇▅▆▃\n\n\nSTATE\n0\n1\n30.26\n15.15\n1\n18\n29\n45\n56\n▃▇▆▆▇\n\n\n\n\n\nCode\n\n# confirm that the bound table is the same as the original skimmed table\nidentical(bind(separate_df), skim(census_2010)) \n[1] TRUE\n\n\nThe following syntax is using yank() to extract a specific table eg.character to examine.\n\n\nCode\n# Extract character data\nyank(skim(census_2010), \"character\")\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0"
  },
  {
    "objectID": "lessons_original/01_skimr.html#skimr-with-dplyr",
    "href": "lessons_original/01_skimr.html#skimr-with-dplyr",
    "title": "Skimr Package",
    "section": "4.2 Skimr with Dplyr",
    "text": "4.2 Skimr with Dplyr\nSkimr functions can be used in combination with Dplyr functions to examine specific variables within the census dataset.\nThe following example used skim() with filter() to display the variable CENSUS2010POP. The dataframe was further customized to display variable name and data type using select().\n\n\nCode\n# use dplyr functions on the statistics summary table\ncensus_filter &lt;- skim(census_2010) %&gt;% \n  filter(skim_variable == \"CENSUS2010POP\")\ncensus_filter\n\n\n\nData summary\n\n\nName\ncensus_2010\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCENSUS2010POP\n0\n1\n193387\n1176201\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n\n\n\n\n\nCode\n\ncensus_select &lt;- skim(census_2010) %&gt;% \n  select(skim_type, skim_variable)\nhead(census_select)\n# A tibble: 6 × 2\n  skim_type skim_variable\n  &lt;chr&gt;     &lt;chr&gt;        \n1 character STNAME       \n2 character CTYNAME      \n3 numeric   SUMLEV       \n4 numeric   REGION       \n5 numeric   DIVISION     \n6 numeric   STATE        \n\n\nYou can also customize the output of the skim() function by using various arguments. For example, you can use the numeric argument to specify which variables should be treated as numeric variables, or use the ranges argument to specify custom ranges for variables.\nUsing skim() in combination with mutate() we will compute a new variable to add to our skim dataframe.\n\n\nCode\n# create a new variable calculate the change in birth rate from 2010 to 2011\ncensus_2010 %&gt;% \n  # new variable\n  mutate(net_birth = BIRTHS2011 - BIRTHS2010) %&gt;% \n  # move the variable to the beginning of the dataset\n  relocate(net_birth, .after = CENSUS2010POP) %&gt;% \n  # summary statistics table\n  skim() %&gt;% \n  # only the first fifteen variables\n  head(n = 15) %&gt;% \n  # change the formatting \n  kable(digit = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nSTNAME\n0\n1\n4\n20\n0\n51\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nSUMLEV\n0\n1\nNA\nNA\nNA\nNA\nNA\n4.98e+01\n1.25e+00\n40\n50\n50\n50\n50\n▁▁▁▁▇\n\n\nnumeric\nREGION\n0\n1\nNA\nNA\nNA\nNA\nNA\n2.67e+00\n8.10e-01\n1\n2\n3\n3\n4\n▁▆▁▇▂\n\n\nnumeric\nDIVISION\n0\n1\nNA\nNA\nNA\nNA\nNA\n5.19e+00\n1.97e+00\n1\n4\n5\n7\n9\n▂▇▅▆▃\n\n\nnumeric\nSTATE\n0\n1\nNA\nNA\nNA\nNA\nNA\n3.03e+01\n1.52e+01\n1\n18\n29\n45\n56\n▃▇▆▆▇\n\n\nnumeric\nCOUNTY\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.02e+02\n1.08e+02\n0\n33\n77\n133\n840\n▇▁▁▁▁\n\n\nnumeric\nCENSUS2010POP\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.93e+05\n1.18e+06\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n\n\nnumeric\nnet_birth\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.87e+03\n1.18e+04\n-3\n96\n232\n639\n386443\n▇▁▁▁▁\n\n\nnumeric\nESTIMATESBASE2010\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.93e+05\n1.18e+06\n82\n11299\n26446\n71491\n37254503\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2010\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.94e+05\n1.18e+06\n83\n11275\n26467\n71721\n37334079\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2011\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.95e+05\n1.19e+06\n90\n11277\n26417\n72387\n37700034\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2012\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.97e+05\n1.20e+06\n81\n11195\n26362\n72496\n38056055\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2013\n0\n1\nNA\nNA\nNA\nNA\nNA\n1.98e+05\n1.21e+06\n89\n11180\n26519\n72222\n38414128\n▇▁▁▁▁\n\n\nnumeric\nPOPESTIMATE2014\n0\n1\nNA\nNA\nNA\nNA\nNA\n2.00e+05\n1.22e+06\n87\n11121\n26483\n72257\n38792291\n▇▁▁▁▁"
  },
  {
    "objectID": "lessons_original/01_skimr.html#adding-variables",
    "href": "lessons_original/01_skimr.html#adding-variables",
    "title": "Skimr Package",
    "section": "4.3 Adding Variables",
    "text": "4.3 Adding Variables\n\nbase - An sfl that sets skimmers for all column types.\nappend - Whether the provided options should be in addition to the defaults already in skim. Default is TRUE.\n\nAs mentioned, skim() is designed to display default statistics, however you can use this function to change the summary statistics that it returns.\nskim_with() is type closure: a function that returns adds a new variable to the table. This lets you have several skimming functions in a single R session, but it also means that you need to assign the return of skim_with() before you can use it.\nYou assign values within skim_with() by using the sfl() helper (skimr function list). It identifies which skimming functions you want to remove, by setting them to NULL. Assign an sfl to each column type that you wish to modify.\nFor example, we will add the following variables to the dataframe: median, min, max, IQR, length.\n\n\nCode\nmy_skim &lt;- skim_with(\n  numeric = sfl(median, min, max, IQR),\n  character = sfl(length), \n  append = TRUE\n)\n\n# add new variables into the summary table\ncensus_2010 %&gt;% \n  my_skim() %&gt;% \n  head(n = 10)\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n3193\n\n\nNumber of columns\n100\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\nlength\n\n\n\n\nSTNAME\n0\n1\n4\n20\n0\n51\n0\n3193\n\n\nCTYNAME\n0\n1\n4\n33\n0\n1927\n0\n3193\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nmedian\nmin\nmax\nIQR\n\n\n\n\nSUMLEV\n0\n1\n4.98e+01\n1.25e+00\n40\n50\n50\n50\n50\n▁▁▁▁▇\n50\n40\n50\n0\n\n\nREGION\n0\n1\n2.67e+00\n8.10e-01\n1\n2\n3\n3\n4\n▁▆▁▇▂\n3\n1\n4\n1\n\n\nDIVISION\n0\n1\n5.19e+00\n1.97e+00\n1\n4\n5\n7\n9\n▂▇▅▆▃\n5\n1\n9\n3\n\n\nSTATE\n0\n1\n3.03e+01\n1.52e+01\n1\n18\n29\n45\n56\n▃▇▆▆▇\n29\n1\n56\n27\n\n\nCOUNTY\n0\n1\n1.02e+02\n1.08e+02\n0\n33\n77\n133\n840\n▇▁▁▁▁\n77\n0\n840\n100\n\n\nCENSUS2010POP\n0\n1\n1.93e+05\n1.18e+06\n82\n11299\n26424\n71404\n37253956\n▇▁▁▁▁\n26424\n82\n37253956\n60105\n\n\nESTIMATESBASE2010\n0\n1\n1.93e+05\n1.18e+06\n82\n11299\n26446\n71491\n37254503\n▇▁▁▁▁\n26446\n82\n37254503\n60192\n\n\nPOPESTIMATE2010\n0\n1\n1.94e+05\n1.18e+06\n83\n11275\n26467\n71721\n37334079\n▇▁▁▁▁\n26467\n83\n37334079\n60446"
  },
  {
    "objectID": "lessons_original/01_table1.html",
    "href": "lessons_original/01_table1.html",
    "title": "Demographics table with table1",
    "section": "",
    "text": "Code\nlibrary(conflicted)\nconflict_prefer(\"filter\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"lag\", \"dplyr\", quiet = TRUE)\n\nsuppressPackageStartupMessages(library(tidyverse))\n\n# suppress \"`summarise()` has grouped output by \" messages\noptions(dplyr.summarise.inform = FALSE)"
  },
  {
    "objectID": "lessons_original/01_table1.html#necessary-packages",
    "href": "lessons_original/01_table1.html#necessary-packages",
    "title": "Demographics table with table1",
    "section": "Necessary Packages",
    "text": "Necessary Packages\nThe htmlTable package allows for the usage of the table1() function to create a table 1, while also making life easy when attempting to copy this table into a Word document.\nThe boot package was created to aid in performing bootstrapping analysis. With it comes numerous data sets, specifically clinical trial data sets to make this possible. However, there is no code book provided within the package when the data is downloaded as a csv file. This is a link on Github that explains and elaborates on every data within the package itself2.\n\n#install.packages(\"htmlTable\")\n#install.packages(\"boot\")\n\n# Load libraries\nlibrary(htmlTable)\nlibrary(table1)\nlibrary(boot)"
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html",
    "href": "lessons_original/02_fisher_exact_test.html",
    "title": "Fisher’s Exact Test",
    "section": "",
    "text": "Fisher’s exact test is an independent test used to determine if there is a relationship between categorical (non-parametric) variables with a small sample size.\nUsed to assess whether proportions of one variable are different among values of another table.\nUses (hypergeometric) marginal distribution to derive exact p-values which are not approximated, which are also somewhat conservative.\nThe rules of Chi distribution do not apply when the frequency count is &lt;5 for more than 20% of the cells in a contingency table (Bower 2003).\nData is easily manipulated by using a contingency table.\n\n\n\n\nAssumes that the individual observations are independent.\nAssumes that the row and column totals are fixed or conditioned.\nThe variables are categorical and randomly sampled.\nObservations are count data.\n\n\n\n\nThe hypotheses of Fisher’s exact test are similar to Chi-square test:\nNull hypothesis:\\((H_0)\\) There is no relationship between the categorical variables, the variables are independent.\nAlternative hypothesis: \\((H_1)\\) There is a relationship between the categorical variables, the variables are dependent."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#introduction",
    "href": "lessons_original/02_fisher_exact_test.html#introduction",
    "title": "Fisher’s Exact Test",
    "section": "",
    "text": "Fisher’s exact test is an independent test used to determine if there is a relationship between categorical (non-parametric) variables with a small sample size.\nUsed to assess whether proportions of one variable are different among values of another table.\nUses (hypergeometric) marginal distribution to derive exact p-values which are not approximated, which are also somewhat conservative.\nThe rules of Chi distribution do not apply when the frequency count is &lt;5 for more than 20% of the cells in a contingency table (Bower 2003).\nData is easily manipulated by using a contingency table.\n\n\n\n\nAssumes that the individual observations are independent.\nAssumes that the row and column totals are fixed or conditioned.\nThe variables are categorical and randomly sampled.\nObservations are count data.\n\n\n\n\nThe hypotheses of Fisher’s exact test are similar to Chi-square test:\nNull hypothesis:\\((H_0)\\) There is no relationship between the categorical variables, the variables are independent.\nAlternative hypothesis: \\((H_1)\\) There is a relationship between the categorical variables, the variables are dependent."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#fishers-exact-test-equation",
    "href": "lessons_original/02_fisher_exact_test.html#fishers-exact-test-equation",
    "title": "Fisher’s Exact Test",
    "section": "Fisher’s Exact Test Equation",
    "text": "Fisher’s Exact Test Equation\nFisher’s exact test for a one-tailed p-value is calculated using the following formula:\n\\[   p = {(a+b)!(c+d)!(a+c)!(b+d)! \\over a! b! c! d! n!} \\] - n = population size/ total frequency\n- a + b = “successes” values in the contingency table\n- a + c = sample size / draws from the population\n- a = sample successes\n\nFormula description\nthis test is usually used as a one-tailed test but it can also be used as a two tailed test as well, \\(a\\),\\(b\\),\\(c\\), and \\(d\\) are the individual frequencies on the 2x2 contingency table and \\(n\\) is our total frequency. This particular test is used to obtain the probability of the combination of frequencies that we can actually obtain.\n\n\nWhat is a contingency table?\nThis is a table that shows the distribution of a variable in the rows and columns. Sometimes referred to as a 2x2 table. They are useful in summarizing categorical variables. The table() function is used to create a contingency table in R. When the variables of interest are summarized in a contingency table it is easier to run the Fisher’s Exact test.\n\nExample: Creating a contingency table\nLets say we have information on the gender of participants in a clinical trial and the type of drug administered to them we can create the following contingency table for further analysis.\n\n# Example R code to create a contingency table\n\n# Creating a data frame\n df &lt;- data.frame(\n   \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\"),\n   \"Gender\" = c(\"Male\", \"Male\", \"Female\")\n )\n \n# Creating contingency table using table()\nctable &lt;- table(df)\nprint(ctable)\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n\n\n\n\n\nPerforming Fisher’s Exact Test in R\nWe will need to install the ggstatplot package to visualize the statistical results.\n\n# install.packages(\"ggstatplot\") \n# install.packages(\"summarytools\")\n# install.packages(\"gmodels\")\n# install.packages(tidyverse)\n\n\n\nData Source: GMP2017\nFor this example we will be using the Greater Manchester Police’s UK stop and search data from 2017(December) sourced from the Sage Research Methods Dataset Part 2 (https://methods.sagepub.com/dataset/fishers-exact-gmss-2017). This data has information on stop and search events, gender and ethnicity. For this example we would like to access whether there is a significant relationship between gender and stop and search events (having controlled drugs vs harmful weapons)?\n\nGMP17 &lt;- read.csv(\n  \"../data/02_dataset-gmss-2017-subset1_jittered_20240503.csv\"\n)\n\n\n\nLoad in libraries\n\nlibrary(gmodels)\nlibrary(ggstatsplot)\nlibrary(gt)\nlibrary(gtsummary)\nlibrary(katex)\nlibrary(tidyverse)\n\n\n\nDescriptive summary\n\n\nCode\nhead(GMP17)\n\n\n  Gender Ethnicity ObjectSearch\n1      1         1            1\n2      1         1           -9\n3      1         1            1\n4      1         1            1\n5      1         1           -9\n6      1         1            1\n\n\nCode\nstr(GMP17)\n\n\n'data.frame':   186 obs. of  3 variables:\n $ Gender      : int  1 1 1 1 1 1 1 1 1 -9 ...\n $ Ethnicity   : int  1 1 1 1 1 1 2 1 1 1 ...\n $ ObjectSearch: int  1 -9 1 1 -9 1 1 1 -9 -9 ...\n\n\nCode\n# determining the number of rows\nNROW(GMP17)\n\n\n[1] 186\n\n\n\n\nAssessing frequencies to answer research question\nFor this analysis we will use the Gender variable and the ObjectSearch variable\n\n# Dropping the Ethnicity variable to remain with variables of interest for for the 2x2 table\n\nnewGMP17 &lt;-GMP17[ -c(2) ]\n \nhead(newGMP17)\n\n  Gender ObjectSearch\n1      1            1\n2      1           -9\n3      1            1\n4      1            1\n5      1           -9\n6      1            1\n\n\nThe data contains missing values categorized as -9 that we need to drop and we need to rename our variables based on the data dictionary provided https://methods.sagepub.com/dataset/download/fishers-exact-gmss-2017/guide/codebook.\n\n# Exclude rows that have missing data in both variables\nnewGMP17_nom &lt;- subset(newGMP17, Gender &gt; 0)\nnewGMP17_nom2 &lt;- subset(newGMP17_nom, ObjectSearch  &gt; 0)\nsummary(newGMP17_nom2)\n\n     Gender       ObjectSearch  \n Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.000  \n Median :1.000   Median :1.000  \n Mean   :1.052   Mean   :1.267  \n 3rd Qu.:1.000   3rd Qu.:2.000  \n Max.   :2.000   Max.   :2.000  \n\nnrow(newGMP17_nom2)\n\n[1] 116\n\n\n\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$Gender &lt;- recode_factor(\n  newGMP17_nom2$Gender,\n  \"1\" = \"Male\",\n  \"2\" = \"Female\"\n)\n\n# Renaming the Gender variable based on data dictionary\nnewGMP17_nom2$ObjectSearch &lt;- recode_factor(\n  newGMP17_nom2$ObjectSearch,\n  \"1\" = \"Controlled_Drugs\",\n  \"2\" = \"Harmful_Objects\"\n)\n\n\n# Creating the contingency table for subset data\ncGMP17 = table(newGMP17_nom2)\nprint(cGMP17)\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male                 83              27\n  Female                2               4\n\n\n\n\nVisualizing data using mosaic plot\n\nwe can use the mosaic plot to represent the data.\n\n\nmosaicplot(\n  cGMP17,\n  main = 'Mosaic Plot',\n  color = TRUE\n)\n\n\n\n\n\n\n\n\n\n\nRunning the Fisher’s exact test using fisher.test()\nWhat if we just run a Chi-square test?\nUsing our GMP17 dataset we can try to run a Chi-square test instead of the Fisher’s Exact test and see what happens.\nThe R output gives us a warning that the Chi Square is not appropriate hence we should use another test in this case the Fisher’s Exact Test.\n\nchisq.test(cGMP17)$expected\n\nWarning in chisq.test(cGMP17): Chi-squared approximation may be incorrect\n\n\n        ObjectSearch\nGender   Controlled_Drugs Harmful_Objects\n  Male          80.603448       29.396552\n  Female         4.396552        1.603448\n\n\n\n\nRunning the test\n\n# running the fisher's exact test\n\ntest &lt;- fisher.test(cGMP17)\ntest\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  cGMP17\np-value = 0.04297\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.8133673 70.2637501\nsample estimates:\nodds ratio \n  6.030297 \n\n\nUsing the gt summary to view results.\n\nnewGMP17_nom2 |&gt; \n  tbl_summary(by = Gender) |&gt; \n  add_p() |&gt; \n  add_overall()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall, N = 1161\nMale, N = 1101\nFemale, N = 61\np-value2\n\n\n\n\nObjectSearch\n\n\n\n\n\n\n0.043\n\n\n    Controlled_Drugs\n85 (73%)\n83 (75%)\n2 (33%)\n\n\n\n\n    Harmful_Objects\n31 (27%)\n27 (25%)\n4 (67%)\n\n\n\n\n\n1 n (%)\n\n\n2 Fisher’s exact test\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of results\nThe most important test statistic is the p - value therefore we can retrieve the specific result using the following code;\n\ntest$p.value \n\n[1] 0.04297268\n\n\nOdds ratio = 6.33, 95% CI = 0.85-73.59], we reject the null hypothesis (p &lt; 0.05) and conclude that there is a strong association between the two categorical independent variables (gender and object search events)\nTherefore the odds ratio indicates that the odds of having controlled drugs at a stop and search is 6.33 times as likely for males compared to females. In other words, males are more likely of having controlled drugs at a stop and search than females.\n\n\nVisualizing statistical results with plots using ggstatsplot\n\nwe download the ggsattsplot package to visualize the results in a plot.\n\n\n# Fisher's exact test \n\ntest &lt;- fisher.test(cGMP17)\n\n# combine plot and statistical test with ggbarstats\n\nggbarstats(\n  newGMP17_nom2, Gender, ObjectSearch,\n  results.subtitle = FALSE,\n  subtitle = paste0(\n    \"Fisher's exact test\", \", p-value = \",\n    ifelse(test$p.value &lt; 0.001, \"&lt; 0.001\", round(test$p.value, 3))\n  )\n)\n\n\n\n\n\n\n\n\nFrom the plot, it is clear that the proportion of males among object search events is higher compared to females, suggesting that there is a relationship between the two variables.\nThis is confirmed thanks to the p-value displayed in the subtitle of the plot. As previously, we reject the null hypothesis and we conclude that the variables gender and stop and search events are not independent (p-value = 0.038)."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#what-if-we-have-more-than-two-levels",
    "href": "lessons_original/02_fisher_exact_test.html#what-if-we-have-more-than-two-levels",
    "title": "Fisher’s Exact Test",
    "section": "What if we have more than two levels?",
    "text": "What if we have more than two levels?\nUsing the drug example used previously lets say we have 3 drugs ‘Drug A, Drug B or Drug C’ and we want to see if there is any relationship with gender ‘Male/Female’.\n\n# Creating a data frame\ndf &lt;- data.frame (\n  \"Drug\" = c(\"Drug A\", \"Drug B\", \"Drug A\", \"Drug C\", \"Drug C\"),\n  \"Gender\" = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Female\")\n)\n \n# Creating contingency table using table()\nctable &lt;- table(df)\nprint(ctable)\n\n        Gender\nDrug     Female Male\n  Drug A      1    1\n  Drug B      0    1\n  Drug C      2    0\n\n\n\n# Running the Fisher's Exact test for the 3x2 table\nfisher.test(ctable)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  ctable\np-value = 0.6\nalternative hypothesis: two.sided\n\n\nThe p-value is non-significant [p = 0.6], we fail to reject the null hypothesis (p &lt; 0.05) and conclude that there is no association between the drug treatments and gender. If the results had been significant we would have gone ahead and conducted a post hoc analysis using pairwise_fisher_test to asses each combination.\nSummary\nThis article describe the assumptions and hypotheses of the Fisher’s Exact test. It also provides examples on how it can be applied."
  },
  {
    "objectID": "lessons_original/02_fisher_exact_test.html#references",
    "href": "lessons_original/02_fisher_exact_test.html#references",
    "title": "Fisher’s Exact Test",
    "section": "References",
    "text": "References\n\nBower, Keith M. 2003. “When to Use Fisher’s Exact Test.” In American Society for Quality, Six Sigma Forum Magazine, 2:35–37. 4.\nMcCrum-Gardner, Evie. 2008. “Which Is the Correct Statistical Test to Use?” British Journal of Oral and Maxillofacial Surgery 46 (1): 38–41.\nWong KC. Chi squared test versus Fisher’s exact test. Hong Kong Med J. 2011 Oct;17(5):427\nPatil, I. (2021). Visualizations with statistical details: The ‘ggstatsplot’ approach. Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\nZach Bobbit. (2021). Fisher’s Exact Test: Definition, Formula, and Example"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "What is bootstrapping?\nBootstrapping is a technique from Efron (1979) that is built on a simple idea: if the data we have is a sample from a population, why don’t we sample from our own data to make more samples? Now, because we don’t have access to any new data, we’re going to take samples of our data set with replacement.\n\n\nThe purpose of bootstrapping is to increase the sample size for our analysis when the sample we have been given is small."
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#when-to-use-bootstrapping",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#when-to-use-bootstrapping",
    "title": "Bootstrap Confidence Intervals",
    "section": "",
    "text": "The purpose of bootstrapping is to increase the sample size for our analysis when the sample we have been given is small."
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#distribution",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#distribution",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.1 Distribution",
    "text": "3.1 Distribution\nBoxplots and histograms will be useful to understand the distribution of the data.\nOur data is not normal based on the distribution.\n\n\nCode\n# check the boxplot of the data\nboxplot(\n  new_penguins_df$flipper_length_mm ~ new_penguins_df$island, las = 1, \n  ylab = \"Flipper Length (mm)\",\n  xlab = \"Island\",\n  main = \"Flipper Length by Island\"\n)\n\n\n\n\n\n\n\n\n\nCode\n\n# check the histogram of the data\nhist(\n  x = new_penguins_df$flipper_length_mm,\n  main = \"Distribution of Flipper Length (mm)\",\n  xlab = \"Flipper Length\"\n)"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#bootstrapping-test",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#bootstrapping-test",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.2 Bootstrapping Test",
    "text": "3.2 Bootstrapping Test\nWe need the difference in means in order to conduct our permutation test. We will test whether the difference is significant so that we can reject the null. This indicates that there is a different in flipper length among the same species that come from different islands.\n\n\nCode\n# set a seed so that our random results can be replicated by other people:\nset.seed(20150516)\n\n# take a random re-sample of the data that is the *same size*\nN &lt;- length(new_penguins_df$flipper_length_mm)\n\n# a random sample:\nsample(new_penguins_df$flipper_length_mm, size = N, replace = TRUE)\n [1] 184 192 198 195 195 176 188 183 184 193 199 198 184 190 198 195 195 199 193\n[20] 197 198 189 197 188 189 199 200 190 183 198 194 190 191 196 189 195 198 197\n[39] 191 184 198 180 195 186 193 193 191 195 190 198 189 181 197 196 182 200 188\n[58] 184 202 189 197 186 181 195 181 191 185 193 196 185 192 199 186 196 180 190\n[77] 190 195 197 193 191 181 195 190 186 189 192 187 190 195 195 182 172 194 181\n\n# number of bootstrap samples\nB_int &lt;- 10000\n\n# create a list of these thousands of samples \nbootstrapSamples_ls &lt;- map(\n  .x = 1:B_int,\n  .f = ~{\n    sample(new_penguins_df$flipper_length_mm, size = N, replace = TRUE)\n  }\n)\n\n# subset of the random samples \nbootstrapSamples_ls[1:3]\n[[1]]\n [1] 183 190 189 188 181 198 181 172 187 189 189 193 180 197 191 190 196 191 195\n[20] 181 193 190 190 186 188 195 190 197 198 190 180 198 194 188 195 191 203 199\n[39] 190 189 195 186 189 199 202 197 189 190 194 190 181 190 190 181 186 196 174\n[58] 185 174 202 191 184 181 184 193 190 190 190 191 196 189 195 195 198 193 190\n[77] 197 184 186 188 193 190 191 195 198 180 191 185 189 192 183 192 199 186 195\n\n[[2]]\n [1] 187 194 187 189 184 188 187 187 184 197 193 191 187 189 190 172 187 186 180\n[20] 193 191 195 195 180 184 189 197 191 187 186 186 187 184 188 190 193 198 190\n[39] 195 198 184 197 195 195 195 198 194 191 198 197 198 186 194 195 189 186 181\n[58] 180 191 180 191 193 196 191 202 191 187 181 199 172 181 191 195 195 194 198\n[77] 191 191 190 192 190 199 195 193 195 197 188 181 190 185 186 191 174 193 195\n\n[[3]]\n [1] 191 196 203 195 185 195 193 186 186 202 186 203 187 180 185 186 192 202 186\n[20] 192 200 195 184 185 195 193 199 190 189 185 181 181 188 197 181 190 188 185\n[39] 187 184 184 195 199 186 200 186 192 195 190 182 189 191 203 193 195 191 191\n[58] 199 195 198 187 191 195 190 190 187 189 192 186 199 193 190 187 181 190 191\n[77] 190 190 183 193 190 197 181 190 187 198 187 190 200 184 190 184 186 191 193"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-1",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-1",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.3 Building Confidence Intervals for Various Statistics: Example 1",
    "text": "3.3 Building Confidence Intervals for Various Statistics: Example 1\n\n\nCode\n\n# The Sample Mean\nbootMeans_num &lt;-\n  bootstrapSamples_ls %&gt;%\n  # the map_dbl() function takes in a list and returns an atomic vector of type\n  #   double (numeric)\n  map_dbl(mean)\n\n# a normally distributed histogram using the samples from bootstrapping\nhist(bootMeans_num)\n\n\n\n\n\n\n\n\n\nCode\n\n# 95% confidence interval?\nquantile(bootMeans_num, probs = c(0.025, 0.975))\n 2.5% 97.5% \n  189   191"
  },
  {
    "objectID": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-2",
    "href": "lessons_original/03_two_sample_bootstrap_conf_int.html#building-confidence-intervals-for-various-statistics-example-2",
    "title": "Bootstrap Confidence Intervals",
    "section": "3.4 Building Confidence Intervals for Various Statistics: Example 2",
    "text": "3.4 Building Confidence Intervals for Various Statistics: Example 2\nSource: https://www.geeksforgeeks.org/bootstrap-confidence-interval-with-r-programming/\n\n\nCode\n\n# Custom function to find correlation between the bill length and depth \ncorr.fun &lt;- function(data, idx) {\n  \n# vector of indices that the boot function uses\n  df &lt;- data[idx, ]\n\n# Find the spearman correlation between\n# the 3rd (length) and 5th (depth) columns of dataset\n  cor(df[, 3], df[, 4], method = 'spearman')\n}\n\n# Setting the seed for reproducability of results\nset.seed(42)\n\n# Calling the boot function with the dataset\nbootstrap &lt;- boot(iris, corr.fun, R = 1000)\n\n# Display the result of boot function\nbootstrap\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = iris, statistic = corr.fun, R = 1000)\n\n\nBootstrap Statistics :\n    original   bias    std. error\nt1*    0.938 -0.00272     0.00944\n\n# Plot the bootstrap sampling distribution using ggplot\nplot(bootstrap)\n\n\n\n\n\n\n\n\n\nCode\n\n# Function to find the bootstrap CI\nboot.ci(\n  boot.out = bootstrap,\n    type = \"perc\"\n)\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bootstrap, type = \"perc\")\n\nIntervals : \nLevel     Percentile     \n95%   ( 0.914,  0.952 )  \nCalculations and Intervals on Original Scale"
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html",
    "href": "lessons_original/03_two_sample_ttest.html",
    "title": "Two sample t test",
    "section": "",
    "text": "This is also called the independent sample t test. It is used to see whether the unknown population means of two groups are equal or different. This test requires one variable which can be the exposure x and another variable which can be the outcome y. If you have more than two groups then analysis of variance (ANOVA) will be more suitable. If data is nonparametric then an alternative test to use would be the Mann Whitney U test or a permutation test.(cressie1986?).\nThere are two types of t tests, the first being the Student’s t test, which assumes the variance of the two groups is equal, the second being the Welch’s t test (default in R), which assumes the variance in the two groups is different.\nIn this article we will be discussing the Student’s t test.\n\n\n\nMeasurements for one observation do not affect measurements for any other observation (assumes independence).\nData in each group must be obtained via a random sample from the population.\nData in each group are normally distributed.\nData values are continuous.\nThe variances for the two independent groups are equal in the Student’s t test.\nThere should be no significant outliers.\n\n\n\n\n\n(H_0): the mean of group A (m_A) is equal to the mean of group B (m_B)- two tailed test,\n(H_0): (m_A)\\ge (m_B)- one tailed test.\n(H_0): (m_A)\\le (m_B)- one tailed test.\nThe corresponding alternative hypotheses would be as follows:\n\n\n\n(H_1): (m_A)\\neq(m_B)- two tailed test.\n(H_1): (m_A)&lt;(m_B)- one tailed test.\n(H_1): (m_A)&gt; (m_B)- one tailed test.\n\n\n\n\nFor the Student’s t test which assumes equal variance the following is how the |t| statistic may be calculated using groups A and B as examples:\nt ={ {m_{A} - m_{B}} \\over \\sqrt{ {S^2 \\over n_{A} } + {S^2 \\over n_{B}}   }}\nThis can be described as the sample mean difference divided by the sample standard deviation of the sample mean difference where:\nm_A and m_B are the mean values of A and B,\nn_A and n_B are the seize of group A and B,\nS^2 is the estimator for the pooled variance,\nwith the degrees of freedom (df) = n_A + n_B - 2,\nand S^2 is calculated as follows:\nS^2 = { {\\sum{ (x_A-m_{A})^2} + \\sum{ (x_B-m_{B})^2}} \\over {n_{A} + n_{B} - 2 }}\nResults for both Students t test and Welch’s t test are usually similar unless the group sizes and standard deviations are different.\nWhat if the data is not independent?\nIf the data is not independent such as paired data in the form of matched pairs which are correlated, we use the paired t test. This test checks whether the means of two paired groups are different from each other. It’s usually used in clinical trial studies with a “before and after” or case control studies with matched pairs. For this test we only assume the difference of each pair to be normally distributed (the paired groups are the ones important for analysis) unlike the independent t test which assumes that data from both samples are independent and variances are equal.(fralick?)\n\n\n\n\n\n\n\ntidyverse: data manipulation and visualization.\nrstatix: providing pipe friendly R functions for easy statistical analyses.\ncar: providing variance tests.\n\n\n\nCode\n#install.packages(\"ggstatplot\") \n#install.packages(\"car\")\n#install.packages(\"rstatix\")\n#install.packages(tidyVerse)\n\n\n\n\n\nThis example dataset sourced from kaggle was obtained from surveys of students in Math and Portuguese classes in secondary school. It contains demographic information on gender, social and study information.(cortez2008?)\n\n\nCode\n# load relevant libraries\nlibrary(rcompanion)\nlibrary(car)\nlibrary (gt)\nlibrary(gtsummary)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(tidyverse)\n\n\n\n\nCode\n# load the dataset\nstu_math &lt;- read_csv(\"../data/03_student-mat.csv\")\n\n\nRows: 395 Columns: 33\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (17): school, sex, address, famsize, Pstatus, Mjob, Fjob, reason, guardi...\ndbl (16): age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking the data\n\n\nCode\n# check the data\nglimpse(stu_math)\n\n\nRows: 395\nColumns: 33\n$ school     &lt;chr&gt; \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\",…\n$ sex        &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\",…\n$ age        &lt;dbl&gt; 18, 17, 15, 15, 16, 16, 16, 17, 15, 15, 15, 15, 15, 15, 15,…\n$ address    &lt;chr&gt; \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\",…\n$ famsize    &lt;chr&gt; \"GT3\", \"GT3\", \"LE3\", \"GT3\", \"GT3\", \"LE3\", \"LE3\", \"GT3\", \"LE…\n$ Pstatus    &lt;chr&gt; \"A\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"A\", \"A\", \"T\", \"T\", \"T\",…\n$ Medu       &lt;dbl&gt; 4, 1, 1, 4, 3, 4, 2, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4,…\n$ Fedu       &lt;dbl&gt; 4, 1, 1, 2, 3, 3, 2, 4, 2, 4, 4, 1, 4, 3, 2, 4, 4, 3, 2, 3,…\n$ Mjob       &lt;chr&gt; \"at_home\", \"at_home\", \"at_home\", \"health\", \"other\", \"servic…\n$ Fjob       &lt;chr&gt; \"teacher\", \"other\", \"other\", \"services\", \"other\", \"other\", …\n$ reason     &lt;chr&gt; \"course\", \"course\", \"other\", \"home\", \"home\", \"reputation\", …\n$ guardian   &lt;chr&gt; \"mother\", \"father\", \"mother\", \"mother\", \"father\", \"mother\",…\n$ traveltime &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1,…\n$ studytime  &lt;dbl&gt; 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, 1, 1,…\n$ failures   &lt;dbl&gt; 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,…\n$ schoolsup  &lt;chr&gt; \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"n…\n$ famsup     &lt;chr&gt; \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\",…\n$ paid       &lt;chr&gt; \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", …\n$ activities &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"ye…\n$ nursery    &lt;chr&gt; \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes…\n$ higher     &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n$ internet   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\",…\n$ romantic   &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\"…\n$ famrel     &lt;dbl&gt; 4, 5, 4, 3, 4, 5, 4, 4, 4, 5, 3, 5, 4, 5, 4, 4, 3, 5, 5, 3,…\n$ freetime   &lt;dbl&gt; 3, 3, 3, 2, 3, 4, 4, 1, 2, 5, 3, 2, 3, 4, 5, 4, 2, 3, 5, 1,…\n$ goout      &lt;dbl&gt; 4, 3, 2, 2, 2, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 3, 2, 5, 3,…\n$ Dalc       &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ Walc       &lt;dbl&gt; 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 2, 1, 4, 3,…\n$ health     &lt;dbl&gt; 3, 3, 3, 5, 5, 5, 3, 1, 1, 5, 2, 4, 5, 3, 3, 2, 2, 4, 5, 5,…\n$ absences   &lt;dbl&gt; 6, 4, 10, 2, 4, 10, 0, 6, 0, 0, 0, 4, 2, 2, 0, 4, 6, 4, 16,…\n$ G1         &lt;dbl&gt; 5, 5, 7, 15, 6, 15, 12, 6, 16, 14, 10, 10, 14, 10, 14, 14, …\n$ G2         &lt;dbl&gt; 6, 5, 8, 14, 10, 15, 12, 5, 18, 15, 8, 12, 14, 10, 16, 14, …\n$ G3         &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14,…\n\n\nIn total there are 395 observations and 33 variables. We will drop the variables we do not need and keep the variables that will help us answer the following: Is there a difference between boys and girls in math final grades?\nH_0: There is no statistical difference between the final grades between boys and girls.\nH_1: There is a statistically significant difference in the final grades between the two groups.\n\n\nCode\n# creating a subset of the data \nmath = subset(stu_math, select= c(sex,G3))\nglimpse(math)\n\n\nRows: 395\nColumns: 2\n$ sex &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"…\n$ G3  &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14, 14, 10…\n\n\nSummary statistics- the dependent variable is continuous (grades=G3) and the independent variable is character but binary (sex).\n\n\nCode\n# summarizing our data\n summary(math)\n\n\n     sex                  G3       \n Length:395         Min.   : 0.00  \n Class :character   1st Qu.: 8.00  \n Mode  :character   Median :11.00  \n                    Mean   :10.42  \n                    3rd Qu.:14.00  \n                    Max.   :20.00  \n\n\nWe see that data ranges from 0-20 with 0 being people who were absent and could not take the test therefore missing data. We remove these 0 values before running the t test. However other models should be considered such as the zero inflated model to differentiate those who truly got a 0 and those who were not present to take test.\n\n\nCode\n# creating a boxplot to visualize the data with no outliers\nmath2 = subset(math, G3&gt;0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nVisualizing the data- we can use histograms and box lots to visualize the data to check for outliers and distribution thus checking for normality.\n\n\nCode\n# Histograms for data by groups \n\nmale = math2$G3[math2$sex == \"M\"]\nfemale = math2$G3[math2$sex == \"F\"]\n\n# plotting distribution for males\nplotNormalHistogram(\n  male, \n  breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for males \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for males seem to be normally distributed from 0-20. Data is approximately normal because we have a large amount of bins.\n\n\nCode\n# plotting distribution for females\nplotNormalHistogram(\n  female, breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for females \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for females also appear to be normally distributed. The final score across both is almost evenly distributed. However there seem to be a significant number of individuals who failed the test (grade=0).\n\n\nCode\n# plotting bar plot to see the distribution in sample size\nsample_size = table(math2$sex)\nbarplot(sample_size,main= \"Distribution of sample size by sex\")\n\n\n\n\n\n\n\n\n\nThe bar graph shows that there are slightly more females in the sample than males.\nIdentifying outliers\n\n\nCode\n# creating a boxplot to visualize the outliers (G3=0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nThe box plot shows us that there are no outliers as these have been removed in terms of people who had a score of 0. This score is not truly reflective of the performance between boys and girls as a grade of 0 may represent absentia or other reasons for the test not been taken. Therefore we opt to drop the outliers. We will compare to see if this decision affects the mean which appears similar from the above plot.\n\n\nCode\n# finding the mean for the groups with outliers\nmean(math$G3[math$sex==\"F\"])\n\n\n[1] 9.966346\n\n\nCode\nmean(math$G3[math$sex==\"M\"])\n\n\n[1] 10.91444\n\n\nCode\n# finding the mean for the groups without outliers\nmean(math2$G3[math2$sex==\"F\"])\n\n\n[1] 11.20541\n\n\nCode\nmean(math2$G3[math2$sex==\"M\"])\n\n\n[1] 11.86628\n\n\nThe mean has increased slightly and the difference decreased after removing the outliers but the distribution is still the same.\nCheck the equality of variances (homogeneity)\nWe can use the Levene’s test or the Bartlett’s test to check for homogeneity of variances. The former is in the car library and the later in the rstatix library. If the variances are homogeneous the p value will be greater than 0.05.\nOther tests include F test 2 sided, Brown-Forsythe and O’Brien but we shall not cover these.\n\n\nCode\n# running the Bartlett's test to check equal variance\nbartlett.test(G3~sex, data=math2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  G3 by sex\nBartlett's K-squared = 0.12148, df = 1, p-value = 0.7274\n\n\nCode\n# running the Levene's test to check equal variance\nmath2 %&gt;% levene_test(G3~sex)\n\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1   355     0.614 0.434\n\n\nThe p value is greater than 0.05 suggesting there is no difference between the variances of the two groups.\n\n\n\n\nData is continuous(G3)\nData is normally distributed\nData is independent (males and females distinct not the same individual)\nNo significant outliers\nThere are equal variances\n\nAs the assumptions are met we go ahead to perform the Student’s t test.\n\n\n\nSince the default is the Welch t test we use the \\color{blue}{\\text{var.eqaul = TRUE }} code to signify a Student’s t test. There is a t.test() function in stats package and a t_test() in the rstatix package. For this analysis we use the rstatix method as it comes out as a table.\n\n\nCode\n# perfoming the two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE) %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df      p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.0531 ns      \n\n\n\n\nCode\nstat.test$statistic\n\n\n        t \n-1.940477 \n\n\nThe results are represented as follows;\n\ny - dependent variable\ngroup1, group 2 - compared groups(independent variables)\ndf - degrees of freedom\np - p value\n\ngtsummary table of results\n\n\nCode\n math2 |&gt; \n  tbl_summary(\n    by = sex,\n    statistic =\n      list(\n        all_continuous() ~ \"{mean} ({sd})\",\n        all_dichotomous() ~ \"{p}%\")\n    ) |&gt; \n   add_n() |&gt; \n  add_overall() |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOverall, N = 3571\nF, N = 1851\nM, N = 1721\nDifference2\n95% CI2,3\np-value2\n\n\n\n\nG3\n357\n11.5 (3.2)\n11.2 (3.2)\n11.9 (3.3)\n-0.66\n-1.3, 0.01\n0.053\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n3 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nInterpretation of results\nFor the two sample t test with t(355) = -1.940477, p = 0.0531, the p value is greater than our alpha of 0.05 , we fail to reject the null hypothesis and conclude that there is no statistical difference between the means of the two groups. There is no difference in final grades between boys and girls. (A significant |t| would be 1.96 or greater).\nEffect size\nCohen’s d can be an used as an effect size statistic for the two sample t test. It is the difference between the means of each group divided by the pooled standard deviation.\nd= {m_A-m_B \\over SD_pooled}\nIt ranges from 0 to infinity, with 0 indicating no effect where the means are equal. 0.5 means that the means differ by half the standard deviation of the data and 1 means they differ by 1 standard deviation. It is divided into small, medium or large using the following cut off points.\n\nsmall 0.2-&lt;0.5\nmedium 0.5-&lt;0.8\nlarge &gt;=0.8\n\nFor the above test the following is how we can find the effect size;\n\n\nCode\n#perfoming cohen's d\nmath2 %&gt;% \n  cohens_d(G3~sex,var.equal = TRUE)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2 effsize    n1    n2 magnitude\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 G3    F      M       -0.206   185   172 small    \n\n\nThe effect size is small d= -0.20.\nIn conclusion, a two-samples t-test showed that the difference was not statistically significant, t(355) = -1.940477, p &lt; 0.0531, d = -0.20; where, t(355) is shorthand notation for a t-statistic that has 355 degrees of freedom and d is Cohen’s d. We can conclude that the females mean final grade is greater than males final grade (d= -0.20) but this result is not significant.\nWhat if it is one tailed t test?\nUse the \\color{blue}{\\text{alternative =}} option to determine if one group is \\color{blue}{\\text{\"less\"}} or \\color{blue}{\\text{\"greater\"}}. For example if we want to see whether the final grades for females are greater than males we can use the following code:\n\n\nCode\n# perfoming the one tailed two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE, alternative = \"greater\") %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df     p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.973 ns      \n\n\nThe p value is greater than 0.05 (p=0.973), we fail to reject the null hypothesis. We conclude that the final grades for females are not significantly greater than for males.\nWhat about running the paired sample t test?\nWe can simply add the syntax \\color{blue}{\\text{paired= TRUE}} to our t_test() to run the analysis for matched pairs data.\n\n\n\n\nThis article covers the Student’s t test and how we run it in R. It also shows how we find the effect size and how we can conclude the results."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#assumptions",
    "href": "lessons_original/03_two_sample_ttest.html#assumptions",
    "title": "Two sample t test",
    "section": "",
    "text": "Measurements for one observation do not affect measurements for any other observation (assumes independence).\nData in each group must be obtained via a random sample from the population.\nData in each group are normally distributed.\nData values are continuous.\nThe variances for the two independent groups are equal in the Student’s t test.\nThere should be no significant outliers."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#hypotheses",
    "href": "lessons_original/03_two_sample_ttest.html#hypotheses",
    "title": "Two sample t test",
    "section": "",
    "text": "(H_0): the mean of group A (m_A) is equal to the mean of group B (m_B)- two tailed test,\n(H_0): (m_A)\\ge (m_B)- one tailed test.\n(H_0): (m_A)\\le (m_B)- one tailed test.\nThe corresponding alternative hypotheses would be as follows:\n\n\n\n(H_1): (m_A)\\neq(m_B)- two tailed test.\n(H_1): (m_A)&lt;(m_B)- one tailed test.\n(H_1): (m_A)&gt; (m_B)- one tailed test."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#statistical-hypotheses-formula",
    "href": "lessons_original/03_two_sample_ttest.html#statistical-hypotheses-formula",
    "title": "Two sample t test",
    "section": "",
    "text": "For the Student’s t test which assumes equal variance the following is how the |t| statistic may be calculated using groups A and B as examples:\nt ={ {m_{A} - m_{B}} \\over \\sqrt{ {S^2 \\over n_{A} } + {S^2 \\over n_{B}}   }}\nThis can be described as the sample mean difference divided by the sample standard deviation of the sample mean difference where:\nm_A and m_B are the mean values of A and B,\nn_A and n_B are the seize of group A and B,\nS^2 is the estimator for the pooled variance,\nwith the degrees of freedom (df) = n_A + n_B - 2,\nand S^2 is calculated as follows:\nS^2 = { {\\sum{ (x_A-m_{A})^2} + \\sum{ (x_B-m_{B})^2}} \\over {n_{A} + n_{B} - 2 }}\nResults for both Students t test and Welch’s t test are usually similar unless the group sizes and standard deviations are different.\nWhat if the data is not independent?\nIf the data is not independent such as paired data in the form of matched pairs which are correlated, we use the paired t test. This test checks whether the means of two paired groups are different from each other. It’s usually used in clinical trial studies with a “before and after” or case control studies with matched pairs. For this test we only assume the difference of each pair to be normally distributed (the paired groups are the ones important for analysis) unlike the independent t test which assumes that data from both samples are independent and variances are equal.(fralick?)"
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#example",
    "href": "lessons_original/03_two_sample_ttest.html#example",
    "title": "Two sample t test",
    "section": "",
    "text": "tidyverse: data manipulation and visualization.\nrstatix: providing pipe friendly R functions for easy statistical analyses.\ncar: providing variance tests.\n\n\n\nCode\n#install.packages(\"ggstatplot\") \n#install.packages(\"car\")\n#install.packages(\"rstatix\")\n#install.packages(tidyVerse)\n\n\n\n\n\nThis example dataset sourced from kaggle was obtained from surveys of students in Math and Portuguese classes in secondary school. It contains demographic information on gender, social and study information.(cortez2008?)\n\n\nCode\n# load relevant libraries\nlibrary(rcompanion)\nlibrary(car)\nlibrary (gt)\nlibrary(gtsummary)\nlibrary(ggpubr)\nlibrary(rstatix)\nlibrary(tidyverse)\n\n\n\n\nCode\n# load the dataset\nstu_math &lt;- read_csv(\"../data/03_student-mat.csv\")\n\n\nRows: 395 Columns: 33\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (17): school, sex, address, famsize, Pstatus, Mjob, Fjob, reason, guardi...\ndbl (16): age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking the data\n\n\nCode\n# check the data\nglimpse(stu_math)\n\n\nRows: 395\nColumns: 33\n$ school     &lt;chr&gt; \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\", \"GP\",…\n$ sex        &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\",…\n$ age        &lt;dbl&gt; 18, 17, 15, 15, 16, 16, 16, 17, 15, 15, 15, 15, 15, 15, 15,…\n$ address    &lt;chr&gt; \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\", \"U\",…\n$ famsize    &lt;chr&gt; \"GT3\", \"GT3\", \"LE3\", \"GT3\", \"GT3\", \"LE3\", \"LE3\", \"GT3\", \"LE…\n$ Pstatus    &lt;chr&gt; \"A\", \"T\", \"T\", \"T\", \"T\", \"T\", \"T\", \"A\", \"A\", \"T\", \"T\", \"T\",…\n$ Medu       &lt;dbl&gt; 4, 1, 1, 4, 3, 4, 2, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4,…\n$ Fedu       &lt;dbl&gt; 4, 1, 1, 2, 3, 3, 2, 4, 2, 4, 4, 1, 4, 3, 2, 4, 4, 3, 2, 3,…\n$ Mjob       &lt;chr&gt; \"at_home\", \"at_home\", \"at_home\", \"health\", \"other\", \"servic…\n$ Fjob       &lt;chr&gt; \"teacher\", \"other\", \"other\", \"services\", \"other\", \"other\", …\n$ reason     &lt;chr&gt; \"course\", \"course\", \"other\", \"home\", \"home\", \"reputation\", …\n$ guardian   &lt;chr&gt; \"mother\", \"father\", \"mother\", \"mother\", \"father\", \"mother\",…\n$ traveltime &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1,…\n$ studytime  &lt;dbl&gt; 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 1, 3, 2, 1, 1,…\n$ failures   &lt;dbl&gt; 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,…\n$ schoolsup  &lt;chr&gt; \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"n…\n$ famsup     &lt;chr&gt; \"no\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\",…\n$ paid       &lt;chr&gt; \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\", …\n$ activities &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"ye…\n$ nursery    &lt;chr&gt; \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes…\n$ higher     &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n$ internet   &lt;chr&gt; \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\",…\n$ romantic   &lt;chr&gt; \"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\"…\n$ famrel     &lt;dbl&gt; 4, 5, 4, 3, 4, 5, 4, 4, 4, 5, 3, 5, 4, 5, 4, 4, 3, 5, 5, 3,…\n$ freetime   &lt;dbl&gt; 3, 3, 3, 2, 3, 4, 4, 1, 2, 5, 3, 2, 3, 4, 5, 4, 2, 3, 5, 1,…\n$ goout      &lt;dbl&gt; 4, 3, 2, 2, 2, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 3, 2, 5, 3,…\n$ Dalc       &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ Walc       &lt;dbl&gt; 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 2, 1, 4, 3,…\n$ health     &lt;dbl&gt; 3, 3, 3, 5, 5, 5, 3, 1, 1, 5, 2, 4, 5, 3, 3, 2, 2, 4, 5, 5,…\n$ absences   &lt;dbl&gt; 6, 4, 10, 2, 4, 10, 0, 6, 0, 0, 0, 4, 2, 2, 0, 4, 6, 4, 16,…\n$ G1         &lt;dbl&gt; 5, 5, 7, 15, 6, 15, 12, 6, 16, 14, 10, 10, 14, 10, 14, 14, …\n$ G2         &lt;dbl&gt; 6, 5, 8, 14, 10, 15, 12, 5, 18, 15, 8, 12, 14, 10, 16, 14, …\n$ G3         &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14,…\n\n\nIn total there are 395 observations and 33 variables. We will drop the variables we do not need and keep the variables that will help us answer the following: Is there a difference between boys and girls in math final grades?\nH_0: There is no statistical difference between the final grades between boys and girls.\nH_1: There is a statistically significant difference in the final grades between the two groups.\n\n\nCode\n# creating a subset of the data \nmath = subset(stu_math, select= c(sex,G3))\nglimpse(math)\n\n\nRows: 395\nColumns: 2\n$ sex &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"…\n$ G3  &lt;dbl&gt; 6, 6, 10, 15, 10, 15, 11, 6, 19, 15, 9, 12, 14, 11, 16, 14, 14, 10…\n\n\nSummary statistics- the dependent variable is continuous (grades=G3) and the independent variable is character but binary (sex).\n\n\nCode\n# summarizing our data\n summary(math)\n\n\n     sex                  G3       \n Length:395         Min.   : 0.00  \n Class :character   1st Qu.: 8.00  \n Mode  :character   Median :11.00  \n                    Mean   :10.42  \n                    3rd Qu.:14.00  \n                    Max.   :20.00  \n\n\nWe see that data ranges from 0-20 with 0 being people who were absent and could not take the test therefore missing data. We remove these 0 values before running the t test. However other models should be considered such as the zero inflated model to differentiate those who truly got a 0 and those who were not present to take test.\n\n\nCode\n# creating a boxplot to visualize the data with no outliers\nmath2 = subset(math, G3&gt;0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nVisualizing the data- we can use histograms and box lots to visualize the data to check for outliers and distribution thus checking for normality.\n\n\nCode\n# Histograms for data by groups \n\nmale = math2$G3[math2$sex == \"M\"]\nfemale = math2$G3[math2$sex == \"F\"]\n\n# plotting distribution for males\nplotNormalHistogram(\n  male, \n  breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for males \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for males seem to be normally distributed from 0-20. Data is approximately normal because we have a large amount of bins.\n\n\nCode\n# plotting distribution for females\nplotNormalHistogram(\n  female, breaks= 20,\n  xlim=c(0,20),\n  main=\"Distribution of the grades for females \", \n  xlab= \"Math Grades\"\n  )\n\n\n\n\n\n\n\n\n\nFinal grades for females also appear to be normally distributed. The final score across both is almost evenly distributed. However there seem to be a significant number of individuals who failed the test (grade=0).\n\n\nCode\n# plotting bar plot to see the distribution in sample size\nsample_size = table(math2$sex)\nbarplot(sample_size,main= \"Distribution of sample size by sex\")\n\n\n\n\n\n\n\n\n\nThe bar graph shows that there are slightly more females in the sample than males.\nIdentifying outliers\n\n\nCode\n# creating a boxplot to visualize the outliers (G3=0)\nboxplot(G3 ~ sex,data=math2)\n\n\n\n\n\n\n\n\n\nThe box plot shows us that there are no outliers as these have been removed in terms of people who had a score of 0. This score is not truly reflective of the performance between boys and girls as a grade of 0 may represent absentia or other reasons for the test not been taken. Therefore we opt to drop the outliers. We will compare to see if this decision affects the mean which appears similar from the above plot.\n\n\nCode\n# finding the mean for the groups with outliers\nmean(math$G3[math$sex==\"F\"])\n\n\n[1] 9.966346\n\n\nCode\nmean(math$G3[math$sex==\"M\"])\n\n\n[1] 10.91444\n\n\nCode\n# finding the mean for the groups without outliers\nmean(math2$G3[math2$sex==\"F\"])\n\n\n[1] 11.20541\n\n\nCode\nmean(math2$G3[math2$sex==\"M\"])\n\n\n[1] 11.86628\n\n\nThe mean has increased slightly and the difference decreased after removing the outliers but the distribution is still the same.\nCheck the equality of variances (homogeneity)\nWe can use the Levene’s test or the Bartlett’s test to check for homogeneity of variances. The former is in the car library and the later in the rstatix library. If the variances are homogeneous the p value will be greater than 0.05.\nOther tests include F test 2 sided, Brown-Forsythe and O’Brien but we shall not cover these.\n\n\nCode\n# running the Bartlett's test to check equal variance\nbartlett.test(G3~sex, data=math2)\n\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  G3 by sex\nBartlett's K-squared = 0.12148, df = 1, p-value = 0.7274\n\n\nCode\n# running the Levene's test to check equal variance\nmath2 %&gt;% levene_test(G3~sex)\n\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1   355     0.614 0.434\n\n\nThe p value is greater than 0.05 suggesting there is no difference between the variances of the two groups.\n\n\n\n\nData is continuous(G3)\nData is normally distributed\nData is independent (males and females distinct not the same individual)\nNo significant outliers\nThere are equal variances\n\nAs the assumptions are met we go ahead to perform the Student’s t test.\n\n\n\nSince the default is the Welch t test we use the \\color{blue}{\\text{var.eqaul = TRUE }} code to signify a Student’s t test. There is a t.test() function in stats package and a t_test() in the rstatix package. For this analysis we use the rstatix method as it comes out as a table.\n\n\nCode\n# perfoming the two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE) %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df      p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.0531 ns      \n\n\n\n\nCode\nstat.test$statistic\n\n\n        t \n-1.940477 \n\n\nThe results are represented as follows;\n\ny - dependent variable\ngroup1, group 2 - compared groups(independent variables)\ndf - degrees of freedom\np - p value\n\ngtsummary table of results\n\n\nCode\n math2 |&gt; \n  tbl_summary(\n    by = sex,\n    statistic =\n      list(\n        all_continuous() ~ \"{mean} ({sd})\",\n        all_dichotomous() ~ \"{p}%\")\n    ) |&gt; \n   add_n() |&gt; \n  add_overall() |&gt; \n  add_difference()\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOverall, N = 3571\nF, N = 1851\nM, N = 1721\nDifference2\n95% CI2,3\np-value2\n\n\n\n\nG3\n357\n11.5 (3.2)\n11.2 (3.2)\n11.9 (3.3)\n-0.66\n-1.3, 0.01\n0.053\n\n\n\n1 Mean (SD)\n\n\n2 Welch Two Sample t-test\n\n\n3 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nInterpretation of results\nFor the two sample t test with t(355) = -1.940477, p = 0.0531, the p value is greater than our alpha of 0.05 , we fail to reject the null hypothesis and conclude that there is no statistical difference between the means of the two groups. There is no difference in final grades between boys and girls. (A significant |t| would be 1.96 or greater).\nEffect size\nCohen’s d can be an used as an effect size statistic for the two sample t test. It is the difference between the means of each group divided by the pooled standard deviation.\nd= {m_A-m_B \\over SD_pooled}\nIt ranges from 0 to infinity, with 0 indicating no effect where the means are equal. 0.5 means that the means differ by half the standard deviation of the data and 1 means they differ by 1 standard deviation. It is divided into small, medium or large using the following cut off points.\n\nsmall 0.2-&lt;0.5\nmedium 0.5-&lt;0.8\nlarge &gt;=0.8\n\nFor the above test the following is how we can find the effect size;\n\n\nCode\n#perfoming cohen's d\nmath2 %&gt;% \n  cohens_d(G3~sex,var.equal = TRUE)\n\n\n# A tibble: 1 × 7\n  .y.   group1 group2 effsize    n1    n2 magnitude\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 G3    F      M       -0.206   185   172 small    \n\n\nThe effect size is small d= -0.20.\nIn conclusion, a two-samples t-test showed that the difference was not statistically significant, t(355) = -1.940477, p &lt; 0.0531, d = -0.20; where, t(355) is shorthand notation for a t-statistic that has 355 degrees of freedom and d is Cohen’s d. We can conclude that the females mean final grade is greater than males final grade (d= -0.20) but this result is not significant.\nWhat if it is one tailed t test?\nUse the \\color{blue}{\\text{alternative =}} option to determine if one group is \\color{blue}{\\text{\"less\"}} or \\color{blue}{\\text{\"greater\"}}. For example if we want to see whether the final grades for females are greater than males we can use the following code:\n\n\nCode\n# perfoming the one tailed two sample t test\nstat.test &lt;- math2 %&gt;% \n  t_test(G3~ sex, var.equal=TRUE, alternative = \"greater\") %&gt;%\n  add_significance()\nstat.test\n\n\n# A tibble: 1 × 9\n  .y.   group1 group2    n1    n2 statistic    df     p p.signif\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 G3    F      M        185   172     -1.94   355 0.973 ns      \n\n\nThe p value is greater than 0.05 (p=0.973), we fail to reject the null hypothesis. We conclude that the final grades for females are not significantly greater than for males.\nWhat about running the paired sample t test?\nWe can simply add the syntax \\color{blue}{\\text{paired= TRUE}} to our t_test() to run the analysis for matched pairs data."
  },
  {
    "objectID": "lessons_original/03_two_sample_ttest.html#conclusion",
    "href": "lessons_original/03_two_sample_ttest.html#conclusion",
    "title": "Two sample t test",
    "section": "",
    "text": "This article covers the Student’s t test and how we run it in R. It also shows how we find the effect size and how we can conclude the results."
  },
  {
    "objectID": "lessons/00_lesson_template.html",
    "href": "lessons/00_lesson_template.html",
    "title": "The Method",
    "section": "",
    "text": "# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n\n1 Introduction to &lt;the method&gt;\n\n\n2 Mathematical definition of &lt;the method&gt;\n\n\n3 Data source and description\n\n\n4 Cleaning the data to create a model data frame\n\n\n5 Assumptions of &lt;the method&gt;\n\n\n6 Checking the assumptions with plots\n\n\n7 Code to run &lt;the method&gt;\n\n\n8 Code output\nNOTE: this section will be created automatically by the Quarto document. You should not create a section specifically for this. When you run the code in the previous section, you will get the output automatically.\n\n\n9 Brief interpretation of the output"
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html",
    "href": "lessons/02_z-test_one_prop.html",
    "title": "Z-Test for One Proportion",
    "section": "",
    "text": "The one-sample \\(Z\\)-test is used to compare a sample proportion to a population proportion."
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#independence-and-randomness",
    "href": "lessons/02_z-test_one_prop.html#independence-and-randomness",
    "title": "Z-Test for One Proportion",
    "section": "6.1 Independence and Randomness",
    "text": "6.1 Independence and Randomness\nBecause the samples were collected at random via an FDA approved clinical trial protocol, we assume that all the participants were randomly selected and are independent of each other."
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#extreme-proportions",
    "href": "lessons/02_z-test_one_prop.html#extreme-proportions",
    "title": "Z-Test for One Proportion",
    "section": "6.2 “Extreme” Proportions",
    "text": "6.2 “Extreme” Proportions\nAccording to Ling et al. (2020), the 12-month abstinence proportion of all 533 participants in their study was 40.5 percent. As we can see here, our abstinence rates are 39.4. Neither these proportions are smaller than 5% or greater than 95%.\n\n(pExpected &lt;- 0.508 * (425/533))\n\n[1] 0.4050657\n\n# Count the number of TRUE values\n(nAbstinent &lt;- sum(outcomesCTN0094$kosten1993_isAbs))\n\n[1] 1402"
  },
  {
    "objectID": "lessons/02_z-test_one_prop.html#type-and-counts-of-data",
    "href": "lessons/02_z-test_one_prop.html#type-and-counts-of-data",
    "title": "Z-Test for One Proportion",
    "section": "6.3 Type and Counts of Data",
    "text": "6.3 Type and Counts of Data\nWe observe binary data, and we see at least 10 successes and at least 10 failures."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html",
    "href": "lessons/01_mosaic_violin.html",
    "title": "Mosaic & Box/Violin Plots",
    "section": "",
    "text": "# Installing Required Packages\n# install.packages(\"public.ctn0094data\")\n# install.packages(\"tidyverse\")\n# install.packages(\"ggmosaic\")\n\n# Loading Required Packages\nlibrary(public.ctn0094data)\nlibrary(tidyverse)\nlibrary(ggmosaic)"
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#mosaic-plot",
    "href": "lessons/01_mosaic_violin.html#mosaic-plot",
    "title": "Mosaic & Box/Violin Plots",
    "section": "7.1 Mosaic Plot",
    "text": "7.1 Mosaic Plot\n\nCompared to Project 27 and Project 51, Project 30 had the highest proportion of participants who indicated that their race is ‘White’.\nCompared to Project 30 and Project 51, Project 27 had the highest proportion of participants who indicated that their race is ‘Other’.\nCompared to Project 27 and Project 51, Project 30 has the lowest proportion of participants who indicated that their race is ‘Other’."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#violin-plot",
    "href": "lessons/01_mosaic_violin.html#violin-plot",
    "title": "Mosaic & Box/Violin Plots",
    "section": "6.3 Violin Plot",
    "text": "6.3 Violin Plot\nIn order to create a Violin plot, you must specify what data object you will be using within the ggplot() function. Then you will set aesthetic mapping options within the aes() or aesthetic layer. The geom_violin() layer specifies the violin plot. An additional call for geom_boxplot() will overlay box quartiles on the violin plot.\nThe following aesthetics are understood by geom_violin():\n\nx: Specifies the categorical variable along the x-axis.\ny: Specifies the continuous variable along the y-axis.\nalpha: Specifies a variable to determine transparency.\ncolor: Assigns an outline color to respective levels of a specified categorical variable.\nfill: Assigns a fill color to respective levels of a specified categorical variable.\ngroup: Partitions data by a discrete variable when no other grouping variable is specified, or grouping is incorrectly defaulted by R.\nlinetype: Specifies line type of violin plot.\nlinewidth: Specifies line width of violin plot.\nweight: Specifies a weight variable.\n\n\n# Violin Plot\nviolin_basic &lt;- demographics_df %&gt;% \n  ggplot() +\n  aes(x = race, y = age, color = race) +\n  labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Violin Plot of Race and Age\",\n    subtitle = \"With Summary Information\",\n    color = \"Race\"\n  ) +\n  geom_violin() +\n  geom_boxplot(width = 0.1) +\n  theme(legend.position = \"None\")\n\nviolin_basic"
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#mosaic-plots",
    "href": "lessons/01_mosaic_violin.html#mosaic-plots",
    "title": "Mosaic & Box/Violin Plots",
    "section": "6.1 Mosaic Plots",
    "text": "6.1 Mosaic Plots\nIn order to create a Mosaic plot, you must specify what data object you will be using within the ggplot() function. Then you will set aesthetic mapping options within the following geometric object layer: geom_mosaic().\nIn geom_mosaic(), the following aesthetics can be specified:\n\nweight: a weighting variable.\nx: categorical variable for the x-axis.\n\nSpecified as x = product(var1, var2, ...)\nThe product() function is used to extract the values from the categorical variable specified.\n\nalpha: a variable specifying transparency.\n\nIf the variable is not called in x:, then alpha: will be added in the first position.\n\nfill: a variable specifying fill color.\n\nIf the variable is not called in x:, then fill: will be added after the optional alpha: variable.\n\nconds: a variable specifying conditions.\n\nSpecified as conds = product(var1, var2, ...)\n\n\nThe ordering of the variables is vital as the product plot is created hierarchically.\n\n6.1.1 Basic Mosaic Plot\nIn the following example of a basic mosaic plot, we visualize the distribution of Race among CTN Projects 27, 30, and 51.\n\n# Basic Mosaic Plot\nmosaic_basic &lt;- demographics_df %&gt;% \n  ggplot() +\n  geom_mosaic(\n    aes(\n      # geom_mosaic() does not have one-to-one mapping between a variable and the x- \n      # or y-axis. So you must use the product() function when assigning a variable\n      # to the x-axis to account for the variable number of variables.\n      x = product(project),\n      fill = race\n    )\n  ) +\n  labs(\n    y = \"Race\",\n    x = \"Project\",\n    title = \"Mosaic Plot of Race by CTN Project\") +\n  # Specifies default `geom_mosaic` aesthetics, e.g white panel background, \n  # removes grid lines, adjusts widths and heights of rows and columns to \n  # reflect frequencies\n  theme_mosaic() +\n  # Removes legend illustrating Race and respective fill colors\n  theme(legend.position = \"None\")\n  \nmosaic_basic\n\n\n\n\n\n\n\n\n\n\n6.1.2 More Advanced Mosaic Plot\nIn a more advanced version of a mosaic plot, we can visualize more than 2 categorical variables. The following example utilizes race, project, and ethnicity among CTN Projects 27, 30, and 51.\n\n# Advanced Mosaic Plot\nmosaic_advanced &lt;- demographics_df %&gt;% \n  ggplot() +\n  geom_mosaic(\n    aes(\n      x = product(race, project),\n      fill = is_male\n    )\n  ) +\n  labs(\n    y = \"Race\",\n    x = \"Project\",\n    title = \"Mosaic Plot of Race by Gender and CTN Project\",\n    fill = \"Gender\"\n  ) +\n  scale_fill_manual(\n    labels = c(\"No\" = \"Female\", \"Yes\" = \"Male\"),\n    values = c(\"darkseagreen2\", \"darkslategray3\", \"grey\")\n  ) +\n  theme_mosaic() +\n  # Adjust axis tick labels to 60 degrees and justification to the right\n  # with hjust (horizontal justification) and vjust (vertical justification)\n  theme(axis.text.x = element_text(angle = 60, hjust = 1, vjust = 1))\n  \nmosaic_advanced"
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#box-plot",
    "href": "lessons/01_mosaic_violin.html#box-plot",
    "title": "Mosaic & Box/Violin Plots",
    "section": "7.2 Box Plot",
    "text": "7.2 Box Plot\n\nParticipants who indicated that their race is ‘Black’ exhibited the highest median age of around 45 years old\nParticipants who indicated that their race is ‘White’ exhibited the lowest median age at approximately 31 years old."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#box-plot-1",
    "href": "lessons/01_mosaic_violin.html#box-plot-1",
    "title": "Mosaic & Box/Violin Plots",
    "section": "7.2 Box Plot",
    "text": "7.2 Box Plot\n\nParticipants who indicated that their race is ‘Black’ exhibited the highest median age of around 45 years old\nParticipants who indicated that their race is ‘White’ exhibited the lowest median age at approximately 31 years old."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#violin-plot-1",
    "href": "lessons/01_mosaic_violin.html#violin-plot-1",
    "title": "Mosaic & Box/Violin Plots",
    "section": "7.3 Violin Plot",
    "text": "7.3 Violin Plot\n\nParticipants who indicated that their race is ‘White’ exhibited peak density around mid-20s compared to those who indicated that their race is ‘Black’, where peak density is exhibited around late-40s.\nParticipants who indicated that their race is ‘White’ had the lowest median age at approximately 31 years old, where participants who indicated that their race is ‘Black’ had the highest median age at approximately 45 years old."
  },
  {
    "objectID": "lessons/01_mosaic_violin.html#box-plots",
    "href": "lessons/01_mosaic_violin.html#box-plots",
    "title": "Mosaic & Box/Violin Plots",
    "section": "6.2 Box Plots",
    "text": "6.2 Box Plots\nIn order to create a box plot, you must specify what data object you will be using within the ggplot() function. Then you will set aesthetic mapping options within the aes() or aesthetic layer. The geom_boxplot() layer specifies the box plot.\nThe following aesthetics are understood by geom_boxplot():\n\nx or y: Specifies the categorical variable along the x- or y-axis.\nlower or xlower: Specifies the 25th percentile/first quartile.\nupper or xupper: Specifies the 75th percentile/third quartile.\nmiddle or xmiddle: Specifies the 50th percentile/second quartile/median.\nymin or xmin: Specifies the y or x minimum for the plot.\nymax or xmax: Specifies the y or x maximum for the plot.\nalpha: Specifies a variable to determine transparency.\ncolor: Assigns an outline color to respective levels of a specified categorical variable.\nfill: Assigns a fill color to respective levels of a specified categorical variable.\ngroup: Partitions data by a discrete variable when no other grouping variable is specified, or grouping is incorrectly defaulted by R.\nlinetype: Specifies line type of box plot.\nlinewidth: Specifies line width of box plot.\nshape: Specifies the shape of the (outlier) points.\nsize: Specifies the size of the points and text.\nweight: Specifies a weight variable.\n\n\n6.2.1 Basic Box Plot\nThe following is a basic box plot showing the relationship between one continuous and one categorical variable.\n\n# Box Plot\nbox_basic &lt;- demographics_df %&gt;% \n  ggplot() +\n  aes(x = race, y = age, color = race) +\n  labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Box Plot of Race and Age\",\n    color = \"Race\"\n  ) +\n  # Using width to adjust the width of the boxes\n  geom_boxplot(width = 0.5) +\n  theme(legend.position = \"None\")\n\nbox_basic\n\n\n\n\n\n\n\n\n\n\n6.2.2 More Advanced Box Plot\nWith geom_box(), you can also specify a additional categorical variable (different from you x and y variables) to break up your plot by that variable. For example, the following plot takes the previous plot of race and age and adds information by gender (is_male)\n\n# Box Plot\nbox_advanced &lt;- demographics_df %&gt;% \n  ggplot() +\n  aes(x = race, y = age, color = is_male) +\n  # changing the labels for is_male, and specifying the colors we want\n  scale_color_manual(\n    labels = c(\"No\" = \"Female\", \"Yes\" = \"Male\"),\n    values = c(\"darkorchid4\", \"darkolivegreen4\")\n  ) +\n  labs(\n    x = \"Race\",\n    y = \"Age\",\n    title = \"Box Plot of Race and Age\",\n    color = \"Gender\"\n  ) +\n  # Using width to adjust the width of the boxes\n  geom_boxplot(width = 0.5)\n\nbox_advanced"
  },
  {
    "objectID": "lessons/01_scatterplots.html",
    "href": "lessons/01_scatterplots.html",
    "title": "How to Create a Scatterplot",
    "section": "",
    "text": "library(tidyverse)\n# Contains colour palette for ggplot\nlibrary(viridis)\n# Gapminder dataset\nlibrary(dslabs)\n\n\n1 Introduction to Scatterplots\nScatterplots display the relationship between two variables using dots to represent the values for each numeric variable. This presentation will examine the relationship between GDP per capita and Fertility over time using ggplot with facets.\nHypothesis: A negative relationship exists between GDP per capita and fertility i.e. as GDP per capita increases, fertility decreases.\n\n\n2 Gapminder data description\nData was obtained from the dslabs package and comes from Gapminder a Swedish non-profit organization. The Gapmidner data set has health and income outcomes for 184 countries from 1960 to 2016. Gapminder aims to promote a fact-based worldview by providing accessible and understandable global development data. The dataset covers a wide range of variables, including economic, social, and health-related indicators like GDP, infant mortality, life expectancy, fertility, as well as population, making it a valuable resource for understanding global trends and patterns over time. Countries and territories with missing information were not excluded from the data set as the lack of information can also be looked into and shed light on why data was not collected or provided. To determine whether a country’s health and income outcomes are influenced by population sizes and GDP per capita, the data will be used to create a series of graphs to view different trends.\n\n\n3 Cleaning the data to create a model data frame\nA tibble was created from the gapminder dataset, and a new column was created to measure GDP per capita. Overall, using tibbles enhances the readability, usability, and compatibility of your code within the tidyverse ecosystem.\n\n# Creating gapminder dataset\\tibble\ngapminder_df &lt;-\n  as_tibble(gapminder) %&gt;%\n  mutate(gdp_per_capita = gdp / population)\n\n\n\n4 Components of ggplot2\nggplot2 is a package used to create graphs and visualize data. The main three components of ggplot2 are the data, aesthetics and geom layers.\n\nThe data layer - states what data will be used to graph\nThe aesthetics layer - specifies the variables that are being mapped\nThe geom layer - specifies the type of graph to be produced\n\n\n\n\n\n\n\n\n5 Code to run interpretable scatterplots and create facets\nIn order to create a scatter-plot using ggplot, you must specify what data you will be using, state which variables will be mapped and how under aesthetics. What differentiates the scatter-plot from any other type of graph will be specified under the geom layer. For the scatter-plot, geom_point will be used.\nIn this example, we will analyze the relationship between fertility rates and gdp per capita for each country in 2011.\n\nfig_bubble_2011 &lt;-\n  ggplot(data = filter(gapminder_df, year == 2011)) +\n  aes(x = gdp_per_capita, y = fertility) +\n  geom_point()\n\nfig_bubble_2011 \n\n\n\n\n\n\n\nFigure 1: Association between fertility rates and gdp per capita for each country in 2011\n\n\n\n\n\nIn the example above, we have mapped out fertility as our y-axis and gdp per capita as our x-axis. However, at it’s very basic level, there is not enough information provided to accurately analyze the relationship between the two. For this reason, we can add additional layers that will provide more information to properly analyze the scatter-plot.\n\nfig_bubble_pretty_2011 &lt;-\n  ggplot(data = filter(gapminder_df, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    # will change the size of the point based on population size \n    size = population, \n    # will assign colors based on the continent the country is in \n    color = continent\n  ) +\n  # gives a range as to how big or small the points of population should be\n  scale_size(range = c(1, 20)) + \n  # removes N/A from the legend and titles it Continent \n  scale_colour_discrete(na.translate = F, name = \"Continent\") +\n  # removes population size from the legend \n  guides(size = \"none\") +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    # transforms numbers from scientific notation to regular number \n    labels = scales::comma\n  ) +\n  labs(\n    title = \"Fertility rate descreases as GDP per capita increases in 2011\",\n    y = \"Fertility rates\",\n    caption = \"Source: Gapminder\"\n  ) +\n  # the ylim was set based on the fertility, lowest was near 1 & highest was above 7\n  ylim(1.2, 8.0) +\n  # alpha increases transparency of the points to ensure they can all be seen\n  geom_point(alpha = 0.5) \n\nfig_bubble_pretty_2011\n\n\n\n\n\n\n\nFigure 2: Association between fertility rates and gdp per capita for each country, grouped by continent, in 2011\n\n\n\n\n\nFigure 2 builds on the previous scatterplot of Fertility Rates (y axis) against GDP per capita (x axis) for 2011. The bubble size depicts respective country populations, and continents are coded by colors according to the key. This figure displays a negative relationship between GDP per capita and Fertility Rates. It supports the Hypothesis which states that as GDP per capita increases, Fertility Rates decreases. This trend can be confirmed for all continents, however, the degree to which fertility rates drop between continents varies. Most European country appear below a fertility rate of 2 babies per woman. The Americas appear to follow closely behind (under 4), followed by Oceania and Asia. A significant number of African countries still maintained higher fertility rates with lower GDP per capita for 2011.\nThis is an example of wanting to create four separate graphs to see the relationship between fertility rates and GDP per capita based on the years 1960, 1975, 1990 and 2005. In this example we omitted the facet argument.\n\nfig_bubble_multiple &lt;-\n  ggplot(data = filter(gapminder_df, year %in% c(1960, 1975, 1990, 2005))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE, name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) \n\nfig_bubble_multiple\n\n\n\n\n\n\n\nFigure 3: Association between fertility rates and GDP per capita based on the years 1960, 1975, 1990 and 2005\n\n\n\n\n\nWithout having used the facet argument, all points of all four years have been included into one graph. This graph does not provide us with the information we were looking for.\n\nfig_bubble_multiple_facet &lt;-\n  ggplot(data = filter(gapminder_df, year %in% c(1960, 1975, 1990, 2005))) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility,\n    size = population,\n    color = continent\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  ) +\n  scale_size(range = c(0, 20)) +\n  guides(size = \"none\") +\n  scale_colour_discrete(na.translate = FALSE , name = \"Continent\") +\n  labs(\n    title = \"Fertility continues to decrease as GDP per capita increases\",\n    caption = \"Source: Gapminder\",\n    y = \"Fertility rates\"\n  ) +\n  geom_point(alpha = 0.3) +\n  # specifiying we want the graphs split based on year\n  facet_wrap(~ year)\n\nfig_bubble_multiple_facet\n\n\n\n\n\n\n\nFigure 4: Association between fertility rates and GDP per capita based on the years 1960, 1975, 1990 and 2005, using facet\n\n\n\n\n\nNow that we’ve specified the facet argument, we now have four separate graphs that can be properly analysed. In Figure 4 we see an increasingly negative relationship between the two variables over time. This observation is congruent with the hypothesis that as GDP per capita increases, fertility decreases.\nThis global trend can be attributed to the increasing proportion of women in the workforce in the mid to late 20th century. As a result of World War II (1939-1945), women took on roles outside the home to compensate for men at war. Despite increased GDP per capita, this may have contributed to reduced fertility (babies per woman) over time. In 1960, a clear disparity among continents is seen. Most European countries’ fertility rates fell below 5, while their GDP per capita increased. Most African countries maintained high fertility rates above 5, but little change is seen in GDP per capita. The Asian continent shows the most variation among countries during that year. Some smaller Asian countries continued to maintain high fertility rates as GDP per capita increased in 1960. However, others displayed a drastic decrease in fertility rates by 1960. The Americas followed a steady decline over the years. By 2005, an overall negative relationship can be seen with most countries’ fertility rates below 5 babies per woman.\n\nfig_bubble_row_2011 &lt;-\n  ggplot(data = filter(gapminder_df, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent, nrow = 1)\n\nfig_bubble_row_2011 \n\n\n\n\n\n\n\nFigure 5: Association between fertility rates and GDP per capita based on continent\n\n\n\n\n\nIn the graph above, we see an example of separating the single graph into graphs based on continent. It has also been specified to have all graphs appear in one single row through the nrow argument. Very importantly however, this graph is unclear and cannot be used to compare the relationship between fertility and gdp per capita.\n\nfig_bubble_facet_2011 &lt;-\n  ggplot(data = filter(gapminder_df, year == 2011)) +\n  aes(\n    x = gdp_per_capita,\n    y = fertility\n  ) +\n  scale_x_continuous(\n    name = \"GDP per Capita\",\n    trans = \"log10\",\n    labels = scales::comma\n  )  +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ continent)\n\nfig_bubble_facet_2011 \n\n\n\n\n\n\n\nFigure 6: Association between fertility rates and GDP per capita based on continent not using nrow\n\n\n\n\n\nIn the next example above, we removed the nrow argument and the system automatically separated the graphs into three columns with two rows. Additionally, we changed the x-axis to a log scale to better interpret gdp per capita. There is a way to determine a relationship between fertility and gdp per capita by continent.\n\n\n6 Public Health Interpretation\nA global negative trend is depicted between GDP per capita and fertility over time. Such changes were due to wars as well as social, cultural and economic changes that incentivize smaller families especially in Asian countries. Most European, American and Asian countries depicted significant decreases in fertility rates over time as GDP per capita increased. On the other hand, African countries remain in the top rank for fertility over the years. These differences are depicted in the population pyramid changes of developed vs developing countries. Public health policies can be tailored to incentivizing increased fertility in developed countries to ensure generation continuity, and effective family planning strategies in developing countries.\n\n\n7 Conclusion\nIn this lesson, the basic functions of ggplot2 package were shown, which can create a scatterplot. There are three layers to the code to make a plot in R: data, aesthetic, and geometric. Within the aesthetic layer, functions can be added such as size and color to analyze more variables. Additionally, facets can split up graphs over a categorical variable, adding another potential variable to analyze in the plot."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html",
    "href": "lessons_original/05_glm_ordinal_logistic.html",
    "title": "Ordinal Logistic Regression",
    "section": "",
    "text": "We are all familiar with the concept of Logistic regression. It is used to analyze data when the outcome variables is categorical. There are three types of logistic regression, Binary logistic regression where the outcome variable is binary (Yes/No), Multinomial logistic regression when the outcome variable is categorical with three or more categories, Ordinal logistic regression where there is a natural ordering among three or more categories of the outcome variableagresti2002?.\n\nTypes of Logistic Regression\n\n\n\nBinary LR\nMultinomial LR\nOrdinal LR\n\n\n\n\nNumber of categories?\nTwo\nThree or more\nThree or more\n\n\nOrdering matters?\nNo\nNo\nYes"
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#model-assumptions",
    "href": "lessons_original/05_glm_ordinal_logistic.html#model-assumptions",
    "title": "Ordinal Logistic Regression",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nThe key assumptions of Ordinary logistic Regression which ensures the validity of the model are as follows,\n\nThe outcome variable is ordered.\nThe predictor variables are either continuous, categorical, or ordinal.\nThere is no multicollinearity among the predictors.\nProportional odds."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#libraries",
    "href": "lessons_original/05_glm_ordinal_logistic.html#libraries",
    "title": "Ordinal Logistic Regression",
    "section": "Libraries",
    "text": "Libraries\nHere are libraries required to run the analysis.\n\n# install.packages(\"multgee\")\n# install.packages(\"pander\")\n# install.packages(\"table1\")\n# install.packages(\"car\")\n# install.packages(\"mltools\")\n# install.packages(\"pomcheckr\")\nlibrary(conflicted)\nlibrary(table1)\nlibrary(multgee)\nlibrary(skimr)\nlibrary(pander)\nlibrary(gtsummary)\nlibrary(car)\nlibrary(mltools)\nlibrary(MASS)\nlibrary(pomcheckr)\n\nconflict_prefer(\"filter\", \"dplyr\", quiet = TRUE)\nconflict_prefer(\"select\", \"dplyr\", quiet = TRUE)\nlibrary(tidyverse)\n\n\nWarning\nInstead of installing package MASS to the global environment use MASS::polr() for running the Ordinal Logistic Regression model. As masking it conflicts wirh the select() function for tidyverse and gtsummary()."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#exploring-data",
    "href": "lessons_original/05_glm_ordinal_logistic.html#exploring-data",
    "title": "Ordinal Logistic Regression",
    "section": "Exploring data",
    "text": "Exploring data\nLet’s begin by looking at the data.\n\narthritis_df &lt;- \n  multgee::arthritis %&gt;%\n  mutate(\n    y = factor(y, ordered = TRUE),\n    sex = factor(\n      sex,\n      levels = c(1, 2),\n      labels = c(\"Female\", \"Male\")\n    ),\n    treatment = factor(\n      trt,\n      levels = c(\"1\", \"2\"),\n      labels = c(\"Placebo\", \"Drug\")\n    ),\n    baseline = factor(baseline, ordered = TRUE)\n  ) %&gt;%\n  select(\"y\", \"sex\", \"age\", \"treatment\", \"baseline\") %&gt;%\n  drop_na() %&gt;% \n  as_tibble()\n\n\nSummary\n\nskim(arthritis_df)\n\n\nData summary\n\n\nName\narthritis_df\n\n\nNumber of rows\n888\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ny\n0\n1\nTRUE\n5\n3: 345, 4: 275, 2: 159, 5: 76\n\n\nsex\n0\n1\nFALSE\n2\nMal: 645, Fem: 243\n\n\ntreatment\n0\n1\nFALSE\n2\nDru: 445, Pla: 443\n\n\nbaseline\n0\n1\nTRUE\n5\n3: 407, 2: 215, 4: 166, 1: 67\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n50.4\n11.1\n21\n42\n54\n60\n66\n▁▃▃▇▇\n\n\n\n\n\n\n\nDescriptives\n\narthritis_df %&gt;% \n  tbl_summary(by = treatment) \n\n\n\nTable 1: Predictors by treatment group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nPlacebo, N = 4431\nDrug, N = 4451\n\n\n\n\ny\n\n\n\n\n\n\n    1\n26 (5.9%)\n7 (1.6%)\n\n\n    2\n96 (22%)\n63 (14%)\n\n\n    3\n165 (37%)\n180 (40%)\n\n\n    4\n129 (29%)\n146 (33%)\n\n\n    5\n27 (6.1%)\n49 (11%)\n\n\nsex\n\n\n\n\n\n\n    Female\n127 (29%)\n116 (26%)\n\n\n    Male\n316 (71%)\n329 (74%)\n\n\nage\n55 (42, 60)\n53 (42, 59)\n\n\nbaseline\n\n\n\n\n\n\n    1\n33 (7.4%)\n34 (7.6%)\n\n\n    2\n105 (24%)\n110 (25%)\n\n\n    3\n207 (47%)\n200 (45%)\n\n\n    4\n83 (19%)\n83 (19%)\n\n\n    5\n15 (3.4%)\n18 (4.0%)\n\n\n\n1 n (%); Median (IQR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting Outcome variable (rheumatoid arthritis score)\n\narthritis_df %&gt;% \n  count(y) %&gt;% \n  mutate(prop = n / sum(n)) %&gt;% \n  rename(score = y) %&gt;% \n  ggplot() + \n    aes(x = score, y = prop) +\n    labs(\n      x = \"Rheumatoid Arthritis Score\", \n      y = \"Relative Frequencies (w Obs. Count)\"\n    ) +\n    scale_y_continuous(labels = scales::percent) +\n    geom_col() +\n    geom_text(aes(label = n), vjust = 1.5, color = \"white\")\n\n\n\n\n\n\n\n\n\n\nPairs\n\nGGally::ggpairs(arthritis_df)"
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#how-to-use-polr",
    "href": "lessons_original/05_glm_ordinal_logistic.html#how-to-use-polr",
    "title": "Ordinal Logistic Regression",
    "section": "How to use polr()",
    "text": "How to use polr()\nThe basic structure of the function looks like this (there are other options we don’t list, but we won’t need them):\n\npolr(\n  # Two required arguments\n  formula,\n  data,\n  # Optional stuff\n  weights,\n  subset,\n  na.action,\n  Hess = FALSE,\n  method = \"logistic\"\n)\n\nHere,\n\nformula: a formula expression as for regression models, of the form response ~ predictors. The response should be a factor (preferably an ordered factor), which will be interpreted as an ordinal response, with levels ordered as in the factor.\ndata: a data frame which contains the variables occurring in formula.\nweights: optional case weights in fitting. Defaults to 1.\nsubset: expression saying which subset of the rows of the data should be used in the fit. All observations are included by default.\nna.action: a function to filter missing data. We removed all the missing values from our data, so we won’t use this.\nHess: logical for whether the Hessian (the observed information matrix) should be returned. We will use this if we intend to call summary or variance covariance on the fit.\nmethod: \"logistic\", \"probit\", \"loglog\" (log-log), \"cloglog\" (complementary log-log), or \"cauchit\" (corresponding to a Cauchy latent variable). The default option is to use the Logistic link function."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#fitting-the-model",
    "href": "lessons_original/05_glm_ordinal_logistic.html#fitting-the-model",
    "title": "Ordinal Logistic Regression",
    "section": "Fitting the model",
    "text": "Fitting the model\nUsing this function, let’s fit the POLR model to the data. By default, the Hess option is turned off, so we turn it on so that we can calculate the odds ratios later.\n\nfit_olr_mod &lt;- MASS::polr(y ~ ., data = arthritis_df, Hess = TRUE)\n\nThe output is a bit ugly, so we clean it up for more professional documents using the pander() function (from the pander:: and knitr:: packages).\n\npander(summary(fit_olr_mod))\n\nCall: MASS::polr(formula = y ~ ., data = arthritis_df, Hess = TRUE)\n\nCoeficients\n\n\n\n\n\n\n\n\n \nValue\nStd. Error\nt value\n\n\n\n\nsexMale\n0.1513\n0.1377\n1.099\n\n\nage\n-0.01366\n0.005713\n-2.391\n\n\ntreatmentDrug\n0.5454\n0.1255\n4.347\n\n\nbaseline.L\n3.109\n0.2826\n11\n\n\nbaseline.Q\n0.6897\n0.233\n2.96\n\n\nbaseline.C\n0.09577\n0.1796\n0.5334\n\n\nbaseline^4\n-0.1802\n0.1239\n-1.455\n\n\n\n\nIntercepts\n\n\n\n\n\n\n\n\n \nValue\nStd. Error\nt value\n\n\n\n\n1|2\n-4.244\n0.3731\n-11.38\n\n\n2|3\n-2.162\n0.339\n-6.378\n\n\n3|4\n-0.2073\n0.3352\n-0.6186\n\n\n4|5\n2.094\n0.3429\n6.108\n\n\n\nResidual Deviance: 2238.92\nAIC: 2260.92\n\n\nThe summary() function called on a polr model object gives us the coefficients, intercepts, their standard errors, and t-statistics."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#odds-ratio",
    "href": "lessons_original/05_glm_ordinal_logistic.html#odds-ratio",
    "title": "Ordinal Logistic Regression",
    "section": "Odds Ratio",
    "text": "Odds Ratio\nIn order to get the Odds Ratio and the predictor’s confidence intervals we take the exponential of the coefficient. There is no straight forward way of doing that in R. Below is one way of solving that issue, which uses the confint() function from the multgee:: package.\n\n# Calculate a matrix of the lower and upper confidence intervals\nCI_mat &lt;- confint(fit_olr_mod)\n\n# Combine results and make them \"pretty\"\norResults_df &lt;- tibble(\n  variable = rownames(CI_mat),\n  oddsRatio = exp(fit_olr_mod$coefficients),\n  lower = exp(CI_mat[, 1]),\n  upper = exp(CI_mat[, 2])\n)\n\npander(orResults_df)\n\n\n\n\n\n\n\n\n\n\nvariable\noddsRatio\nlower\nupper\n\n\n\n\nsexMale\n1.163\n0.8883\n1.524\n\n\nage\n0.9864\n0.9754\n0.9975\n\n\ntreatmentDrug\n1.725\n1.35\n2.208\n\n\nbaseline.L\n22.41\n12.94\n39.27\n\n\nbaseline.Q\n1.993\n1.266\n3.161\n\n\nbaseline.C\n1.101\n0.7745\n1.567\n\n\nbaseline^4\n0.8351\n0.6548\n1.064"
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#interpreting-the-results",
    "href": "lessons_original/05_glm_ordinal_logistic.html#interpreting-the-results",
    "title": "Ordinal Logistic Regression",
    "section": "Interpreting the Results",
    "text": "Interpreting the Results\n\nSex: Compared to female participants, Male participants had orResults_df[1, \"oddsRatio\", drop = TRUE] fold higher odds of reporting high score of rheumatoid arthritis.\nAge: For 1 year change in age the odds of reporting high rheumatoid arthritis score changes orResults_df[2, \"oddsRatio\", drop = TRUE] times.\nTreatment: Compared to the Placebo group participants, the participant who received the drug had orResults_df[3, \"oddsRatio\", drop = TRUE] times higher odds of reporting high score of rheumatoid arthritis.\nBaseline score: It appears that we could perhaps collapse the baseline rheumatoid arthritis score into only three levels, because the confidence intervals for the cubic and quartic polynomial components include 1."
  },
  {
    "objectID": "lessons_original/05_glm_ordinal_logistic.html#checking-assumptions",
    "href": "lessons_original/05_glm_ordinal_logistic.html#checking-assumptions",
    "title": "Ordinal Logistic Regression",
    "section": "Checking Assumptions",
    "text": "Checking Assumptions\nNext we check the key assumptions to verify whether the model is appropriate to use.\n\nMulticollinearity\nTwo of our predictors are binary, one predictor is continuous, and one predictor and the response are ordered. Because of this, there are no “standard” functions to calculate the correlation matrix of these predictors. However, we will use indicator encoding to transform the binary predictors, and we will use polynomial encoding to transform the ordered predictor (polynomial encoding represents ordered predictors as a set of polynomial terms with G-1 components, where G is the number of categories). Both actions were already done “behind the scenes” by the polr() function, so we simply need to access the “model matrix” object. We do this via the model.matrix() function, but we remove the first column because it represents the intercept.\n\n# Extract the encoded features used by the POLR model, dropping the intercept\nmodel.matrix(fit_olr_mod)[, -1] %&gt;% \n  # calculate the correlation matrix of the predictors (using the \"spearman\" \n  #   option because some of the predictors are binary)\n  cor(method = \"spearman\")\n               sexMale      age treatmentDrug baseline.L baseline.Q baseline.C\nsexMale        1.00000 -0.00498       0.02917   -0.02839     0.0284   -0.04546\nage           -0.00498  1.00000      -0.04114   -0.11361     0.0657    0.09082\ntreatmentDrug  0.02917 -0.04114       1.00000   -0.00358     0.0195    0.00995\nbaseline.L    -0.02839 -0.11361      -0.00358    1.00000    -0.1986   -0.57397\nbaseline.Q     0.02835  0.06571       0.01950   -0.19857     1.0000   -0.02112\nbaseline.C    -0.04546  0.09082       0.00995   -0.57397    -0.0211    1.00000\nbaseline^4    -0.03688 -0.04347      -0.01599    0.30668    -0.7821   -0.31491\n              baseline^4\nsexMale          -0.0369\nage              -0.0435\ntreatmentDrug    -0.0160\nbaseline.L        0.3067\nbaseline.Q       -0.7821\nbaseline.C       -0.3149\nbaseline^4        1.0000\n\nThe correlation is quite low among most of the predictors. However, we see that the quadratic and quartic (.Q and ^4, respectively) components are just under the “let’s worry about this” threshold of 0.8 in absolute value. This suggests to me that the highest two categories of the rheumatoid arthritis score at baseline (4 and 5) can probably be collapsed without losing a lot of information. However, we’ll keep things simple for now and say there is no multicollinearity.\n\n\nProportional Odds\nOrdinal logistic regression makes the assumption that the relationship between each pair of outcome groups is the same. In other words, ordinal logistic regression assumes that the coefficients describing the relationship between, say, the lowest and all higher categories of the response variable are the same as those describing the relationship between the next lowest and all higher categories, and so on. This assumption can be vefied several ways. Here, I have used a package calledpomcheckr? that generates graphics to check for proportional odds assumption created by UCLA statistical consulting group see more here .\n\nGraphics to check for proportional odds\n\npomchk &lt;- pomcheck(\n  y ~ sex + age + treatment + baseline,\n  data = arthritis_df\n)\nplot(pomchk)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere the function is calculating the difference in proportion of the categories in the outcome variable and plotting them against each category of the predictors. In the ideal case scenario, the distance between the dots in each line is somewhat equal; if this is true, then the categories should be considered proportional. It appears that the proportional odds assumption is violated here.\nAdd discussion on how to fix the assumption violation."
  }
]