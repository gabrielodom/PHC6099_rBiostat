---
title: "Transformations to Normality"
author: 
  - name: "Freeman Lewis, MPH"
    affiliation: "Florida International University Robert Stempel College of Public Health and Social Work"
output: 
  pdf_document: default
  html_document: default
editor: "visual"
---

## Introduction to Transformations to Normality ##

The pattern of values obtained when a variable is measured in a large number of individuals is called a distribution. Distributions can be broadly classified as normal and non-normal. The normal distribution is also called ‘Gaussian distribution’ as it was first described by K.F. Gauss. This chapter outlines the process of transforming data to achieve a normal distribution in R. Parametric methods, such as t-tests and ANOVA, require that the dependent (outcome) variable is approximately normally distributed within each group being compared. When the normality assumption is not satisfied, transforming the data can correct the non-normal distributions. For t-tests and ANOVA, it is sufficient to transform the dependent variable. However, for linear regression, transformations may be applied to the independent variable, the dependent variable, or both to achieve a linear relationship between variables and ensure homoscedasticity.

## When to Apply Transformations to Normality ##

One of the critical assumptions of statistical hypothesis testing is that the data are samples from a normal distribution. Therefore, it is essential to identify whether distributions are skewed or normal. There are several straightforward methods to detect skewness. Firstly, if the mean is less than twice the standard deviation, the distribution is likely skewed. Additionally, in a normally distributed population, the mean and standard deviation of the samples are independent. This characteristic can be used to detect skewness; if the standard deviation increases as the mean increases across groups from a population, the distribution is skewed. Beyond these simple methods, normality can be verified using statistical tests such as the Shapiro-Wilk test, the Kolmogorov-Smirnov test, and the Anderson-Darling test. Additionally, the `moments` package in R can be used to calculate skewness quantitatively. The skewness is determined using the third standardized moment, providing a measure of the asymmetry of the data distribution. If skewness is identified, efforts should be made to transform the data to achieve a normal distribution. This transformation is crucial for applying robust parametric tests in the analysis.

Transformations can also be employed to facilitate comparison and interpretation. A classical example of a variable commonly reported after logarithmic transformation is the hydrogen ion concentration (pH). Another instance where transformation aids in data comparison is the logarithmic transformation of a dose-response curve. When plotted, the dose-response relationship is curvilinear; however, plotting the response against the logarithm of the dose (log dose-response plot) results in an elongated S-shaped curve. The middle portion of this curve forms a straight line, making it easier to compare two straight lines by measuring their slopes than to compare two curves. Thus, transformation can significantly enhance data comparison.

In summary, transformations can be applied to normalize data distribution or to simplify interpretation and comparison.

## Types of Transformations to Normality ##

Often, the transformation that normalizes the distribution also equalizes the variance. While there are several types of transformations available—such as logarithmic, square root, reciprocal, cube root, and Box-Cox—the first three are the most commonly used. The following guidelines can help in selecting the appropriate method of transformation:

1. **Logarithmic Transformation**: If the standard deviation is proportional to the mean, the distribution is positively skewed, making logarithmic transformation ideal. Note that when using a log transformation, a constant should be added to all values to ensure they are positive before transformation.

    $$ y' = \log(y + c) $$

    where $y$ is the original value and $c$ is a constant added to ensure all values are positive.
    
<div style="display: flex; justify-content: center;">

```{r original_histogram_transformed_histogram, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)

set.seed(123)
data <- rlnorm(1000, meanlog = 0, sdlog = 1)  # Generate data from a log-normal distribution

# Original data histogram
original_plot <- ggplot(data.frame(x = data), aes(x = x)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Original Data (Right-Skewed)", x = "Value", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Log-transformed data histogram
log_data <- log(data)  # Log transform the log-normal data
transformed_plot <- ggplot(data.frame(x = log_data), aes(x = x)) +
  geom_histogram(binwidth = 0.2, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Log-Transformed (Normalized)", x = "Log(Value)", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Arrange plots side by side
grid.arrange(original_plot, transformed_plot, ncol = 2)
```
</div>

2. **Square Root Transformation**: When the variance is proportional to the mean, square root transformation is preferred. This is particularly applicable to variables measured as counts, such as the number of malignant cells in a microscopic field or the number of deaths from swine flu.

    $$ y' = \sqrt{y} $$
    
<div style="display: flex; justify-content: center;">
```{r original_histogram_squareroot_histogram, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)

set.seed(123)
data <- rchisq(1000, df = 4)  # Generate data from a chi-squared distribution

# Original data histogram
original_plot_sqrt <- ggplot(data.frame(x = data), aes(x = x)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Original Data (Right-Skewed)", x = "Value", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Square root transformed data histogram
sqrt_data <- sqrt(data)  # Square root transform the chi-squared data
transformed_plot_sqrt <- ggplot(data.frame(x = sqrt_data), aes(x = x)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Square Root Transformed (Normalized)", x = "Square Root(Value)", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Arrange plots side by side
grid.arrange(original_plot_sqrt, transformed_plot_sqrt, ncol = 2)
```
</div>

3. **Geometric Reciprocal Transformation**: If the standard deviation is proportional to the mean squared, a reciprocal transformation is appropriate. This is typically used for highly variable quantities, such as serum creatinine levels.

    $$ y' = \frac{1}{y} $$
    
<div style="display: flex; justify-content: center;">
```{r original_histogram_georeciprocaltransform_histogram, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)

set.seed(123)
data <- -rlnorm(1000, meanlog = 0, sdlog = 1)  # Generate data from a negatively skewed distribution

# Original data histogram
original_plot_reciprocal <- ggplot(data.frame(x = data), aes(x = x)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Original Data (Left-Skewed)", x = "Value", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Geometric reciprocal transformed data histogram
reciprocal_data <- -1 / data  # Geometric reciprocal transform the left-skewed data
transformed_plot_reciprocal <- ggplot(data.frame(x = reciprocal_data), aes(x = x)) +
  geom_histogram(binwidth = 0.2, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Geometric Reciprocal Transformed", x = "Reciprocal(Value)", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Arrange plots side by side
grid.arrange(original_plot_reciprocal, transformed_plot_reciprocal, ncol = 2)
```
</div>

4. **Box-Cox Transformation**: The Box-Cox transformation is a family of power transformations that can be used to stabilize variance and make the data more closely conform to a normal distribution, especially when the best power transformation (e.g., square root, logarithmic) is uncertain. By estimating an optimal parameter $\lambda$ from the data, the Box-Cox transformation tailors the transformation to the specific dataset's needs. The transformation is defined as:

    $$
    y(\lambda) =
    \begin{cases} 
    \frac{y^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0 \\
    \log(y) & \text{if } \lambda = 0 
    \end{cases}
    $$

   Here, $\lambda$ is a parameter that is estimated from the data. The Box-Cox transformation is particularly useful because it includes many of the other transformations (such as the logarithmic and square root transformations) as special cases.

<div style="display: flex; justify-content: center;">
```{r original_histogram_boxcoctransform_histogram , echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(MASS)
library(gridExtra)

set.seed(123)
data <- rgamma(1000, shape = 2, scale = 2)  # Generate data from a gamma distribution

# Original data histogram
original_plot <- ggplot(data.frame(x = data), aes(x = x)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Original Data (Right-Skewed)", x = "Value", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Perform Box-Cox transformation
boxcox_data <- boxcox(data ~ 1, lambda = seq(-2, 2, by = 0.1))
lambda_opt <- boxcox_data$x[which.max(boxcox_data$y)]
transformed_data <- (data^lambda_opt - 1) / lambda_opt

# Box-Cox transformed data histogram
transformed_plot <- ggplot(data.frame(x = transformed_data), aes(x = x)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  theme_minimal() +
  labs(title = "Box-Cox Transformed (Normalized)", x = "Transformed(Value)", y = "Frequency") +
  theme(plot.title = element_text(size = 12, hjust = 0.5))

# Arrange plots side by side
grid.arrange(original_plot, transformed_plot, ncol = 2)
```
</div>

Among these transformations, logarithmic transformation is often favored because it is meaningful when back-transformed (using the antilog).

## Examples of Transformations to Normality ##

### Data Source and Description ###

The `USJudgeRatings` dataset is a built-in dataset in R that contains ratings of 43 judges in the US Superior Court. The ratings are based on the evaluations from lawyers who have had cases before these judges. The dataset includes multiple variables that represent different aspects of the judges' performance.

#### Variables in the Dataset ####

-   **CONT**: Judicial "controlling" or authoritative nature.

-   **INTG**: Judicial integrity.

-   **DMNR**: Judicial demeanor.

-   **DILG**: Judicial diligence.

-   **CFMG**: Case flow management.

-   **DECI**: Judicial decision-making.

-   **PREP**: Judicial preparation.

-   **FAMI**: Familiarity with the law.

-   **ORAL**: Oral skills.

-   **WRIT**: Written skills.

-   **PHYS**: Physical ability.

-   **RTEN**: Willingness to follow trends.

This dataset is useful for analyzing various performance metrics of judges and can be used to explore relationships between different aspects of judicial performance. In the following examples, we’ll consider two variables:

-   `CONT`: Number of contacts of lawyer with judge. Positively skewed.

-   `PHYS`: Physical ability. Negatively skewed

### Requisite Packages and Dataset Loading ###

```{r setup, include=FALSE}
# Load necessary libraries
library(ggplot2)
library(GGally)
library(moments)
library(knitr)
library(MASS)
```

```{r load-data, echo=TRUE}
# Load necessary libraries
library(ggplot2)
library(GGally)
library(moments)
library(knitr)
library(MASS)

# Load the USJudgeRatings dataset
data("USJudgeRatings")
df <- USJudgeRatings

# Display the first few rows of the dataset
head(df)
```

### Visualizations of `CONT` and `PHYS` Variables ###

```{r plot-cont, echo=TRUE, fig.cap="Figure 2.1: Distribution of CONT Variable"}
# Plot density of CONT variable
ggplot(df, aes(x=CONT)) + 
  geom_density(fill="lightgray") +
  scale_x_continuous(limits=c(3, 12)) +
  stat_function(fun=dnorm, args=list(mean=mean(df$CONT), sd=sd(df$CONT)), color="red", linetype="dashed") +
  labs(title="Density Plot of CONT", x="CONT", y="Density")
```

```{r plot-phys, echo=TRUE, fig.cap="Figure 2.2: Distribution of PHYS Variable"}
# Plot density of PHYS variable
ggplot(df, aes(x=PHYS)) + 
  geom_density(fill="lightgray") +
  scale_x_continuous(limits=c(3, 12)) +
  stat_function(fun=dnorm, args=list(mean=mean(df$PHYS), sd=sd(df$PHYS)), color="red", linetype="dashed") +
  labs(title="Density Plot of PHYS", x="PHYS", y="Density")
```

### Summary Statistics for `CONT` and `PHYS` Variables ###

```{r summary-stats, echo=TRUE}

# Get the summary statistics for CONT and PHYS variables
summary_stats <- summary(df[, c("CONT", "PHYS")])

# Convert the matrix to a data frame
summary_df <- as.data.frame.matrix(summary_stats)

# Display summary statistics as a table without the Statistic column
kable(summary_df, caption = "Table 2.1: Summary Statistics for CONT and PHYS Variables")
```

### Skewness and Kurtosis for `CONT` and `PHYS` Variables ###

```{r skewness-kurtosis, echo=TRUE}

# Calculate skewness and kurtosis for CONT and PHYS variables using the Moments Package
skewness_vals <- sapply(df[, c("CONT", "PHYS")], skewness)
kurtosis_vals <- sapply(df[, c("CONT", "PHYS")], kurtosis)

# Create a data frame to display skewness and kurtosis
skew_kurt_df <- data.frame(
  Variable = names(skewness_vals),
  Skewness = skewness_vals,
  Kurtosis = kurtosis_vals
)

# Display the data frame as a table
kable(skew_kurt_df, caption = "Table 2.2: Skewness and Kurtosis for CONT and PHYS Variables")
```

### Visualizations of Transformed `CONT` and `PHYS` Variables ###

```{r plot-transformedcont, echo=TRUE, fig.cap="Figure 2.4: Distribution of log transformed CONT Variable"}
# Apply log transformation to CONT variable
df$LOG_CONT <- log(df$CONT)

# Plot density of log-transformed CONT variable
ggplot(df, aes(x=LOG_CONT)) + 
  geom_density(fill="lightgray") +
  stat_function(fun=dnorm, args=list(mean=mean(df$LOG_CONT), sd=sd(df$LOG_CONT)), color="red", linetype="dashed") +
  labs(title="Density Plot of Log-Transformed CONT", x="Log-Transformed CONT", y="Density")
```

```{r plot-box_coxlambdaPhys, echo=TRUE, fig.cap="Figure 2.5: Distribution of optimal lambda determined by the `boxcox` function"}

# Apply Box-Cox transformation to PHYS using MASS package
bc <- boxcox(df$PHYS ~ 1, lambda = seq(-5, 5, 0.1))
lambda <- bc$x[which.max(bc$y)]
df$BOX_COX_PHYS <- (df$PHYS^lambda - 1) / lambda
```

```{r plot-box_coxPhys, echo=TRUE, fig.cap="Figure 2.6: Distribution of Box-Cox transformed PHYS Variable"}
# Plot density of Box-Cox transformed PHYS variable
ggplot(df, aes(x=BOX_COX_PHYS)) + 
  geom_density(fill="lightgray") +
  stat_function(fun=dnorm, args=list(mean=mean(df$BOX_COX_PHYS), sd=sd(df$BOX_COX_PHYS)), color="red", linetype="dashed") +
  labs(title="Density Plot of Box-Cox Transformed PHYS", x="Box-Cox Transformed PHYS", y="Density")

```

### Skewness and Kurtosis for Transformed `CONT` and `PHYS` Variables ###

```{r skewness-kurtosis_transformed, echo=TRUE}

# Calculate skewness and kurtosis for transformed variables
skewness_vals_trans <- sapply(df[, c("LOG_CONT", "BOX_COX_PHYS")], skewness)
kurtosis_vals_trans <- sapply(df[, c("LOG_CONT", "BOX_COX_PHYS")], kurtosis)

# Create a data frame to display skewness and kurtosis for transformed variables
skew_kurt_df_trans <- data.frame(
  Variable = names(skewness_vals_trans),
  Skewness = skewness_vals_trans,
  Kurtosis = kurtosis_vals_trans
)

# Display the data frame as a table
kable(skew_kurt_df_trans, caption = "Table 2.3: Skewness and Kurtosis for Transformed Variables (LOG_CONT and BOX_COX_PHYS)")
```

## Results

The application of log and Box-Cox transformations has effectively improved the normality of the `CONT` and `PHYS` variables, respectively. For the `CONT` variable, the original distribution exhibited a positive skewness of 1.086 and a kurtosis of 4.730, indicating a right-skewed distribution with heavy tails and a sharp peak. The log transformation reduced the skewness to 0.656 and the kurtosis to 3.758, demonstrating a significant move towards normality, though the distribution still retains some right-skewness and heavier tails compared to a normal distribution. The `PHYS` variable originally had a negative skewness of -1.558 and a kurtosis of 5.408, reflecting a left-skewed distribution with heavy tails and a pronounced peak. Following the Box-Cox transformation, the skewness was reduced to -0.381 and the kurtosis to 2.502. These results indicate that the transformed `PHYS` distribution is much closer to normality, with reduced skewness and lighter tails, achieving a more symmetric distribution. In summary, the transformations have substantially mitigated the skewness and kurtosis of both variables, enhancing their suitability for statistical analyses that assume normality. This adjustment ensures more reliable and valid results in subsequent analyses.

## Conclusion and Discussion
The transformations applied to the CONT and PHYS variables demonstrate the effectiveness of data transformation techniques in improving the normality of distributions. By addressing skewness and kurtosis, transformations like the log and Box-Cox methods help in stabilizing variance and making data more symmetric. This enhancement is crucial for statistical analyses that rely on the assumption of normality, ensuring more accurate and reliable results. Overall, the use of appropriate transformations is a vital step in data preprocessing, significantly enhancing the suitability of data for various analytical procedures and improving the robustness of statistical inferences. However, caution is warranted in the interpretation of results after transformation. Transformed data can sometimes complicate the understanding of results and their real-world implications, as the transformed scale may not directly relate to the original measurements. It is essential to back-transform results when interpreting findings to ensure they are meaningful and relevant to the original context.

## References

1.  Manikandan S. (2010). Data transformation. *Journal of pharmacology & pharmacotherapeutics*, *1*(2), 126–127. https://doi.org/10.4103/0976-500X.72373
2.  West R. M. (2022). Best practice in statistics: The use of log transformation. *Annals of clinical biochemistry*, *59*(3), 162–165. https://doi.org/10.1177/00045632211050531
3.  Lee D. K. (2020). Data transformation: a focus on the interpretation. *Korean journal of anesthesiology*, *73*(6), 503–508. https://doi.org/10.4097/kja.20137
